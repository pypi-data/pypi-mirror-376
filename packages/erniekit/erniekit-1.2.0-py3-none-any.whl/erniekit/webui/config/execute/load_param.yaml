### webui中控制的参数导入到execute执行文件中

train:
  - model_name_or_path
  - fine_tuning
  - output_dir
  - amp_master_grad
  - compute_type
  - tensor_parallel_degree
  - pipeline_parallel_degree
  - sharding_parallel_degree
  - pipeline_parallel_config
  - pp_seg_method
  - use_sp_callback
  - sharding
  - moe_group
  - disable_ckpt_quant
  - lora_rank
  - lora_alpha
  - lora_plus_scale
  - rslora
  - train_dataset_path
  - train_dataset_prob
  - eval_dataset_path
  - eval_dataset_prob
  - max_seq_len
  - logging_dir
  - num_samples_each_epoch
  - stage
  - num_train_epochs
  - gradient_accumulation_steps
  - max_steps
  - batch_size
  - recompute
  - dataloader_num_workers
  - distributed_dataloader
  - learning_rate
  - lr_scheduler_type
  - min_lr
  - layerwise_lr_decay_bound
  - weight_decay
  - adam_epsilon
  - adam_beta1
  - adam_beta2
  - warmup_steps
  - save_steps
  - logging_steps
  - save_strategy
  - evaluation_strategy
  - eval_steps
  - save_total_limit
  - max_prompt_len
  - release_grads
  - offload_optim
  - optim
  - scale_loss
  - train_dataset_type
  - eval_dataset_type
  - modality_ratio
  - text_dataset_path
  - text_dataset_prob
  - text_dataset_type
  - pp_need_data_degree
  - virtual_pp_degree
chat:
  - model_name_or_path
  - tensor_parallel_degree
  - output_dir
  - max_model_len
  - port
  - max_new_tokens
  - top_p
  - temperature
export:
  - max_shard_size
  - model_name_or_path
  - fine_tuning
  - output_dir
  - compute_type
  - tensor_parallel_degree
  - pipeline_parallel_degree
  - sharding_parallel_degree
  - pipeline_parallel_config
  - sharding
eval:
  - eval_dataset_type
  - eval_dataset_path
  - eval_dataset_prob
  - max_seq_len
  - num_samples_each_epoch
  - model_name_or_path
  - moe_group
  - fine_tuning
  - lora_rank
  - lora_alpha
  - lora_plus_scale
  - rslora
  - fuse_rope
  - logging_dir
  - batch_size
  - output_dir
  - amp_master_grad
  - compute_type
  - tensor_parallel_degree
  - pipeline_parallel_degree
  - sharding_parallel_degree
  - pipeline_parallel_config
  - sharding
  - disable_ckpt_quant
