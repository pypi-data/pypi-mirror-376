{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d3YWvsJbXY",
   "metadata": {
    "id": "32d3YWvsJbXY"
   },
   "source": [
    "# Load our Example Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "F-rupY0-qvol",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696,
     "referenced_widgets": [
      "f9ec6d072d904b5989b1062f80705fc8",
      "b04c0e708d4542a48477dd868af36c9c",
      "1f01143e735f4eefb99350f04713249d",
      "d4eabab758de4a3798cb79884e0baf01",
      "90d73a4244304f6dbf403ce640ea389a",
      "abbbf00663c2408f88aea9b5aa50f242",
      "a443b0debb3f4a2ab7d4f87384ed8476",
      "21c6aa9d505d4ea7a9f149f29fe61519",
      "dc22958a739c4e95bc1be7dd915d3dce",
      "9709262184a8478181d59abcebb559f3",
      "48451a643245422cb5b61eae2e7ec828",
      "fd828d78fb1d45c38791a21c7ef3da4f",
      "52cf5cfb3d624c91a118c03b29e4f57c",
      "d9da21e263c4431f88bf2f27161ce89b",
      "2ee35d93aa5240bf850b4bfcf24631fb",
      "d71ae7c7093d4688a21554052536e955",
      "41c5af0d59e74fa5ae627f090895eb91",
      "2e50cb5eb96c44e68815dc63ccb100f2",
      "b147302c6db4448595f27a5f6afbc1b3",
      "4663db4f5693459ebe57f2ccc338c6b7",
      "23d527d76cdd4c8a817d02372b2503cf",
      "e28600d636424622b62ec97cd7f2ebe1",
      "253075f666c847aeb962965dabe67f44",
      "cc98be6cbde846bab9a939071140c9e8",
      "8294567a25bf4d618e5c76fe7fa83627",
      "db18b1b5d246491190d8bf174b4ad0d5",
      "0aec5fa6a59143d4a3be9783a5e885da",
      "ce997c78582e4e9e964bf8f0a95513ff",
      "15761f852e154b7c81b2b5e942e951d3",
      "592fb96f4d0a4333ae0d56f51fd9ac57",
      "56d0b50c443347a18ee8a2aedb9f3b5d",
      "2e68a898444e4019980a2729d55b7425",
      "7097d6d3b6b140dbb617c57a29d90c56",
      "b9467bd81dd6426cafea61228a108852",
      "f5d495ea79164c229e8ae598de97801b",
      "245ccfa119624186aa5c6d21b5e294ad",
      "cc54c78d3c6c44b1abc81590980094a5",
      "31bbcf1ca75c40f08081724468eda3b1",
      "406d4376fc96406891abc294fab65224",
      "67420e9cb44a4daba5f00919ce7b1309",
      "8957e67a0bd2468aaca9ade7229567d7",
      "e8e63a83b388421fae3a2c95b4248b43",
      "04c5dfb96495447aa90ddbae3c102a4d",
      "493d3709d6c9434e8fd68cd3315f7815",
      "26a2a360e7924c88aab4578803c69850",
      "ab32615f65aa4098a57c04ba034927e2",
      "81cdb92565bd43f4ab5c1479f18eccc4",
      "d7f60d1ed037479bb689a62664fc9cd2",
      "b2de5e7192ba4067a5190dc9a7cb197a",
      "ab24563fade94630b902eeab25f151ab",
      "0e4322b443aa44208a075089093a3eb5",
      "3ab0feaf5ca24e3d973d38738189ff4c",
      "81a1c40b69ff4d059f2cb78c1cb67e6c",
      "d372981f2c7241ef85404a322dac2cc0",
      "cb73f1fbcfe440a5aec891f12f263c50"
     ]
    },
    "id": "F-rupY0-qvol",
    "outputId": "f3c6de20-8890-45eb-e61b-d1c74678a935"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 02:09:47.687046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-13 02:09:47.938457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-13 02:09:48.016127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-13 02:09:48.512492: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 02:09:54.994873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ec6d072d904b5989b1062f80705fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd828d78fb1d45c38791a21c7ef3da4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253075f666c847aeb962965dabe67f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9467bd81dd6426cafea61228a108852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a2a360e7924c88aab4578803c69850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last hidden states shape: torch.Size([1, 8, 768])\n",
      "Pooler output shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# prompt: import bert base embedding model from hugging face\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is a sample sentence.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# The output is a dictionary containing 'last_hidden_state' and 'pooler_output'\n",
    "last_hidden_states = output.last_hidden_state\n",
    "pooler_output = output.pooler_output\n",
    "\n",
    "print(\"Last hidden states shape:\", last_hidden_states.shape)\n",
    "print(\"Pooler output shape:\", pooler_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Q5gkgGP9q_dD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5gkgGP9q_dD",
    "outputId": "f519c088-98e1-4d14-acfb-d8a01c4cdb67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between text1 and text2: 0.9522\n",
      "Cosine similarity between text1 and text3: 0.8442\n",
      "Cosine similarity between text2 and text3: 0.8108\n"
     ]
    }
   ],
   "source": [
    "# prompt: now compuse cosine similarity between three texts (1 relevant pair and 1 irrelevant text)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embedding(text):\n",
    "  encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "  with torch.no_grad():\n",
    "    output = model(**encoded_input)\n",
    "  # Use the CLS token embedding as the sentence embedding\n",
    "  sentence_embedding = output.last_hidden_state[:, 0, :].numpy()\n",
    "  return sentence_embedding\n",
    "\n",
    "# Define the texts\n",
    "text1 = \"The weather is nice today.\"\n",
    "text2 = \"It's a beautiful day outside.\"\n",
    "text3 = \"The stock market crashed yesterday.\"\n",
    "\n",
    "# Get embeddings for each text\n",
    "embedding1 = get_embedding(text1)\n",
    "embedding2 = get_embedding(text2)\n",
    "embedding3 = get_embedding(text3)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_1_2 = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "similarity_1_3 = cosine_similarity(embedding1, embedding3)[0][0]\n",
    "similarity_2_3 = cosine_similarity(embedding2, embedding3)[0][0]\n",
    "\n",
    "print(f\"Cosine similarity between text1 and text2: {similarity_1_2:.4f}\")\n",
    "print(f\"Cosine similarity between text1 and text3: {similarity_1_3:.4f}\")\n",
    "print(f\"Cosine similarity between text2 and text3: {similarity_2_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VWP3Y1ZpJq7H",
   "metadata": {
    "id": "VWP3Y1ZpJq7H"
   },
   "source": [
    "# Set OPENAI API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LOdMuCTcpSrH",
   "metadata": {
    "id": "LOdMuCTcpSrH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-svcacct-jd_qsygf8C4wNycwAwrjfBAApSasg72tP2FGTpHPGJHbZb0tCtvS19n0dg4fT3BlbkFJBlb-yNLhygEwdu4OiRCxwA2aJ6KF9OY49BEYS2htqzX_4EwCghBpBpjQQTUA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UA7c1LcNV7CK",
   "metadata": {
    "id": "UA7c1LcNV7CK"
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import checklist_plus\n",
    "from checklist_plus.editor import Editor\n",
    "from checklist_plus.perturb import LLMPerturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nlvhAhvzOgLY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nlvhAhvzOgLY",
    "outputId": "ebfdd9ec-51b9-4cfa-b8ac-d57882c5120a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checklist_plus.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rFHKn9FzpBdL",
   "metadata": {
    "id": "rFHKn9FzpBdL"
   },
   "outputs": [],
   "source": [
    "llm_editor = Editor(\n",
    "             use_llm=True,\n",
    "            model_name='gpt-4o-mini'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6PHaN3zNKJ9I",
   "metadata": {
    "id": "6PHaN3zNKJ9I"
   },
   "source": [
    "## Generate Examples data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DuXzDqHyrOq5",
   "metadata": {
    "id": "DuXzDqHyrOq5"
   },
   "outputs": [],
   "source": [
    "ret = llm_editor.template('The football game was very good, I especially liked {mask}', context=\"different experiences in football games\", remove_duplicates=True, n_completions=100)\n",
    "original_texts = ret.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fx-pY0FrsWlG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fx-pY0FrsWlG",
    "outputId": "2446417a-0bb4-4b7b-c4b8-7da3ab87b7e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The football game was very good, I especially liked match's highlights\", \"The football game was very good, I especially liked defender's block\", \"The football game was very good, I especially liked goal's significance\", \"The football game was very good, I especially liked goalpost's impact\", \"The football game was very good, I especially liked game's review\"]\n"
     ]
    }
   ],
   "source": [
    "original_texts = list(set(original_texts))\n",
    "print(original_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Jtd4SakztVVK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jtd4SakztVVK",
    "outputId": "b7a621fd-87b8-4d9e-c584-0dc5c9446652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sZGGrK6UKMlH",
   "metadata": {
    "id": "sZGGrK6UKMlH"
   },
   "source": [
    "## Paraphrase Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Ttq5-xrusmdZ",
   "metadata": {
    "id": "Ttq5-xrusmdZ"
   },
   "outputs": [],
   "source": [
    "ret = llm_editor.paraphrase_llm(original_texts, n_paraphrases=1, length_preference='similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7OFSGqXJuLrm",
   "metadata": {
    "id": "7OFSGqXJuLrm"
   },
   "outputs": [],
   "source": [
    "paraphrased_texts = ret.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "YM7XdyTVuUEj",
   "metadata": {
    "id": "YM7XdyTVuUEj"
   },
   "outputs": [],
   "source": [
    "assert len(paraphrased_texts) == len(original_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cJ-iD26kuSyh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJ-iD26kuSyh",
    "outputId": "33351ae2-0c22-4abc-fa3f-70b8bb869220"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The soccer match was excellent; I particularly enjoyed the highlights of the game.',\n",
       " \"The soccer match was quite impressive; I particularly enjoyed the defender's tackle.\",\n",
       " 'The soccer match was quite enjoyable; I particularly appreciated the importance of the goal.',\n",
       " 'The soccer match was excellent, and I particularly appreciated the influence of the goalposts.',\n",
       " 'The soccer match was excellent, and I particularly enjoyed the analysis of the game.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jqt2AEfQKSSp",
   "metadata": {
    "id": "Jqt2AEfQKSSp"
   },
   "source": [
    "## Negate Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "az7HDU05ucr3",
   "metadata": {
    "id": "az7HDU05ucr3"
   },
   "outputs": [],
   "source": [
    "perturb = LLMPerturb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "YLvV7GGaun1e",
   "metadata": {
    "id": "YLvV7GGaun1e"
   },
   "outputs": [],
   "source": [
    "ret = perturb.add_negation_llm(original_texts, n_variations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "An-UPIzdvMWK",
   "metadata": {
    "id": "An-UPIzdvMWK"
   },
   "outputs": [],
   "source": [
    "negated_texts = [x[0] for x in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ah2sRGH-vWXp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah2sRGH-vWXp",
    "outputId": "69d94eba-463e-4223-9cf6-c92e7e5eba97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The football game was not very good; I did not especially like the match's highlights.\",\n",
       " \"The football game was not very good; I did not especially like the defender's block.\",\n",
       " 'The football game was not very good, and I did not like the significance of the goal.',\n",
       " \"The football game was not very good; I did not like the goalpost's impact at all.\",\n",
       " \"The football game was not very good; I did not especially like the game's review.\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MhE84H_jKcq6",
   "metadata": {
    "id": "MhE84H_jKcq6"
   },
   "source": [
    "# Perform Simple MFT test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "OIW8HXfYvceZ",
   "metadata": {
    "id": "OIW8HXfYvceZ"
   },
   "outputs": [],
   "source": [
    "from checklist_plus.test_types import MFT, INV, DIR\n",
    "from checklist_plus.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "TPdgaB_Kwqk7",
   "metadata": {
    "id": "TPdgaB_Kwqk7"
   },
   "outputs": [],
   "source": [
    "# expect original text is more similar to the paraphrased one\n",
    "def similar_paraphrase(x, pred, conf, label=None, meta=None):\n",
    "    return pred == 0\n",
    "expect_fn = Expect.single(similar_paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "iowk0KjpwWDt",
   "metadata": {
    "id": "iowk0KjpwWDt"
   },
   "outputs": [],
   "source": [
    "test = MFT(list(zip(original_texts, paraphrased_texts, negated_texts)), expect=expect_fn, name='Simple negation',\n",
    "           capability='Negation', description='Very simple negations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "K1QR4_RW1hzA",
   "metadata": {
    "id": "K1QR4_RW1hzA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_cosine_similarities(data):\n",
    "  similarities = []\n",
    "  for original, paraphrased, negated in data:\n",
    "    original_embedding = get_embedding(original)\n",
    "    paraphrased_embedding = get_embedding(paraphrased)\n",
    "    negated_embedding = get_embedding(negated)\n",
    "\n",
    "    sim_paraphrased = cosine_similarity(original_embedding, paraphrased_embedding)[0][0]\n",
    "    sim_negated = cosine_similarity(original_embedding, negated_embedding)[0][0]\n",
    "\n",
    "    similarities.append([sim_paraphrased, sim_negated])\n",
    "  similarities = np.array(similarities)\n",
    "  return np.argmax(similarities, axis=-1), similarities\n",
    "\n",
    "cosine_sims = get_cosine_similarities(list(zip(original_texts, paraphrased_texts, negated_texts))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sGWWq5R1xvr4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGWWq5R1xvr4",
    "outputId": "abde0dff-452e-46c0-fba5-a42b900f40b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, 1, 1]), array([[0.9449084 , 0.94528353],\n",
      "       [0.94997364, 0.95709735],\n",
      "       [0.9254709 , 0.9529028 ],\n",
      "       [0.8882368 , 0.8951863 ],\n",
      "       [0.9117462 , 0.92221034]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sims[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "jsXxgY3j2P6y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsXxgY3j2P6y",
    "outputId": "cb57b01c-05d2-4365-a86b-584a2e55c84a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 99 examples\n"
     ]
    }
   ],
   "source": [
    "test.run(get_cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "p2UqxIAg2ToE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2UqxIAg2ToE",
    "outputId": "067f75d3-c7b5-4e6e-90e8-808a6ffbd46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      99\n",
      "Fails (rate):    86 (86.9%)\n",
      "\n",
      "Example fails:\n",
      "0.9 (\"The football game was very good, I especially liked midfielder's pass\", \"The soccer match was excellent; I particularly appreciated the midfielder's assist.\", \"The football game was not very good, and I did not like the midfielder's pass at all.\")\n",
      "----\n",
      "0.9 (\"The football game was very good, I especially liked player's creativity\", 'The soccer match was excellent, and I particularly appreciated the creativity displayed by the players.', \"The football game was not very good; I did not like the player's creativity at all.\")\n",
      "----\n",
      "0.9 (\"The football game was very good, I especially liked fan's celebration\", 'The soccer match was excellent, and I particularly enjoyed how the fans celebrated.', \"The football game was not good, and I did not particularly like the fans' celebration.\")\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# bert-base-uncased is not sensitive to negations\n",
    "test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w8mkw98DBW5G",
   "metadata": {
    "id": "w8mkw98DBW5G"
   },
   "source": [
    "# Let's test whether embedding model understands sizes in our marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fNJjvyuwBhzp",
   "metadata": {
    "id": "fNJjvyuwBhzp"
   },
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "XOM9hHpD2eHn",
   "metadata": {
    "id": "XOM9hHpD2eHn"
   },
   "outputs": [],
   "source": [
    "ret = llm_editor.template('red {mask} shoes US 11 size ', context=\"different shoe brands\", remove_duplicates=True, n_completions=100)\n",
    "user_queries = ret.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "WvPwb3Sv2v8j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvPwb3Sv2v8j",
    "outputId": "18feac0d-102f-4372-9fcb-2a316fd96a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red Nike shoes US 11 size ', 'red Brooks Ghost shoes US 11 size ', 'red Asics Gel shoes US 11 size ', 'red Louboutin Louis shoes US 11 size ', 'red Adidas shoes US 11 size ']\n"
     ]
    }
   ],
   "source": [
    "user_queries = list(set(user_queries))\n",
    "print(user_queries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "HJEqPjzd26Cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJEqPjzd26Cq",
    "outputId": "bd8acb77-0d6e-41f6-a2a0-d9531b0f65e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2HWdSwIg3BLj",
   "metadata": {
    "id": "2HWdSwIg3BLj"
   },
   "outputs": [],
   "source": [
    "ret = llm_editor.paraphrase_llm(user_queries, n_paraphrases=1, length_preference='longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "WDof9YrW3Zc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDof9YrW3Zc7",
    "outputId": "04a34394-3e33-4c87-d21a-84716bc757eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A pair of size 11 red Nike sneakers from the United States.', 'Size 11 in the United States for the red Brooks Ghost running shoes.', 'A pair of size 11 US red Asics Gel sneakers.', 'A pair of red Louis Vuitton shoes in a size 11 for men in the United States.', 'A pair of red Adidas sneakers in a size 11 for men in the United States.']\n"
     ]
    }
   ],
   "source": [
    "item_titles = ret.data\n",
    "print(item_titles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rFI_c_UF3jXL",
   "metadata": {
    "id": "rFI_c_UF3jXL"
   },
   "outputs": [],
   "source": [
    "assert len(item_titles) == len(user_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pRrBVXxs4F-T",
   "metadata": {
    "id": "pRrBVXxs4F-T"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nVz_zwDt38nM",
   "metadata": {
    "id": "nVz_zwDt38nM"
   },
   "outputs": [],
   "source": [
    "ret = LLMPerturb.perturb(list(nlp.pipe(item_titles)), LLMPerturb.change_number, n=1, keep_original=False)\n",
    "item_titles_negative = [o[0] for o in ret.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hXQDdD725vMp",
   "metadata": {
    "id": "hXQDdD725vMp"
   },
   "outputs": [],
   "source": [
    "assert len(item_titles) == len(item_titles_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ySzTAkAb57_S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySzTAkAb57_S",
    "outputId": "393b5f5d-45e5-406a-e0d4-492cd6d1dd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red Nike shoes US 11 size ', 'red Brooks Ghost shoes US 11 size ', 'red Asics Gel shoes US 11 size '] ['A pair of size 9 red Nike sneakers from the United States.', 'Size 12 in the United States for the red Brooks Ghost running shoes.', 'A pair of size 14 US red Asics Gel sneakers.'] ['A pair of size 11 red Nike sneakers from the United States.', 'Size 11 in the United States for the red Brooks Ghost running shoes.', 'A pair of size 11 US red Asics Gel sneakers.']\n"
     ]
    }
   ],
   "source": [
    "print(user_queries[:3], item_titles_negative[:3], item_titles[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZjOaN3zQBmIY",
   "metadata": {
    "id": "ZjOaN3zQBmIY"
   },
   "source": [
    "## Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "DBf3lWEd8MJd",
   "metadata": {
    "id": "DBf3lWEd8MJd"
   },
   "outputs": [],
   "source": [
    "test = MFT(list(zip(user_queries, item_titles, item_titles_negative)), expect=expect_fn, name='Size change',\n",
    "           capability='Size', description='Very simple size understanding check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "WT0TctjF8Wil",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT0TctjF8Wil",
    "outputId": "6c7ea0b5-93e4-4379-e9d9-41b1663d986a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 100 examples\n"
     ]
    }
   ],
   "source": [
    "test.run(get_cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "eoTVqIt98XTL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoTVqIt98XTL",
    "outputId": "181ef76b-96e2-4b65-8e67-de4590700a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      100\n",
      "Fails (rate):    45 (45.0%)\n",
      "\n",
      "Example fails:\n",
      "0.9 (\"red Palladium's shoes US 11 size \", 'A pair of red Palladium sneakers in size US 11.', 'A pair of red Palladium sneakers in size US 10.')\n",
      "----\n",
      "0.9 (\"red Salomon's shoes US 11 size \", 'A pair of red Salomon shoes in size US 11.', 'A pair of red Salomon shoes in size US 12.')\n",
      "----\n",
      "0.9 ('red Etnies shoes US 11 size ', 'Crimson Etnies footwear in a US size 11.', 'Crimson Etnies footwear in a US size 13.')\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# bert-base-uncased fails 45% of the times even when texts are identical\n",
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10baa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = llm_editor.template('{mask} phone color of {mask}', context=\"mask1 is for brands and mask2 is for colors\", remove_duplicates=True, n_completions=100)\n",
    "user_queries = ret.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228f2323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTC phone color of khaki', 'OnePlus phone color of citrine', 'Xiaomi phone color of jade', 'HTC phone color of gold', 'Sony phone color of white']\n"
     ]
    }
   ],
   "source": [
    "user_queries = list(set(user_queries))\n",
    "print(user_queries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93732c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28930139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paraphrase prompt template:\n",
      "You are a paraphrasing expert. Generate paraphrases of the given text.\n",
      "Focus on paraphrasing text related to: {context}. Try to use terminology and phrasing common in this domain.\n",
      "Generate exactly {n_paraphrases} unique paraphrases that preserve the original meaning while using different words and sentence structures.\n",
      "Each paraphrase should be:\n",
      "- Each paraphrase must preserve the original meaning\n",
      "- Use different vocabulary and sentence structures\n",
      "- Preserve context and domain relevance\n",
      "- Make each paraphrase unique and natural\n",
      "- {length_instruction}\n",
      "\n",
      "Here are some examples of how to respond:\n",
      "\n",
      "Motorola phone color crimson -> Motorola phone of a rich deep red colour\n",
      "\n",
      "Sharp phone color coffee -> Sharp phone of a deep brown colour\n",
      "\n",
      "Samsung phone color white -> Samsung phone of a pure bright colour\n",
      "\n",
      "\n",
      "Text to paraphrase: {text}\n",
      "Consider synonyms, sentence restructuring, and varying lengths before you respond.\n",
      "Provide the paraphrases as a list. Example:\n",
      "[\"Paraphrase 1\", \"Paraphrase 2\", \"Paraphrase 3\"]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTC phone in a muted olive hue', 'OnePlus phone in a vibrant yellow hue', 'Xiaomi phone in a shade of green resembling jade', 'HTC phone in a luxurious shade of gold', 'Sony phone in a brilliant ivory shade']\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    (\"Motorola phone color crimson\", \"Motorola phone of a rich deep red colour\"),\n",
    "    (\"Sharp phone color coffee\", \"Sharp phone of a deep brown colour\"),\n",
    "    (\"Samsung phone color white\", \"Samsung phone of a pure bright colour\"),\n",
    "]\n",
    "ret = llm_editor.paraphrase_llm(user_queries, n_paraphrases=1, length_preference='similar', context=\"only colors\", examples=examples)\n",
    "item_titles = ret.data\n",
    "print(item_titles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2d43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = llm_editor.detect_and_mask_entities_llm(user_queries, entity_type=\"COLORS\", mask_token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa7df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_titles_no_colors = [o[\"masked_text\"] for o in ret.data if o[\"contains_entities\"]]\n",
    "data = []\n",
    "for idx, o in enumerate(ret.data):\n",
    "    if o[\"contains_entities\"]:\n",
    "        data.append((user_queries[idx], item_titles[idx], o[\"masked_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18157042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3d04fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HTC phone color of khaki',\n",
       "  'HTC phone in a muted olive hue',\n",
       "  'HTC phone color of '),\n",
       " ('OnePlus phone color of citrine',\n",
       "  'OnePlus phone in a vibrant yellow hue',\n",
       "  'OnePlus phone color of '),\n",
       " ('Xiaomi phone color of jade',\n",
       "  'Xiaomi phone in a shade of green resembling jade',\n",
       "  'Xiaomi phone color of ')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Testing Embeddings Behaviour",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "checklist-plus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
