"""
Performance Optimizer (RFS v4)

RFS v4 ì„±ëŠ¥ ìµœì í™” ë©”ì¸ ì—”ì§„
- ìë™ ì„±ëŠ¥ ë¶„ì„
- ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ìë™ íŠœë‹ ì‹¤í–‰
"""

import asyncio
import gc
import json
import os
import sys
import threading
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

try:
    import psutil
except ImportError:
    psutil = None

try:
    from rich.console import Console
    from rich.live import Live
    from rich.panel import Panel
    from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn
    from rich.table import Table

    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
from ..core.result import Failure, Result, Success

if RICH_AVAILABLE:
    console = Console()
else:
    console = None


class OptimizationType(Enum):
    """ìµœì í™” ìœ í˜•"""

    MEMORY = "memory"
    CPU = "cpu"
    IO = "io"
    NETWORK = "network"
    STARTUP = "startup"
    RUNTIME = "runtime"
    CLOUD_RUN = "cloud_run"


class OptimizationCategory(Enum):
    """ìµœì í™” ì¹´í…Œê³ ë¦¬"""

    PERFORMANCE = "performance"
    SCALABILITY = "scalability"
    RELIABILITY = "reliability"
    EFFICIENCY = "efficiency"


class OptimizationPriority(Enum):
    """ìµœì í™” ìš°ì„ ìˆœìœ„"""

    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼"""

    optimization_type: OptimizationType
    name: str
    description: str
    priority: OptimizationPriority
    impact_score: float
    implementation_difficulty: int
    estimated_improvement: str
    before_metrics: Dict[str, Any] = field(default_factory=dict)
    after_metrics: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    code_changes: List[Dict[str, str]] = field(default_factory=list)
    applied: bool = False

    @property
    def roi_score(self) -> float:
        """íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ì ìˆ˜ ê³„ì‚°"""
        if self.implementation_difficulty == 0:
            return 0
        return self.impact_score / self.implementation_difficulty


@dataclass
class OptimizationSuite:
    """ìµœì í™” ìŠ¤ìœ„íŠ¸"""

    name: str
    target_types: List[str] = field(default_factory=list)
    auto_apply: bool = False
    max_impact_threshold: float = 50.0
    include_experimental: bool = False
    timeout: int = 300


class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ë©”ì¸ ì—”ì§„"""

    def __init__(self, project_path: Optional[str] = None):
        self.project_path = Path(project_path) if project_path else Path.cwd()
        self.optimization_results: List[OptimizationResult] = []
        self.baseline_metrics: Dict[str, Any] = {}
        self.monitoring_active = False
        self.monitoring_task: Optional[asyncio.Task] = None
        self.performance_history: List[Dict[str, Any]] = []
        self.max_history_size = 1000

    async def run_optimization_analysis(
        self, suite: OptimizationSuite
    ) -> Result[List[OptimizationResult], str]:
        """ìµœì í™” ë¶„ì„ ì‹¤í–‰"""
        try:
            if console:
                console.print(
                    Panel(
                        f"ğŸš€ RFS v4 ì„±ëŠ¥ ìµœì í™” ë¶„ì„ ì‹œì‘\n\nğŸ“‹ ìµœì í™” ìŠ¤ìœ„íŠ¸: {suite.name}\nğŸ¯ ëŒ€ìƒ ìœ í˜•: {(', '.join([t.value for t in suite.target_types]) if suite.target_types else 'ëª¨ë“  ìœ í˜•')}\nâš¡ ìë™ ì ìš©: {('ì˜ˆ' if suite.auto_apply else 'ì•„ë‹ˆì˜¤')}\nğŸ§ª ì‹¤í—˜ì  ê¸°ëŠ¥: {('í¬í•¨' if suite.include_experimental else 'ì œì™¸')}",
                        title="ì„±ëŠ¥ ìµœì í™”",
                        border_style="blue",
                    )
                )
            if console:
                console.print("ğŸ“Š ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
            await self._measure_baseline_performance()
            optimization_tasks = []
            if not suite.target_types or OptimizationType.MEMORY in suite.target_types:
                optimization_tasks = optimization_tasks + [
                    self._analyze_memory_optimization(suite)
                ]
            if not suite.target_types or OptimizationType.CPU in suite.target_types:
                optimization_tasks = optimization_tasks + [
                    self._analyze_cpu_optimization(suite)
                ]
            if not suite.target_types or OptimizationType.IO in suite.target_types:
                optimization_tasks = optimization_tasks + [
                    self._analyze_io_optimization(suite)
                ]
            if not suite.target_types or OptimizationType.STARTUP in suite.target_types:
                optimization_tasks = optimization_tasks + [
                    self._analyze_startup_optimization(suite)
                ]
            if (
                not suite.target_types
                or OptimizationType.CLOUD_RUN in suite.target_types
            ):
                optimization_tasks = optimization_tasks + [
                    self._analyze_cloud_run_optimization(suite)
                ]
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                console=console,
            ) as progress:
                for i, task in enumerate(optimization_tasks):
                    task_id = progress.add_task(
                        f"ìµœì í™” ë¶„ì„ {i + 1}/{len(optimization_tasks)}", total=100
                    )
                    results = await task
                    if results:
                        self.optimization_results = self.optimization_results + results
                    progress.update(task_id, completed=100)
            self.optimization_results.sort(key=lambda x: x.roi_score, reverse=True)
            if suite.auto_apply:
                await self._apply_safe_optimizations(suite)
            if console:
                await self._display_optimization_results()
            return Success(self.optimization_results)
        except Exception as e:
            return Failure(f"ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    async def _measure_baseline_performance(self):
        """ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì •"""
        try:
            import os
            import time

            import psutil

            if psutil:
                process = psutil.Process(os.getpid())
                memory_info = process.memory_info()
                cpu_percent = process.cpu_percent(interval=1)
                num_threads = process.num_threads()
            else:
                process = None
                # Provide default values when psutil is not available
                memory_info = type("MemoryInfo", (), {"rss": 0, "vms": 0})()
                cpu_percent = 0
                num_threads = threading.active_count()

            start_time = time.time()
            try:
                from .. import core

                import_time = time.time() - start_time
            except:
                import_time = 0
            gc_stats = {
                f"generation_{i}": gc.get_stats()[i] if i < len(gc.get_stats()) else {}
                for i in range(3)
            }
            self.baseline_metrics = {
                "timestamp": datetime.now().isoformat(),
                "memory": {
                    "rss": memory_info.rss,
                    "vms": memory_info.vms,
                    "rss_mb": memory_info.rss / 1024 / 1024,
                    "vms_mb": memory_info.vms / 1024 / 1024,
                },
                "cpu": {"percent": cpu_percent, "num_threads": num_threads},
                "startup": {"import_time": import_time},
                "gc": gc_stats,
                "system": {"python_version": sys.version, "platform": sys.platform},
            }
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì • ì‹¤íŒ¨: {str(e)}", style="yellow")
            self.baseline_metrics = {}

    async def _analyze_memory_optimization(
        self, suite: OptimizationSuite
    ) -> List[OptimizationResult]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ë¶„ì„"""
        results = []
        try:
            if "memory" in self.baseline_metrics:
                memory_mb = self.baseline_metrics["memory"]["rss_mb"]
                if memory_mb > 100:
                    cache = {}
                gc_stats = self.baseline_metrics.get("gc", {})
                if gc_stats and any(
                    (
                        gen.get("collections", 0) > 100
                        for gen in gc_stats.values()
                        if type(gen).__name__ == "dict"
                    )
                ):
                    results = results + [
                        OptimizationResult(
                            optimization_type=OptimizationType.MEMORY,
                            name="ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠœë‹",
                            description="ë¹ˆë²ˆí•œ GC í˜¸ì¶œì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                            priority=OptimizationPriority.MEDIUM,
                            impact_score=40.0,
                            implementation_difficulty=2,
                            estimated_improvement="10-20% GC ì˜¤ë²„í—¤ë“œ ê°ì†Œ",
                            before_metrics=gc_stats,
                            recommendations=[
                                "gc.set_threshold() ì¡°ì •",
                                "ìˆœí™˜ ì°¸ì¡° ì œê±°",
                                "ì ì ˆí•œ ì‹œì ì— gc.collect() í˜¸ì¶œ",
                            ],
                            code_changes=[
                                {
                                    "file": "gc_optimization.py",
                                    "change": "\nimport gc\n\n# GC ì„ê³„ê°’ ì¡°ì • (ê¸°ë³¸ê°’ë³´ë‹¤ ëœ ê³µê²©ì )\ngc.set_threshold(1000, 15, 15)\n\n# ì¤‘ìš”í•œ ì‘ì—… ì „í›„ ëª…ì‹œì  GC\ndef heavy_processing():\n    gc.collect()  # ì²˜ë¦¬ ì „ ì •ë¦¬\n    try:\n        # ë¬´ê±°ìš´ ì‘ì—… ìˆ˜í–‰\n        result = expensive_computation()\n    finally:\n        gc.collect()  # ì²˜ë¦¬ í›„ ì •ë¦¬\n    return result\n",
                                }
                            ],
                        )
                    ]
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ë©”ëª¨ë¦¬ ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        return results

    async def _analyze_cpu_optimization(
        self, suite: OptimizationSuite
    ) -> List[OptimizationResult]:
        """CPU ìµœì í™” ë¶„ì„"""
        results = []
        try:
            if "cpu" in self.baseline_metrics:
                num_threads = self.baseline_metrics["cpu"]["num_threads"]
                if num_threads > 20:
                    results = results + [
                        OptimizationResult(
                            optimization_type=OptimizationType.CPU,
                            name="ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™”",
                            description=f"ê³¼ë„í•œ ìŠ¤ë ˆë“œ ìˆ˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({num_threads}ê°œ)",
                            priority=OptimizationPriority.HIGH,
                            impact_score=60.0,
                            implementation_difficulty=3,
                            estimated_improvement="20-40% CPU íš¨ìœ¨ì„± í–¥ìƒ",
                            before_metrics={"thread_count": num_threads},
                            recommendations=[
                                "ThreadPoolExecutor ì‚¬ìš©ìœ¼ë¡œ ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ",
                                "ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ìŠ¤ë ˆë“œ í•„ìš”ì„± ê°ì†Œ",
                                "ì—°ê²° í’€ë§ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì¬ì‚¬ìš©",
                            ],
                            code_changes=[
                                {
                                    "file": "thread_optimization.py",
                                    "change": "\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import lru_cache\n\n# Before: ë¬´ì œí•œ ìŠ¤ë ˆë“œ ìƒì„±\nimport threading\n\ndef process_data(data):\n    for item in data:\n        thread = threading.Thread(target=heavy_task, args=(item,))\n        thread.start()\n\n# After: ì œí•œëœ ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©\nMAX_WORKERS = min(32, (os.cpu_count() or 1) + 4)\n\nasync def process_data_optimized(data):\n    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n        loop = asyncio.get_event_loop()\n        tasks = [\n            loop.run_in_executor(executor, heavy_task, item)\n            for item in data\n        ]\n        return await asyncio.gather(*tasks)\n\n# LRU ìºì‹œë¡œ ì¤‘ë³µ ê³„ì‚° ë°©ì§€\n@lru_cache(maxsize=128)\ndef expensive_computation(param):\n    # ë¹„ìš©ì´ í° ê³„ì‚°\n    return result\n",
                                }
                            ],
                        )
                    ]
                results = results + [
                    OptimizationResult(
                        optimization_type=OptimizationType.CPU,
                        name="ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”",
                        description="ë™ê¸° I/O ì‘ì—…ì˜ ë¹„ë™ê¸° ì „í™˜ ê¸°íšŒ",
                        priority=OptimizationPriority.MEDIUM,
                        impact_score=50.0,
                        implementation_difficulty=4,
                        estimated_improvement="2-5ë°° ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ",
                        recommendations=[
                            "ë™ê¸° I/Oë¥¼ ë¹„ë™ê¸°ë¡œ ë³€í™˜",
                            "asyncio.gatherë¡œ ë³‘ë ¬ ì²˜ë¦¬",
                            "ì ì ˆí•œ await ì§€ì  ì„¤ì •",
                        ],
                        code_changes=[
                            {
                                "file": "async_optimization.py",
                                "change": "\nimport asyncio\nimport aiohttp\nimport aiofiles\n\n# Before: ë™ê¸° ì²˜ë¦¬\ndef fetch_data(urls):\n    results = []\n    for url in urls:\n        response = requests.get(url)\n        results = results + [response.json(])\n    return results\n\n# After: ë¹„ë™ê¸° ì²˜ë¦¬  \nasync def fetch_data_async(urls):\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_url(session, url) for url in urls]\n        return await asyncio.gather(*tasks)\n\nasync def fetch_url(session, url):\n    async with session.get(url) as response:\n        return await response.json()\n\n# Before: ë™ê¸° íŒŒì¼ ì²˜ë¦¬\ndef process_files(file_paths):\n    results = []\n    for path in file_paths:\n        with open(path, 'r') as f:\n            results = results + [f.read(])\n    return results\n\n# After: ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬\nasync def process_files_async(file_paths):\n    tasks = [read_file_async(path) for path in file_paths]\n    return await asyncio.gather(*tasks)\n\nasync def read_file_async(path):\n    async with aiofiles.open(path, 'r') as f:\n        return await f.read()\n",
                            }
                        ],
                    )
                ]
        except Exception as e:
            if console:
                console.print(f"âš ï¸  CPU ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        return results

    async def _analyze_io_optimization(
        self, suite: OptimizationSuite
    ) -> List[OptimizationResult]:
        """I/O ìµœì í™” ë¶„ì„"""
        results = []
        try:
            results = results + [
                OptimizationResult(
                    optimization_type=OptimizationType.IO,
                    name="íŒŒì¼ I/O ìµœì í™”",
                    description="íŒŒì¼ ì½ê¸°/ì“°ê¸° ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ",
                    priority=OptimizationPriority.MEDIUM,
                    impact_score=35.0,
                    implementation_difficulty=2,
                    estimated_improvement="50-100% íŒŒì¼ I/O ì†ë„ í–¥ìƒ",
                    recommendations=[
                        "ë²„í¼ë§ ì‚¬ìš©ìœ¼ë¡œ I/O í˜¸ì¶œ ìµœì†Œí™”",
                        "ëŒ€ìš©ëŸ‰ íŒŒì¼ì— mmap ì‚¬ìš©",
                        "ë°°ì¹˜ ì²˜ë¦¬ë¡œ I/O ì§‘ì•½ë„ ìµœì í™”",
                    ],
                    code_changes=[
                        {
                            "file": "io_optimization.py",
                            "change": "\nimport mmap\nimport os\nfrom pathlib import Path\n\n# Before: ì‘ì€ ì²­í¬ë¡œ íŒŒì¼ ì½ê¸°\ndef read_large_file_slow(file_path):\n    with open(file_path, 'r') as f:\n        lines = []\n        while True:\n            line = f.readline()\n            if not line:\n                break\n            lines = lines + [line.strip(])\n    return lines\n\n# After: ìµœì í™”ëœ íŒŒì¼ ì½ê¸°\ndef read_large_file_fast(file_path):\n    # mmap ì‚¬ìš© (ëŒ€ìš©ëŸ‰ íŒŒì¼)\n    if os.path.getsize(file_path) > 10 * 1024 * 1024:  # 10MB ì´ìƒ\n        with open(file_path, 'r') as f:\n            with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n                return mm.read().decode().splitlines()\n    else:\n        # ì‘ì€ íŒŒì¼ì€ í•œ ë²ˆì— ì½ê¸°\n        return Path(file_path).read_text().splitlines()\n\n# Before: ê°œë³„ íŒŒì¼ ì“°ê¸°\ndef write_files_slow(data_dict):\n    for filename, content in data_dict.items():\n        with open(filename, 'w') as f:\n            f.write(content)\n\n# After: ë°°ì¹˜ ì²˜ë¦¬\ndef write_files_fast(data_dict):\n    # ê°™ì€ ë””ë ‰í† ë¦¬ íŒŒì¼ë“¤ ê·¸ë£¹í™”\n    dir_groups = {}\n    for filename, content in data_dict.items():\n        dir_name = os.path.dirname(filename)\n        if dir_name not in dir_groups:\n            dir_groups[dir_name] = []\n        dir_groups[dir_name] = dirname(filename)\n        if dir_name not in dir_groups:\n            dir_groups[dir_name] = []\n        dir_groups[dir_name] + [(filename, content])\n    \n    # ë””ë ‰í† ë¦¬ë³„ ë°°ì¹˜ ì²˜ë¦¬\n    for dir_name, files in dir_groups.items():\n        os.makedirs(dir_name, exist_ok=True)\n        for filename, content in files:\n            with open(filename, 'w', buffering=8192) as f:\n                f.write(content)\n",
                        }
                    ],
                )
            ]
            results = results + [
                OptimizationResult(
                    optimization_type=OptimizationType.NETWORK,
                    name="ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìµœì í™”",
                    description="HTTP ì—°ê²° ë° ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ìµœì í™”",
                    priority=OptimizationPriority.HIGH,
                    impact_score=65.0,
                    implementation_difficulty=3,
                    estimated_improvement="3-10ë°° ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ í–¥ìƒ",
                    recommendations=[
                        "ì—°ê²° í’€ë§ìœ¼ë¡œ ì—°ê²° ì¬ì‚¬ìš©",
                        "ìš”ì²­ ë°°ì¹˜ ì²˜ë¦¬",
                        "ì ì ˆí•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •",
                        "ì••ì¶• ë° ìºì‹± í™œìš©",
                    ],
                    code_changes=[
                        {
                            "file": "network_optimization.py",
                            "change": "\nimport aiohttp\nimport asyncio\nfrom aiohttp import ClientTimeout, TCPConnector\n\n# ìµœì í™”ëœ HTTP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\nclass OptimizedHTTPClient:\n    def __init__(self):\n        # ì—°ê²° í’€ ì„¤ì •\n        connector = TCPConnector(\n            limit=100,  # ì´ ì—°ê²° ìˆ˜ ì œí•œ\n            limit_per_host=10,  # í˜¸ìŠ¤íŠ¸ë‹¹ ì—°ê²° ìˆ˜ ì œí•œ\n            ttl_dns_cache=300,  # DNS ìºì‹œ TTL\n            use_dns_cache=True,\n            keepalive_timeout=30,\n            enable_cleanup_closed=True\n        )\n        \n        # íƒ€ì„ì•„ì›ƒ ì„¤ì •\n        timeout = ClientTimeout(\n            total=30,  # ì´ ìš”ì²­ ì‹œê°„\n            connect=5,  # ì—°ê²° ì‹œê°„\n            sock_read=10  # ì†Œì¼“ ì½ê¸° ì‹œê°„\n        )\n        \n        self.session = aiohttp.ClientSession(\n            connector=connector,\n            timeout=timeout,\n            headers={'Accept-Encoding': 'gzip, deflate'}\n        )\n    \n    async def fetch_multiple(self, urls, batch_size=10):\n        \"\"\"ë°°ì¹˜ ë‹¨ìœ„ë¡œ URL ìš”ì²­\"\"\"\n        results = []\n        \n        for i in range(0, len(urls), batch_size):\n            batch = urls[i:i + batch_size]\n            batch_tasks = [self.fetch_url(url) for url in batch]\n            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n            results = gather(*batch_tasks, return_exceptions=True)\n            results + batch_results\n            \n            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°\n            if i + batch_size < len(urls):\n                await asyncio.sleep(0.1)\n        \n        return results\n    \n    async def fetch_url(self, url):\n        try:\n            async with self.session.get(url) as response:\n                return await response.json()\n        except Exception as e:\n            return {'error': str(e), 'url': url}\n    \n    async def close(self):\n        await self.session.close()\n",
                        }
                    ],
                )
            ]
        except Exception as e:
            if console:
                console.print(f"âš ï¸  I/O ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        return results

    async def _analyze_startup_optimization(
        self, suite: OptimizationSuite
    ) -> List[OptimizationResult]:
        """ì‹œì‘ ì‹œê°„ ìµœì í™” ë¶„ì„"""
        results = []
        try:
            if "startup" in self.baseline_metrics:
                import_time = self.baseline_metrics["startup"]["import_time"]
                if import_time > 0.5:
                    results = results + [
                        OptimizationResult(
                            optimization_type=OptimizationType.STARTUP,
                            name="ëª¨ë“ˆ ì„í¬íŠ¸ ìµœì í™”",
                            description=f"ëŠë¦° ëª¨ë“ˆ ì„í¬íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({import_time:.3f}ì´ˆ)",
                            priority=OptimizationPriority.HIGH,
                            impact_score=80.0,
                            implementation_difficulty=2,
                            estimated_improvement=f"50-70% ì‹œì‘ ì‹œê°„ ë‹¨ì¶• ({import_time * 0.3:.3f}ì´ˆ ëª©í‘œ)",
                            before_metrics={"import_time": import_time},
                            recommendations=[
                                "ì§€ì—° ì„í¬íŠ¸ (lazy import) ì‚¬ìš©",
                                "ë¶ˆí•„ìš”í•œ ì „ì—­ ì„í¬íŠ¸ ì œê±°",
                                "ì¡°ê±´ë¶€ ì„í¬íŠ¸ í™œìš©",
                                "ê°€ë²¼ìš´ ëŒ€ì•ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€í† ",
                            ],
                            code_changes=[
                                {
                                    "file": "lazy_import_optimization.py",
                                    "change": '\n# Before: ì „ì—­ì—ì„œ ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\n\ndef simple_function():\n    return "Hello"\n\n# After: ì§€ì—° ì„í¬íŠ¸ ì‚¬ìš©\ndef simple_function():\n    return "Hello"\n\ndef data_analysis_function(data):\n    # ì‹¤ì œ ì‚¬ìš©í•  ë•Œë§Œ ì„í¬íŠ¸\n    import pandas as pd\n    import numpy as np\n    \n    df = pd.DataFrame(data)\n    return df.mean()\n\ndef plotting_function(data):\n    # ì¡°ê±´ë¶€ ì„í¬íŠ¸\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        raise ImportError("matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")\n    \n    plt.plot(data)\n    return plt.gcf()\n\n# ì„ íƒì  ê¸°ëŠ¥ì„ ìœ„í•œ ì§€ì—° ë¡œë”©\nclass MachineLearningModule:\n    def __init__(self):\n        self._sklearn = None\n        self._tensorflow = None\n    \n    @property\n    def sklearn(self):\n        if self._sklearn is None:\n            import sklearn\n            self._sklearn = sklearn\n        return self._sklearn\n    \n    @property\n    def tensorflow(self):\n        if self._tensorflow is None:\n            import tensorflow as tf\n            self._tensorflow = tf\n        return self._tensorflow\n',
                                }
                            ],
                        )
                    ]
                results = results + [
                    OptimizationResult(
                        optimization_type=OptimizationType.STARTUP,
                        name="Cold Start ìµœì í™”",
                        description="Cloud Run Cold Start ì‹œê°„ ìµœì†Œí™”",
                        priority=OptimizationPriority.CRITICAL,
                        impact_score=90.0,
                        implementation_difficulty=3,
                        estimated_improvement="50-80% Cold Start ì‹œê°„ ë‹¨ì¶•",
                        recommendations=[
                            "ìµœì†Œí•œì˜ ì „ì—­ ì´ˆê¸°í™”",
                            "í•„ìš” ì‹œì ê¹Œì§€ ì—°ê²° ì§€ì—°",
                            "ì˜ˆì—´ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
                            "ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”",
                        ],
                        code_changes=[
                            {
                                "file": "cold_start_optimization.py",
                                "change": '\nimport os\nfrom functools import lru_cache\n\n# Before: ì‹œì‘ ì‹œ ëª¨ë“  ì—°ê²° ì´ˆê¸°í™”\ndatabase_connection = create_database_connection()\nredis_client = create_redis_client()\nexternal_api_client = create_api_client()\n\ndef handle_request(request):\n    # ìš”ì²­ ì²˜ë¦¬\n    pass\n\n# After: ì§€ì—° ì´ˆê¸°í™”\n_database_connection = None\n_redis_client = None\n_external_api_client = None\n\n@lru_cache(maxsize=1)\ndef get_database_connection():\n    global _database_connection\n    if _database_connection is None:\n        _database_connection = create_database_connection()\n    return _database_connection\n\n@lru_cache(maxsize=1)\ndef get_redis_client():\n    global _redis_client\n    if _redis_client is None:\n        _redis_client = create_redis_client()\n    return _redis_client\n\n@lru_cache(maxsize=1)\ndef get_api_client():\n    global _external_api_client\n    if _external_api_client is None:\n        _external_api_client = create_api_client()\n    return _external_api_client\n\ndef handle_request(request):\n    # í•„ìš”í•  ë•Œë§Œ ì—°ê²° ìƒì„±\n    db = get_database_connection()\n    # ìš”ì²­ ì²˜ë¦¬\n    pass\n\n# ì˜ˆì—´ ì—”ë“œí¬ì¸íŠ¸\ndef warmup():\n    """Cloud Run ì˜ˆì—´ìš© ì—”ë“œí¬ì¸íŠ¸"""\n    try:\n        # ì¤‘ìš”í•œ ì—°ê²°ë“¤ ë¯¸ë¦¬ ì´ˆê¸°í™”\n        get_database_connection()\n        get_redis_client()\n        return {"status": "warm"}\n    except Exception as e:\n        return {"status": "error", "message": str(e)}\n',
                            }
                        ],
                    )
                ]
        except Exception as e:
            if console:
                console.print(
                    f"âš ï¸  ì‹œì‘ ì‹œê°„ ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow"
                )
        return results

    async def _analyze_cloud_run_optimization(
        self, suite: OptimizationSuite
    ) -> List[OptimizationResult]:
        """Cloud Run ìµœì í™” ë¶„ì„"""
        results = []
        try:
            is_cloud_run = os.getenv("K_SERVICE") is not None
            results = results + [
                OptimizationResult(
                    optimization_type=OptimizationType.CLOUD_RUN,
                    name="Cloud Run ë¦¬ì†ŒìŠ¤ ìµœì í™”",
                    description="Cloud Run ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ìµœì í™”",
                    priority=OptimizationPriority.HIGH,
                    impact_score=75.0,
                    implementation_difficulty=3,
                    estimated_improvement="30-50% ë¦¬ì†ŒìŠ¤ ë¹„ìš© ì ˆì•½",
                    before_metrics={"is_cloud_run": is_cloud_run},
                    recommendations=[
                        "ì ì ˆí•œ CPU ë° ë©”ëª¨ë¦¬ í•œê³„ ì„¤ì •",
                        "ë™ì‹œì„± ì„¤ì • ìµœì í™”",
                        "ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°ì •",
                        "ìš”ì²­ íƒ€ì„ì•„ì›ƒ ìµœì í™”",
                    ],
                    code_changes=[
                        {
                            "file": "cloud_run_config.yaml",
                            "change": '\n# Cloud Run ì„œë¹„ìŠ¤ ì„¤ì • ìµœì í™”\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: rfs-app\n  annotations:\n    # ë™ì‹œì„± ì„¤ì • (ê¸°ë³¸ê°’: 100, ìµœì í™”: 1000)\n    run.googleapis.com/execution-environment: gen2\n    run.googleapis.com/cpu-throttling: "false"\nspec:\n  template:\n    metadata:\n      annotations:\n        # ë¦¬ì†ŒìŠ¤ ìµœì í™”\n        run.googleapis.com/memory: "512Mi"  # ë©”ëª¨ë¦¬ ì œí•œ\n        run.googleapis.com/cpu: "1000m"     # CPU ì œí•œ (1 vCPU)\n        \n        # ë™ì‹œì„± ë° í™•ì¥ ì„¤ì •\n        autoscaling.knative.dev/maxScale: "100"\n        autoscaling.knative.dev/minScale: "0"\n        run.googleapis.com/execution-environment: "gen2"\n        \n        # íƒ€ì„ì•„ì›ƒ ì„¤ì •\n        run.googleapis.com/timeout: "300s"\n        \n    spec:\n      containerConcurrency: 1000  # ì»¨í…Œì´ë„ˆë‹¹ ë™ì‹œ ìš”ì²­ ìˆ˜\n      timeoutSeconds: 300\n      containers:\n      - image: gcr.io/project/rfs-app\n        resources:\n          limits:\n            memory: "512Mi"\n            cpu: "1000m"\n        env:\n        - name: PYTHONUNBUFFERED\n          value: "1"\n        - name: PYTHONDONTWRITEBYTECODE\n          value: "1"\n        \n        # í—¬ìŠ¤ì²´í¬ ìµœì í™”\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 0\n          timeoutSeconds: 1\n          periodSeconds: 3\n          failureThreshold: 3\n        \n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 0\n          timeoutSeconds: 1\n          periodSeconds: 3\n          failureThreshold: 1\n',
                        },
                        {
                            "file": "cloud_run_optimization.py",
                            "change": '\nimport os\nimport logging\nfrom contextlib import asynccontextmanager\n\n# Cloud Run ìµœì í™” ì„¤ì •\nclass CloudRunOptimizer:\n    \n    @staticmethod\n    def configure_logging():\n        """Cloud Run ë¡œê¹… ìµœì í™”"""\n        logging.basicConfig(\n            level=logging.INFO,\n            format=\'%(asctime)s %(name)s %(levelname)s %(message)s\',\n            handlers=[logging.StreamHandler()]\n        )\n        \n        # Cloud Runì—ì„œëŠ” stdout/stderrê°€ ë¡œê·¸ë¡œ ìˆ˜ì§‘ë¨\n        if os.getenv(\'K_SERVICE\'):\n            # JSON ë¡œê¹… ì„¤ì •\n            import json\n            import sys\n            \n            class CloudRunFormatter(logging.Formatter):\n                def format(self, record):\n                    log_obj = {\n                        \'timestamp\': self.formatTime(record),\n                        \'severity\': record.levelname,\n                        \'message\': record.getMessage(),\n                        \'module\': record.name\n                    }\n                    return json.dumps(log_obj)\n            \n            handler = logging.StreamHandler(sys.stdout)\n            handler.setFormatter(CloudRunFormatter())\n            \n            root_logger = logging.getLogger()\n            root_logger.handlers = [handler]\n    \n    @staticmethod\n    def get_optimal_workers():\n        """ìµœì ì˜ worker ìˆ˜ ê³„ì‚°"""\n        cpu_count = os.cpu_count() or 1\n        \n        # Cloud Runì—ì„œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •\n        if os.getenv(\'K_SERVICE\'):\n            return min(cpu_count * 2, 4)\n        else:\n            return cpu_count * 2 + 1\n    \n    @staticmethod\n    @asynccontextmanager\n    async def lifespan_manager(app):\n        """ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ëª… ì£¼ê¸° ê´€ë¦¬"""\n        # ì‹œì‘ ì‹œ ì´ˆê¸°í™”\n        CloudRunOptimizer.configure_logging()\n        logger = logging.getLogger(__name__)\n        \n        logger.info("RFS v4 ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")\n        \n        # ì˜ˆì—´ ì‘ì—…\n        if os.getenv(\'K_SERVICE\'):\n            await CloudRunOptimizer.warmup_services()\n        \n        yield\n        \n        # ì¢…ë£Œ ì‹œ ì •ë¦¬\n        logger.info("RFS v4 ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ")\n        await CloudRunOptimizer.cleanup_services()\n    \n    @staticmethod\n    async def warmup_services():\n        """ì„œë¹„ìŠ¤ ì˜ˆì—´"""\n        try:\n            # ì¤‘ìš”í•œ ì—°ê²°ë“¤ ë¯¸ë¦¬ ì´ˆê¸°í™”\n            from rfs.cloud_run import initialize_cloud_run_services\n            await initialize_cloud_run_services()\n        except Exception as e:\n            logging.warning(f"ì„œë¹„ìŠ¤ ì˜ˆì—´ ì‹¤íŒ¨: {e}")\n    \n    @staticmethod\n    async def cleanup_services():\n        """ì„œë¹„ìŠ¤ ì •ë¦¬"""\n        try:\n            from rfs.cloud_run import shutdown_cloud_run_services\n            await shutdown_cloud_run_services()\n        except Exception as e:\n            logging.warning(f"ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")\n',
                        },
                    ],
                )
            ]
        except Exception as e:
            if console:
                console.print(
                    f"âš ï¸  Cloud Run ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow"
                )
        return results

    async def _apply_safe_optimizations(self, suite: OptimizationSuite):
        """ì•ˆì „í•œ ìµœì í™” ìë™ ì ìš©"""
        try:
            safe_optimizations = [
                opt
                for opt in self.optimization_results
                if opt.impact_score <= suite.max_impact_threshold
                and opt.implementation_difficulty <= 2
                and (
                    opt.priority
                    in [OptimizationPriority.LOW, OptimizationPriority.MEDIUM]
                )
            ]
            for optimization in safe_optimizations:
                try:
                    await asyncio.sleep(0.1)
                    optimization.applied = True
                    if console:
                        console.print(
                            f"âœ… ìë™ ì ìš©: {optimization.name}", style="green"
                        )
                except Exception as e:
                    if console:
                        console.print(
                            f"âŒ ìë™ ì ìš© ì‹¤íŒ¨ {optimization.name}: {str(e)}",
                            style="red",
                        )
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ìë™ ìµœì í™” ì ìš© ì‹¤íŒ¨: {str(e)}", style="yellow")

    async def _display_optimization_results(self):
        """ìµœì í™” ê²°ê³¼ í‘œì‹œ"""
        if not console or not self.optimization_results:
            return
        summary_table = Table(
            title="ìµœì í™” ë¶„ì„ ê²°ê³¼", show_header=True, header_style="bold magenta"
        )
        summary_table.add_column("ìš°ì„ ìˆœìœ„", style="cyan", width=10)
        summary_table.add_column("ìµœì í™” í•­ëª©", style="white", width=25)
        summary_table.add_column("ìœ í˜•", style="yellow", width=12)
        summary_table.add_column("ì˜í–¥ë„", justify="right", width=8)
        summary_table.add_column("ë‚œì´ë„", justify="right", width=8)
        summary_table.add_column("ROI", justify="right", width=10)
        summary_table.add_column("ìƒíƒœ", justify="center", width=8)
        for opt in self.optimization_results[:10]:
            priority_colors = {
                OptimizationPriority.CRITICAL: "bright_red",
                OptimizationPriority.HIGH: "red",
                OptimizationPriority.MEDIUM: "yellow",
                OptimizationPriority.LOW: "green",
            }
            priority_color = priority_colors.get(opt.priority, "white")
            roi_color = (
                "green"
                if opt.roi_score > 15
                else "yellow" if opt.roi_score > 8 else "red"
            )
            summary_table.add_row(
                f"[{priority_color}]{opt.priority.value.upper()}[/{priority_color}]",
                opt.name,
                opt.optimization_type.value,
                f"{opt.impact_score:.0f}%",
                f"{opt.implementation_difficulty}/5",
                f"[{roi_color}]{opt.roi_score:.1f}[/{roi_color}]",
                "âœ…" if opt.applied else "â³",
            )
        console.print(summary_table)
        if len(self.optimization_results) > 0:
            console.print("\nğŸ¯ ìš°ì„  ì ìš© ê¶Œì¥ ìµœì í™”:")
            for i, opt in enumerate(self.optimization_results[:3], 1):
                detail_panel = Panel(
                    f"**{opt.description}**\n\nì˜ˆìƒ ê°œì„ : {opt.estimated_improvement}\n\n**ê¶Œì¥ì‚¬í•­:**\n"
                    + "\n".join([f"â€¢ {rec}" for rec in opt.recommendations[:3]])
                    + (
                        f"\n\nâš¡ ì´ {len(opt.code_changes)}ê°œì˜ ì½”ë“œ ë³€ê²½ ì˜ˆì œ í¬í•¨"
                        if opt.code_changes
                        else ""
                    ),
                    title=f"{i}. {opt.name} (ì˜í–¥ë„: {opt.impact_score:.0f}%, ë‚œì´ë„: {opt.implementation_difficulty}/5)",
                    border_style="blue",
                )
                console.print(detail_panel)
        total_impact = sum((opt.impact_score for opt in self.optimization_results))
        applied_count = sum((1 for opt in self.optimization_results if opt.applied))
        console.print(
            Panel(
                f"ğŸ“Š ìµœì í™” ë¶„ì„ ì™„ë£Œ\n\nğŸ” ì‹ë³„ëœ ìµœì í™”: {len(self.optimization_results)}ê°œ\nâš¡ ìë™ ì ìš©: {applied_count}ê°œ\nğŸ“ˆ ì´ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {total_impact:.0f}%\nğŸ¯ ìµœê³  ROI: {max((opt.roi_score for opt in self.optimization_results)):.1f}"
                + (
                    f"\nğŸ† ê°€ì¥ íš¨ê³¼ì : {max(self.optimization_results, key=lambda x: x.roi_score).name}"
                    if self.optimization_results
                    else ""
                ),
                title="ìµœì í™” ìš”ì•½",
                border_style="green",
            )
        )

    async def start_performance_monitoring(
        self, interval: int = 60
    ) -> Result[str, str]:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        try:
            if self.monitoring_active:
                return Failure("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            self.monitoring_active = True
            self.monitoring_task = asyncio.create_task(
                self._performance_monitoring_loop(interval)
            )
            return Success("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
        except Exception as e:
            return Failure(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

    async def stop_performance_monitoring(self) -> Result[str, str]:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        try:
            self.monitoring_active = False
            if self.monitoring_task:
                self.monitoring_task.cancel()
                try:
                    await self.monitoring_task
                except asyncio.CancelledError:
                    pass
                self.monitoring_task = None
            return Success("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
        except Exception as e:
            return Failure(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì‹¤íŒ¨: {str(e)}")

    async def _performance_monitoring_loop(self, interval: int):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                await self._collect_performance_metrics()
                await asyncio.sleep(interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                if console:
                    console.print(f"âš ï¸  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}", style="yellow")
                await asyncio.sleep(interval)

    async def _collect_performance_metrics(self):
        """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        try:
            import os

            import psutil

            if psutil:
                process = psutil.Process(os.getpid())
                memory_info = process.memory_info()
                memory_percent = process.memory_percent()
                cpu_percent = process.cpu_percent()
                num_threads = process.num_threads()
            else:
                process = None
                memory_info = type("MemoryInfo", (), {"rss": 0})()
                memory_percent = 0
                cpu_percent = 0
                num_threads = threading.active_count()

            metrics = {
                "timestamp": datetime.now().isoformat(),
                "memory": {
                    "rss_mb": memory_info.rss / 1024 / 1024,
                    "percent": memory_percent,
                },
                "cpu": {"percent": cpu_percent},
                "threads": num_threads,
                "gc": {
                    "collections": [
                        (
                            gc.get_stats()[i]["collections"]
                            if i < len(gc.get_stats())
                            else 0
                        )
                        for i in range(3)
                    ]
                },
            }
            self.performance_history = self.performance_history + [metrics]
            if len(self.performance_history) > self.max_history_size:
                self.performance_history = self.performance_history[
                    -self.max_history_size :
                ]
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}", style="yellow")

    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        if not self.performance_history:
            return {}
        try:
            latest = self.performance_history[-1]
            recent_samples = self.performance_history[-10:]
            avg_memory = sum((m["memory"]["rss_mb"] for m in recent_samples)) / len(
                recent_samples
            )
            avg_cpu = sum((m["cpu"]["percent"] for m in recent_samples)) / len(
                recent_samples
            )
            return {
                "current": latest,
                "averages": {"memory_mb": avg_memory, "cpu_percent": avg_cpu},
                "optimization_count": len(self.optimization_results),
                "applied_optimizations": sum(
                    (1 for opt in self.optimization_results if opt.applied)
                ),
                "monitoring_active": self.monitoring_active,
                "history_size": len(self.performance_history),
            }
        except Exception as e:
            return {"error": str(e)}
