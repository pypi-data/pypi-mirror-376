Metadata-Version: 2.1
Name: dqu
Version: 0.2.4
Summary: Build intelligent, efficient, and trustable Data & ML Engineering Pipelines with this enterprise-ready Data Quality framework.
Author: Keshav Kant Singh
Author-email: Keshav Singh <masterkeshav@gmail.com>
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE

# DQU

**Build intelligent, efficient, and trustable Data & ML Engineering Pipelines with this enterprise-ready Data Quality framework**

<p align="center">
  <img width="200" alt="Dqu-Clean" src="https://github.com/user-attachments/assets/e5394d0b-dcb3-4f71-a280-d856ee550a97" />
</p>
---

## What is DQU?

DQU (Data QUality) is a unified framework that empowers data and machine learning developers to perform **automated data quality assessments** on **structured** or **semi-structured** data across modern distributed computing engines.

It supports:

- **Pandas** workflows
- **Apache Spark** for distributed batch/stream processing
- **Apache Flink** for stream processing
- **Ray Datasets** for distributed Python-native processing
- **Spark, Pandas, Ray** through a YAML config
- Supports YAML Driven Configuration
- Supports (Basic and Advanced Evals), Advanced emitts Error Records Dataframe along with eval results
- Supports Logging integrations with GCP Cloud Logging, Azure Log Analytics, Console Logs

DQU empowers working on Any cloud GCP, Azure (Microsoft Fabric, Azure Databricks, Azure Synapse) or AWS or local Jupyter Python environment, on any of these 4 engines (Pandas, Spark, Flink, Ray), DQU seamlessly integrates into your data & machine learning pipelines.

---

## GitHub

https://github.com/keshavksingh/dqu

---

## 📚 Table of Contents

- [What is DQU?](#what-is-dqu)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Requirements](#-requirements)
- [Available Checks](#available-checks)
- [Quick Start](#-quick-start)

  - [1. Using with Pandas](#1-using-with-pandas)
    - [1.1 Duplicate Check](#11-duplicate-check)
    - [1.2 Empty Check](#12-empty-check)
    - [1.3 Unique Check](#13-unique-check)
    - [1.4 Data Type Check](#14-data-type-check)
    - [1.5 String Format (Regex) Check](#15-string-format-regex-check)
    - [1.6 Schema Validation](#16-schema-validation)
    - [1.7 Range Check](#17-range-check)
    - [1.8 Categorical Values Check](#18-categorical-values-check)
    - [1.9 Statistical Distribution Check](#19-statistical-distribution-check)
    - [1.10 Label Balance Check](#110-label-balance-check)
    - [1.11 Data Freshness Check](#111-data-freshness-check)
    - [1.12 Referential Integrity Check](#112-referential-integrity-check)
    - [1.13 Row Count Check](#113-row-count-check)
    - [1.14 Custom Check](#114-custom-check---powerful)
  - [2. Using with Apache Spark](#2-using-with-apache-spark)
    - [2.1 Duplicate Check](#21-duplicate-check)
    - [2.2 Empty Check](#22-empty-check)
    - [2.3 Unique Check](#23-unique-check)
    - [2.4 Data Type Check](#24-data-type-check)
    - [2.5 String Format (Regex) Check](#25-string-format-regex-check)
    - [2.6 Schema Validation](#26-schema-validation)
    - [2.7 Range Check](#27-range-check)
    - [2.8 Categorical Values Check](#28-categorical-values-check)
    - [2.9 Statistical Distribution Check](#29-statistical-distribution-check)
    - [2.10 Label Balance Check](#210-label-balance-check)
    - [2.11 Data Freshness Check](#211-data-freshness-check)
    - [2.12 Referential Integrity Check](#212-referential-integrity-check)
    - [2.13 Row Count Check](#213-row-count-check)
    - [2.14 Custom Check](#214-custom-check---powerful)
  - [3. Using with Apache Flink](#3-using-with-apache-flink)
    - [3.1 Duplicate Check](#31-duplicate-check)
    - [3.2 Empty Check](#32-empty-check)
    - [3.3 Unique Check](#33-unique-check)
    - [3.4 Data Type Check](#34-data-type-check)
    - [3.5 String Format (Regex) Check](#35-string-format-regex-check)
    - [3.6 Schema Validation](#36-schema-validation)
    - [3.7 Range Check](#37-range-check)
    - [3.8 Categorical Values Check](#38-categorical-values-check)
    - [3.9 Statistical Distribution Check](#39-statistical-distribution-check)
    - [3.10 Data Freshness Check](#310-data-freshness-check)
    - [3.11 Referential Integrity Check](#311-referential-integrity-check)
    - [3.13 Row Count Check](#313-row-count-check)
    - [3.14 Custom Check](#314-custom-check---powerful)
  - [4. Using with Ray](#4-using-with-ray)
    - [4.1 Duplicate Check](#41-duplicate-check)
    - [4.2 Empty Check](#42-empty-check)
    - [4.3 Unique Check](#43-unique-check)
    - [4.4 Data Type Check](#44-data-type-check)
    - [4.5 String Format (Regex) Check](#45-string-format-regex-check)
    - [4.6 Schema Validation](#46-schema-validation)
    - [4.7 Range Check](#47-range-check)
    - [4.8 Categorical Values Check](#48-categorical-values-check)
    - [4.9 Statistical Distribution Check](#49-statistical-distribution-check)
    - [4.10 Label Balance Check](#410-label-balance-check)
    - [4.11 Data Freshness Check](#411-data-freshness-check)
    - [4.12 Referential Integrity Check](#412-referential-integrity-check)
    - [4.13 Row Count Check](#413-row-count-check)
    - [4.14 Custom Check](#414-custom-check---powerful)
  - [5. Yaml Config Driven Evaluation for Ray/Spark/Pandas](#5-yaml-config-driven-evaluation-for-sparkraypandas)
    - [API Run Checks from Yaml Config](#api-run_checks_from_yaml)
    - [Example for Ray](#example-yaml-config-dqu_ray_checkyml)
    - [Example for Pandas](#example-for-pandas-python)
    - [Example for PySpark](#example-for-spark-pyspark)
  - [Logging And Monitoring Integration](#-logging--monitoring-integration)
    - [How logging works](#how-logging-works)
    - [What Gets Logged](#what-gets-logged)
    - [Why use loggin?](#why-use-logging)

- [Notes](#-notes)
- [Contributing](#-contributing)
- [License](#-license)

---

## 🔑 Key Features

- ✅ **Multi-Engine Support**: Unified APIs for Pandas, Spark, Flink, and Ray
- 🔍 **Comprehensive Checks**:
  - Null / Empty Checks
  - Duplicate Checks
  - Uniqueness
  - Schema Validation
  - Range Checks
  - String Pattern Checks
  - Categorical Value Checks
  - Data Freshness
  - Referential Integrity
  - Statistical Distribution Checks
  - Custom/Advanced Validations (Powerful to apply any any custom-functions)
- 📊 **Detailed Reporting**:
  - Summary statistics
  - Row-level failed results (optional)
  - Timestamps and run IDs
- 🔌 **Enterprise-Ready**:
  - Designed for large-scale data pipelines
- 🧱 **Extensible**:
  - Easily add new custom rules or checks
  - Plug into existing pipeline frameworks
- 🐍 **Pythonic Interface**:
  - Works natively with Python, PySpark, PyFlink, and Ray APIs

---

## 📦 Installation

```bash
pip install dqu
```

For development:

```bash
git clone https://github.com/keshavksingh/dqu.git
cd dqu
pip install -e .
```

---

## 📋 Requirements

None, make sure the desired environment has in-built support for:

| Dependency   | Version   |
| ------------ | --------- |
| Python       | >= 3.7    |
| pandas       | >= 1.3.0  |
| pyspark      | >= 3.0.0  |
| apache-flink | >= 2.1.0  |
| ray          | >= 2.4.8  |
| scipy        | >= 1.16.1 |

---

## Available Checks

| Check Name               | Class Name                        | Description                                          |
| ------------------------ | --------------------------------- | ---------------------------------------------------- |
| Duplicate Check          | `DquDupCheck`                     | Detects duplicates based on columns                  |
| Empty/Null Check         | `DquEmptyCheck`                   | Checks for missing values                            |
| Uniqueness Check         | `DquUniqueCheck`                  | Ensures column uniqueness                            |
| Data Type Check          | `DquDtypeCheck`                   | Ensures column Data Type                             |
| Row Count Check          | `DquRowCountCheck`                | Row Count Check                                      |
| Range Check              | `DquRangeCheck`                   | Enforces min/max thresholds                          |
| String Format Check      | `DquStringFormatCheck`            | Validates string formats (e.g., email)               |
| Categorical Check        | `DquCategoricalValuesCheck`       | Checks values against an allowed set                 |
| Schema Check             | `DquSchemaValidationCheck`        | Verifies types for each column                       |
| Freshness Check          | `DquDataFreshnessCheck`           | Validates timestamp recency                          |
| Referential Integrity    | `DquReferentialIntegrityCheck`    | Cross-checks between datasets                        |
| Statistical Distribution | `DquStatisticalDistributionCheck` | Validates against mean/std expectations              |
| Custom Python Check      | `DquCustomCheck`                  | Run your own logic for validation (Column/Row) Level |

---

## 🚀 Quick Start

## 1. Using with **Pandas**

You can perform the following validation checks using `PandasEngine`:

### 1.1 Duplicate Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dup_check import DquDupCheck

data = {'id': [1, 2, 2, 4], 'name': ['Alice', 'Bob', 'Bob', 'Dave']}
df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquDupCheck(dqudf, config={"columns": ["id"]})
result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "duplicate_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-05T11:48:43.184619+00:00",
  "run_id": null
}
   id name
   2  Bob
   2  Bob
```

### 1.2 Empty Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.empty_check import DquEmptyCheck

data = {'id': [1, 2, 2, 4], 'name': ['', 'Bob', 'Bob', 'Dave']}
df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquEmptyCheck(dqudf, config={"columns": ["name"]}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "empty_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T14:12:27.419489+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
   id name
   1
```

### 1.3 Unique Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.unique_check import DquUniqueCheck

data = {'id': [1, 2, 2, 4], 'name': ['Daniel', 'Bob', 'Bob', 'Dave']}
df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquUniqueCheck(dqudf, config={"columns": ["id"]}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "unique_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-05T14:13:21.537525+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
   id name
   2  Bob
   2  Bob
```

### 1.4 Data Type Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dtype_check import DquDtypeCheck

data = {'id': [1, 2, 2, 4], 'name': ['Daniel', 'Bob', 'Bob', 'Dave']}
df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquDtypeCheck(dqudf, config={"columns": {"id": "int","name": "str"}}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Success",
  "dqu_check_type": "dtype_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-05T14:17:34.098679+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
Empty DataFrame
Columns: [id, name]
Index: []
```

### 1.5 String Format (Regex) Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.stringformat_check import DquStringFormatCheck

data = {
    'id': [1, 2, 3, 4, 5],
    'name': ['Daniel', 'Bob123', 'Alice!', 'Carol', 'Eve']
}
df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Check that 'name' column contains only alphabets (A-Z, a-z)
check = DquStringFormatCheck(
    dqudf,
    config={"column": "name", "pattern": r"^[A-Za-z]+$"},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)
result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "stringformat_check",
  "dqu_total_count": 5,
  "dqu_failed_count": 2,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T14:25:34.254124+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
   id    name
   2  Bob123
   3  Alice!
```

### 1.6 Schema Validation

```python
import pandas as pd
from datetime import datetime
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.schema_check import DquSchemaValidationCheck

data = {
    'id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': ['25', '30', '35'],  # age should be int, but it's string here
    'signup_date': ['2023-01-01', '2023-02-15', '2023-03-20']  # should be datetime
}

df = pd.DataFrame(data)
df['signup_date'] = pd.to_datetime(df['signup_date'])
dqudf = DquDataFrame(df)

expected_schema = {
    'id': 'int64',
    'name': 'object',
    'age': 'int64',  # this will fail as actual type is object (string)
    'signup_date': 'datetime64[ns]'  # this should pass
}

check = DquSchemaValidationCheck(
    dqudf,
    config={"expected_schema": expected_schema},
    run_id="a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Failed",
  "dqu_check_type": "schemavalidation_check",
  "missing_columns": [],
  "type_mismatches": {
    "age": {
      "expected": "int64",
      "actual": "object"
    }
  },
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T14:33:41.550181+00:00",
  "run_id": "a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
}
```

### 1.7 Range Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.range_check import DquRangeCheck
data = {
    'id': [1, 2, 3, 4],
    'name': ['Alice', 'Bob', 'Charlie', 'Daisy'],
    'age': [22, 17, 65, 80]  # 17 and 80 are outside the valid range
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquRangeCheck(
    dqudf,
    config={"column": "age", "min": 18, "max": 65},
    run_id="cb376a28-2652-4cb3-a41f-5ec9c0b93dc6"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "range_check",
  "column": "age",
  "range": {
    "min": 18,
    "max": 65
  },
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-05T14:37:09.446949+00:00",
  "run_id": "cb376a28-2652-4cb3-a41f-5ec9c0b93dc6"
}
   id   name  age
   2    Bob   17
   4  Daisy   80
```

### 1.8 Categorical Values Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.categoricalvalues_check import DquCategoricalValuesCheck

data = {
    'employee_id': [101, 102, 103, 104],
    'name': ['Alice', 'Bob', 'Charlie', 'Daisy'],
    'department': ['HR', 'Finance', 'Legal', 'Magic']  # 'Magic' is not allowed
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquCategoricalValuesCheck(
    dqudf,
    config={"column": "department", "allowed_values": ["HR", "Finance", "Legal", "Engineering"]},
    run_id="ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "categoricalvalues_check",
  "column": "department",
  "allowed_values": [
    "HR",
    "Finance",
    "Legal",
    "Engineering"
  ],
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T14:42:07.527741+00:00",
  "run_id": "ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
}
   employee_id   name department
          104  Daisy      Magic
```

### 1.9 Statistical Distribution Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

data = {
    'employee_id': [1, 2, 3, 4, 5],
    'salary': [70000, 72000, 71000, 69000, 130000]  # 130000 causes drift
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Reference stats represent expected distribution
reference_stats = {"mean": 70000, "std": 5000}

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "salary",
        "mode": "feature_drift",
        "reference_stats": reference_stats,
        "tolerance": 0.1  # 10% drift tolerance
    },
    run_id="2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "feature_drift",
  "column": "salary",
  "dqu_drift_mean": 12400.0,
  "dqu_drift_std": 21632.686683847725,
  "dqu_passed": false,
  "run_timestamp": "2025-08-05T14:45:31.369345+00:00",
  "run_id": "2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
}
```

### 1.10 Label Balance Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

# Imbalanced classification labels
data = {
    'id': [101, 102, 103, 104, 105, 106, 107, 108],
    'label': ['spam', 'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'ham']
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Success",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.75,
    "ham": 0.25
  },
  "dqu_passed": true,
  "run_timestamp": "2025-08-05T14:49:13.961807+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}


import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

# Extremely imbalanced classification labels
data = {
    'id': list(range(1, 21)),
    'label': ['spam'] * 19 + ['ham']  # 95% spam, 5% ham
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.95,
    "ham": 0.05
  },
  "dqu_passed": false,
  "run_timestamp": "2025-08-05T14:53:30.108379+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
```

### 1.11 Data Freshness Check

```python
import pandas as pd
from datetime import datetime, timedelta
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.datafreshness_check import DquDataFreshnessCheck

# Create a dataframe with timestamps (milliseconds since epoch)
now = datetime.utcnow()
data = {
    "id": [1, 2, 3, 4],
    "created_at": [now,now,now,now]
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

check = DquDataFreshnessCheck(
    dqudf,
    config={
        "column": "created_at",
        "freshness_threshold": "2d"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Success",
  "dqu_check_type": "datafreshness_check",
  "column": "created_at",
  "latest_timestamp": "2025-08-05 14:59:41.348080",
  "cutoff_timestamp": "2025-08-03 14:59:41.350868",
  "dqu_passed": true,
  "run_timestamp": "2025-08-05T14:59:41.350955+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
```

### 1.12 Referential Integrity Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

# Main DataFrame (e.g., transactions)
main_data = {
    "user_id": [101, 102, 103, 104],
    "amount": [50.0, 75.5, 23.0, 99.9]
}
main_df = pd.DataFrame(main_data)
dqu_main = DquDataFrame(main_df)

# Reference DataFrame (e.g., users table)
ref_data = {
    "id": [101, 102, 103, 104]  # All user_ids from main_df exist here
}
ref_df = pd.DataFrame(ref_data)
dqu_ref = DquDataFrame(ref_df)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Success",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-05T15:05:04.944163+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
Empty DataFrame
Columns: [user_id, amount]
Index: []

import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

# Main DataFrame (e.g., transactions)
main_data = {
    "user_id": [101, 102, 103, 104],
    "amount": [50.0, 75.5, 23.0, 99.9]
}
main_df = pd.DataFrame(main_data)
dqu_main = DquDataFrame(main_df)

# Reference DataFrame (e.g., users table)
ref_data = {
    "id": [101, 102, 103, 107]  # All user_ids from main_df exist here 107 doesn't
}
ref_df = pd.DataFrame(ref_data)
dqu_ref = DquDataFrame(ref_df)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T15:05:58.191848+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
   user_id  amount
      104    99.9
```

### 1.13 Row Count Check

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

data = {
    "id": [1, 2, 3, 4, 5],
    "name": ["Alice", "Bob", "Charlie", "David", "Eva"]
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Check that the row count is between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 3,
        "max": 10
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Success",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 3,
  "max_allowed": 10,
  "run_timestamp": "2025-08-05T15:11:19.547228+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

data = {
    "id": [1, 2, 3, 4, 5],
    "name": ["Alice", "Bob", "Charlie", "David", "Eva"]
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Check that the row count is between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 30,
        "max": 100
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result = check.run(evaluation="advanced")

print(result)

{
  "status": "Failed",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 30,
  "max_allowed": 100,
  "run_timestamp": "2025-08-05T15:12:09.836859+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
```

### 1.14 Custom Check - (\*\*Powerful)

```python
import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

data = {
    "id": [1, 2, 3, 4],
    "score": [85, 92, -10, 74]
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Run a custom check: score should be >= 0
check = DquCustomCheck(
    dqudf,
    config={
        "column": "score",
        "func": lambda x: x >= 0
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "custom_check_column",
  "column": "score",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-05T15:16:55.688547+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

import pandas as pd
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

data = {
    "id": [1, 2, 3, 4],
    "age": [25, 17, 35, 45],
    "country": ["US", "US", "CA", "IN"]
}

df = pd.DataFrame(data)
dqudf = DquDataFrame(df)

# Run a custom row-level check: age >= 18 and country is 'US'
check = DquCustomCheck(
    dqudf,
    config={
        "func": lambda row: row["age"] >= 18 and row["country"] == "US"
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "custom_check_row",
  "column": null,
  "dqu_total_count": 4,
  "dqu_failed_count": 3,
  "dqu_passed_count": 1,
  "run_timestamp": "2025-08-05T15:19:25.942403+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
   id  age country
   2   17      US
   3   35      CA
   4   45      IN
```

---

## 📌 Notes

- All checks support two `evaluation` modes: `"basic"` (summary JSON) and `"advanced"` (summary JSON + failed rows).
- Optiinally Ensure `run_id` is set for tracking results consistently across runs.

## 2. Using with **Apache Spark**

You can perform the following validation checks using `SparkEngine`:

### 2.1 Duplicate Check

```python
from pyspark.sql import SparkSession
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dup_check import DquDupCheck

spark = SparkSession.builder.appName("dqu-example").getOrCreate()
df = spark.createDataFrame([(1, "Alice"), (2, "Bob"), (2, "Bob"), (3, "Dave")], schema=["id", "name"])
dqudf = DquDataFrame(df)

check = DquDupCheck(dqudf, config={"columns": ["id"]}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "duplicate_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T04:58:52.096909+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
+---+----+-----+
| id|name|count|
+---+----+-----+
|  2| Bob|    2|
|  2| Bob|    2|
+---+----+-----+
```

### 2.2 Empty Check

```python
from pyspark.sql import SparkSession
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.empty_check import DquEmptyCheck

spark = SparkSession.builder.appName("dqu-example").getOrCreate()
df = spark.createDataFrame([(1, "A"), (None, "B")], schema=["id", "category"])
dqudf = DquDataFrame(df)
check = DquEmptyCheck(dqudf, config={"columns": ["id"]}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")

result, failed = check.run(evaluation="advanced")
print(result)
failed.show()

{
  "status": "Failed",
  "dqu_check_type": "empty_check",
  "dqu_total_count": 2,
  "dqu_failed_count": 1,
  "dqu_passed_count": 1,
  "run_timestamp": "2025-08-06T04:57:13.465760+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
+----+--------+
|  id|category|
+----+--------+
|NULL|       B|
+----+--------+
```

### 2.3 Unique Check

```python
from pyspark.sql import SparkSession
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.unique_check import DquUniqueCheck

spark = SparkSession.builder.appName("dqu-example").getOrCreate()
df = spark.createDataFrame([(1, "Daniel"),(2, "Bob"),(2, "Bob"),(3, "Dave")], schema=["id", "name"])
dqudf = DquDataFrame(df)

check = DquUniqueCheck(dqudf, config={"columns": ["id"]}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "unique_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T05:36:24.368083+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
+---+----+-----+
| id|name|count|
+---+----+-----+
|  2| Bob|    2|
|  2| Bob|    2|
+---+----+-----+
```

### 2.4 Data Type Check

```python
from pyspark.sql import SparkSession
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dtype_check import DquDtypeCheck

spark = SparkSession.builder.appName("dqu-example").getOrCreate()
df = spark.createDataFrame([(1, "Daniel"),(2, "Bob"),(2, "Bob"),(3, "Dave")], schema=["id", "name"])
dqudf = DquDataFrame(df)

check = DquDtypeCheck(dqudf, config={"columns": {"id": "int","name": "str"}}, run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28")
result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()

{
  "status": "Success",
  "dqu_check_type": "dtype_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-06T05:37:39.660593+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
+---+----+
| id|name|
+---+----+
+---+----+
```

### 2.5 String Format (Regex) Check

```python
from pyspark.sql import SparkSession
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.stringformat_check import DquStringFormatCheck

spark = SparkSession.builder.appName("dqu-example").getOrCreate()
df = spark.createDataFrame([(1, "Daniel"),(2, "Bob123"),(3, "Alice!"),(4, "Dave")], schema=["id", "name"])
dqudf = DquDataFrame(df)

# Check that 'name' column contains only alphabets (A-Z, a-z)
check = DquStringFormatCheck(
    dqudf,
    config={"column": "name", "pattern": r"^[A-Za-z]+$"},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)
result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()


{
  "status": "Failed",
  "dqu_check_type": "stringformat_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T05:38:48.615612+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
+---+------+
| id|  name|
+---+------+
|  2|Bob123|
|  3|Alice!|
+---+------+
```

### 2.6 Schema Validation

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType
from datetime import datetime
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.schema_check import DquSchemaValidationCheck

spark = SparkSession.builder.appName("DQU_SchemaValidation_Spark").getOrCreate()
data = [
    (1, "Alice", "25", datetime(2023, 1, 1)),
    (2, "Bob", "30", datetime(2023, 2, 15)),
    (3, "Charlie", "35", datetime(2023, 3, 20))
]

schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("name", StringType(), True),
    StructField("age", StringType(), True),  # Incorrect type (should be IntegerType)
    StructField("signup_date", TimestampType(), True)
])

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)

# Expected schema
expected_schema = {
    "id": "int",
    "name": "string",
    "age": "int",           # Intentional mismatch
    "signup_date": "timestamp"
}

check = DquSchemaValidationCheck(
    dqudf,
    config={"expected_schema": expected_schema},
    run_id="a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
)

result = check.run(evaluation="advanced")
print(result)


{
  "status": "Failed",
  "dqu_check_type": "schemavalidation_check",
  "missing_columns": [],
  "type_mismatches": {
    "age": {
      "expected": "int",
      "actual": "string"
    }
  },
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T05:45:01.127153+00:00",
  "run_id": "a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
}
```

### 2.7 Range Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.range_check import DquRangeCheck

spark = SparkSession.builder.appName("DQU_RangeCheck_Spark").getOrCreate()
data = [
    (1, 'Alice', 22),
    (2, 'Bob', 17),       # Out of range
    (3, 'Charlie', 65),
    (4, 'Daisy', 80)      # Out of range
]

schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("name", StringType(), True),
    StructField("age", IntegerType(), True)
])
df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)

# Run Range Check (valid age: 18 to 65)
check = DquRangeCheck(
    dqudf,
    config={"column": "age", "min": 18, "max": 65},
    run_id="cb376a28-2652-4cb3-a41f-5ec9c0b93dc6"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "range_check",
  "column": "age",
  "range": {
    "min": 18,
    "max": 65
  },
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T05:48:31.085152+00:00",
  "run_id": "cb376a28-2652-4cb3-a41f-5ec9c0b93dc6"
}
+---+-----+---+
| id| name|age|
+---+-----+---+
|  2|  Bob| 17|
|  4|Daisy| 80|
+---+-----+---+
```

### 2.8 Categorical Values Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.categoricalvalues_check import DquCategoricalValuesCheck

spark = SparkSession.builder.appName("DQU_CategoricalValuesCheck_Spark").getOrCreate()
data = [
    (101, 'Alice', 'HR'),
    (102, 'Bob', 'Finance'),
    (103, 'Charlie', 'Legal'),
    (104, 'Daisy', 'Magic')  # Invalid category
]

schema = StructType([
    StructField("employee_id", IntegerType(), True),
    StructField("name", StringType(), True),
    StructField("department", StringType(), True)
])

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)
check = DquCategoricalValuesCheck(
    dqudf,
    config={
        "column": "department",
        "allowed_values": ["HR", "Finance", "Legal", "Engineering"]
    },
    run_id="ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "categoricalvalues_check",
  "column": "department",
  "allowed_values": [
    "HR",
    "Finance",
    "Legal",
    "Engineering"
  ],
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T05:51:05.451955+00:00",
  "run_id": "ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
}
+-----------+-----+----------+
|employee_id| name|department|
+-----------+-----+----------+
|        104|Daisy|     Magic|
+-----------+-----+----------+

```

### 2.9 Statistical Distribution Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, FloatType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

spark = SparkSession.builder.appName("DQU_FeatureDriftCheck_Spark").getOrCreate()
data = [
    (1, 70000.0),
    (2, 72000.0),
    (3, 71000.0),
    (4, 69000.0),
    (5, 130000.0)  # drift
]

schema = StructType([
    StructField("employee_id", IntegerType(), True),
    StructField("salary", FloatType(), True)
])

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)

# Reference statistics and drift config
reference_stats = {"mean": 70000, "std": 5000}

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "salary",
        "mode": "feature_drift",
        "reference_stats": reference_stats,
        "tolerance": 0.1  # 10% tolerance
    },
    run_id="2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
)
result = check.run(evaluation="advanced")
print(result)


{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "feature_drift",
  "column": "salary",
  "dqu_drift_mean": 12400.0,
  "dqu_drift_std": 21632.686683847725,
  "dqu_passed": false,
  "run_timestamp": "2025-08-06T05:54:04.584192+00:00",
  "run_id": "2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
}
```

### 2.10 Label Balance Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

spark = SparkSession.builder.appName("DQU_LabelBalanceCheck_Spark").getOrCreate()

# Sample imbalanced label data
data = [
    (101, 'spam'),
    (102, 'spam'),
    (103, 'ham'),
    (104, 'spam'),
    (105, 'spam'),
    (106, 'spam'),
    (107, 'spam'),
    (108, 'ham')
]

schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("label", StringType(), True)
])

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)
check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Success",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.75,
    "ham": 0.25
  },
  "dqu_passed": true,
  "run_timestamp": "2025-08-06T05:57:09.014074+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}


from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

spark = SparkSession.builder.appName("DQU_LabelBalanceFail_Spark").getOrCreate()

# Prepare data (95% spam, 5% ham)
data = [(i, 'spam') for i in range(1, 20)] + [(20, 'ham')]

schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("label", StringType(), True)
])

df = spark.createDataFrame(data, schema=schema)
dqudf = DquDataFrame(df)
check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.95,
    "ham": 0.05
  },
  "dqu_passed": false,
  "run_timestamp": "2025-08-06T05:59:39.640529+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
```

### 2.11 Data Freshness Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import current_timestamp
from pyspark.sql.types import StructType, StructField, IntegerType, TimestampType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.datafreshness_check import DquDataFreshnessCheck


spark = SparkSession.builder.appName("DQU_DataFreshness_Spark").getOrCreate()
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("created_at", TimestampType(), True)
])
from datetime import datetime
now = datetime.utcnow()

data = [
    (1, now),
    (2, now),
    (3, now),
    (4, now)
]

df = spark.createDataFrame(data, schema=schema)
dqudf = DquDataFrame(df)

# Run freshness check (within last 2 days)
check = DquDataFreshnessCheck(
    dqudf,
    config={
        "column": "created_at",
        "freshness_threshold": "2d"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)


{
  "status": "Success",
  "dqu_check_type": "datafreshness_check",
  "column": "created_at",
  "latest_timestamp": "2025-08-06 06:02:02.786425",
  "cutoff_timestamp": "2025-08-04 06:02:03.106781",
  "dqu_passed": true,
  "run_timestamp": "2025-08-06T06:02:03.108243+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}

```

### 2.12 Referential Integrity Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

spark = SparkSession.builder.appName("DQU_ReferentialIntegrity_Spark").getOrCreate()

# Main DataFrame schema and data (e.g., transactions)
main_schema = StructType([
    StructField("user_id", IntegerType(), True),
    StructField("amount", DoubleType(), True)
])
main_data = [
    (101, 50.0),
    (102, 75.5),
    (103, 23.0),
    (104, 99.9)
]
main_df = spark.createDataFrame(main_data, schema=main_schema)
dqu_main = DquDataFrame(main_df)

# Reference DataFrame schema and data (e.g., user table)
ref_schema = StructType([
    StructField("id", IntegerType(), True)
])
ref_data = [
    (101,),
    (102,),
    (103,),
    (104,)
]
ref_df = spark.createDataFrame(ref_data, schema=ref_schema)
dqu_ref = DquDataFrame(ref_df)

# Perform the referential integrity check
check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()


{
  "status": "Success",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-06T06:06:06.016188+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
+-------+------+
|user_id|amount|
+-------+------+
+-------+------+

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

spark = SparkSession.builder.appName("DQU_ReferentialIntegrity_Spark").getOrCreate()

# Main DataFrame schema and data (e.g., transactions)
main_schema = StructType([
    StructField("user_id", IntegerType(), True),
    StructField("amount", DoubleType(), True)
])
main_data = [
    (101, 50.0),
    (102, 75.5),
    (103, 23.0),
    (104, 99.9)
]
main_df = spark.createDataFrame(main_data, schema=main_schema)
dqu_main = DquDataFrame(main_df)

# Reference DataFrame schema and data (e.g., user table)
ref_schema = StructType([
    StructField("id", IntegerType(), True)
])
ref_data = [
    (101,),
    (102,),
    (103,),
    (107,)
]
ref_df = spark.createDataFrame(ref_data, schema=ref_schema)
dqu_ref = DquDataFrame(ref_df)

# Perform the referential integrity check
check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T06:07:30.513938+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
+-------+------+
|user_id|amount|
+-------+------+
|    104|  99.9|
+-------+------+
```

### 2.13 Row Count Check

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

spark = SparkSession.builder.appName("DQU_RowCount_Spark").getOrCreate()
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("name", StringType(), True)
])
data = [
    (1, "Alice"),
    (2, "Bob"),
    (3, "Charlie"),
    (4, "David"),
    (5, "Eva")
]

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)
# Row count check between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 3,
        "max": 10
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result = check.run(evaluation="advanced")
print(result)

{
  "status": "Success",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 3,
  "max_allowed": 10,
  "run_timestamp": "2025-08-06T06:11:00.396034+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

spark = SparkSession.builder.appName("DQU_RowCount_Spark").getOrCreate()
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("name", StringType(), True)
])
data = [
    (1, "Alice"),
    (2, "Bob"),
    (3, "Charlie"),
    (4, "David"),
    (5, "Eva")
]

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)
# Row count check between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 30,
        "max": 100
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 30,
  "max_allowed": 100,
  "run_timestamp": "2025-08-06T06:12:04.183040+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
```

### 2.14 Custom Check - (\*\*Powerful)

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

spark = SparkSession.builder.appName("DQU_CustomCheck_Spark").getOrCreate()
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("score", IntegerType(), True)
])

data = [
    (1, 85),
    (2, 92),
    (3, -10),  # This should fail
    (4, 74)
]

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)

# Custom check: score must be >= 0
check = DquCustomCheck(
    dqudf,
    config={
        "column": "score",
        "func": lambda x: x >= 0
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()


{
  "status": "Failed",
  "dqu_check_type": "custom_check_column",
  "column": "score",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T06:15:05.861702+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
+---+-----+
| id|score|
+---+-----+
|  3|  -10|
+---+-----+

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

spark = SparkSession.builder.appName("DQU_CustomRowCheck_Spark").getOrCreate()
schema = StructType([
    StructField("id", IntegerType(), True),
    StructField("age", IntegerType(), True),
    StructField("country", StringType(), True)
])

data = [
    (1, 25, "US"),
    (2, 17, "US"),  # Fails: age < 18
    (3, 35, "CA"),  # Fails: country != US
    (4, 45, "IN")   # Fails: country != US
]

df = spark.createDataFrame(data, schema)
dqudf = DquDataFrame(df)

# Run custom row-level check: age >= 18 and country == 'US'
check = DquCustomCheck(
    dqudf,
    config={
        "func": lambda row: row["age"] >= 18 and row["country"] == "US"
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "custom_check_row",
  "column": null,
  "dqu_total_count": 4,
  "dqu_failed_count": 3,
  "dqu_passed_count": 1,
  "run_timestamp": "2025-08-06T06:17:47.610289+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
+---+---+-------+
| id|age|country|
+---+---+-------+
|  2| 17|     US|
|  3| 35|     CA|
|  4| 45|     IN|
+---+---+-------+
```

## 3. Using with **Apache Flink**

### 3.1 Duplicate Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dup_check import DquDupCheck
from datetime import datetime

def datetime_to_milliseconds(dt_obj):
    return int(dt_obj.timestamp() * 1000)

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, "Alice", 25, 90, "A", datetime_to_milliseconds(datetime(2023, 1, 1))),
    (2, "Bob", 30, 85, "B", datetime_to_milliseconds(datetime(2023, 1, 2))),
    (2, "Bob", 30, 85, "B", datetime_to_milliseconds(datetime(2023, 1, 2))),  # duplicate
    (4, "", 0, 70, "C", datetime_to_milliseconds(datetime(2023, 1, 3))),
]

columns = ["id", "name", "age", "score", "category", "date"]
type_info = Types.ROW([
    Types.INT(),     # id
    Types.STRING(),  # name
    Types.INT(),     # age
    Types.INT(),     # score
    Types.STRING(),  # category
    Types.LONG()     # date (timestamp in ms)
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquDupCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")

print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "duplicate_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T14:55:39.573457+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
[{'id': 2, 'name': 'Bob', 'age': 30, 'score': 85, 'category': 'B', 'date': 1672646400000},
{'id': 2, 'name': 'Bob', 'age': 30, 'score': 85, 'category': 'B', 'date': 1672646400000}]
```

### 3.2 Empty Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.empty_check import DquEmptyCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (1, "A"),
    (None, "B"),  # This should fail the empty check
    (3, "C")
]
columns = ["id", "category"]
type_info = Types.ROW([
    Types.INT(),      # id
    Types.STRING()    # category
])
ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquEmptyCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "empty_check",
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T15:21:28.233722+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
[{'id': None, 'category': 'B'}]
```

### 3.3 Unique Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.unique_check import DquUniqueCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (1, "Daniel"),
    (2, "Bob"),
    (2, "Bob"),  # Duplicate ID
    (3, "Dave")
]

columns = ["id", "name"]
type_info = Types.ROW([
    Types.INT(),      # id
    Types.STRING()    # name
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquUniqueCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "unique_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T18:29:27.870546+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
[{'id': 2, 'name': 'Bob'}, {'id': 2, 'name': 'Bob'}]
```

### 3.4 Data Type Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dtype_check import DquDtypeCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, "Daniel"),
    (2, "Bob"),
    (2, "Bob"),
    (3, "Dave")
]

columns = ["id", "name"]
type_info = Types.ROW([
    Types.INT(),      # id
    Types.STRING()    # name
])
ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
expected_types = {
    "id": "int",
    "name": "int"
}

check = DquDtypeCheck(
    dqudf,
    config={"columns": expected_types},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)
{
  "status": "Success",
  "dqu_check_type": "dtype_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-07T08:01:24.408889+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
[]
```

### 3.5 String Format (Regex) Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.stringformat_check import DquStringFormatCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, "Daniel"),     # valid
    (2, "Bob123"),     # X has digits
    (3, "Alice!"),     # X has special char
    (4, "Dave")        # valid
]

columns = ["id", "name"]
type_info = Types.ROW([
    Types.INT(),      # id
    Types.STRING()    # name
])
ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquStringFormatCheck(
    dqudf,
    config={
        "column": "name",
        "pattern": r"^[A-Za-z]+$"  # only letters allowed
    },
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "stringformat_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-07T08:19:39.851987+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
[{'name': 'Bob123'}, {'name': 'Alice!'}]
```

### 3.6 Schema Validation

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.schema_check import DquSchemaValidationCheck
import datetime

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (1, "Alice", "25", int(datetime.datetime(2023, 1, 1).timestamp())),
    (2, "Bob", "30", int(datetime.datetime(2023, 2, 15).timestamp())),
    (3, "Charlie", "35", int(datetime.datetime(2023, 3, 20).timestamp()))
]

columns = ["id", "name", "age", "signup_date"]
type_info = Types.ROW([
    Types.INT(),        # id
    Types.STRING(),     # name
    Types.STRING(),     # age (should be INT based on expected schema – mismatch)
    Types.LONG()        # signup_date as UNIX timestamp (to simulate timestamp[s])
])
ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
expected_schema = {
    "id": "int",
    "name": "str",
    "age": "int",              # ← Mismatch on purpose: actual is string
    "signup_date": "timestamp[s]"
}
check = DquSchemaValidationCheck(
    dqudf,
    config={"expected_schema": expected_schema},
    run_id="a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "schemavalidation_check",
  "missing_columns": [],
  "type_mismatches": {
    "age": {
      "expected": "int",
      "actual": "str"
    },
    "signup_date": {
      "expected": "timestamp[s]",
      "actual": "int"
    }
  },
  "dqu_total_count": 3,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-07T08:28:56.920800+00:00",
  "run_id": "a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
}
```

### 3.7 Range Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.range_check import DquRangeCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [(25,), (50,), (200,)]
columns = ["temperature"]
type_info = Types.ROW([Types.INT()])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)

check = DquRangeCheck(
    dqudf,
    config={"column": "temperature", "min": 10, "max": 100},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed = check.run(evaluation="advanced")
print(result)
print(failed)

{
  "status": "Failed",
  "dqu_check_type": "range_check",
  "column": "temperature",
  "range": {
    "min": 10,
    "max": 100
  },
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-07T07:16:20.356526+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}

[{'temperature': 200}]
```

### 3.8 Categorical Values Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.categoricalvalues_check import DquCategoricalValuesCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (101, "Alice", "HR"),
    (102, "Bob", "Finance"),
    (103, "Charlie", "Legal"),
    (104, "Daisy", "Magic")  # Invalid value
]

columns = ["employee_id", "name", "department"]
type_info = Types.ROW([
    Types.INT(),        # employee_id
    Types.STRING(),     # name
    Types.STRING()      # department
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquCategoricalValuesCheck(
    dqudf,
    config={
        "column": "department",
        "allowed_values": ["HR", "Finance", "Legal", "Engineering"]
    },
    run_id="ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "categoricalvalues_check",
  "allowed_values": [
    "HR",
    "Finance",
    "Legal",
    "Engineering"
  ],
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-07T08:47:30.719103+00:00",
  "run_id": "ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
}
[{'employee_id': 104, 'name': 'Daisy', 'department': 'Magic'}]
```

### 3.9 Statistical Distribution Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, 70000.0),
    (2, 72000.0),
    (3, 71000.0),
    (4, 69000.0),
    (5, 130000.0)  # drifted
]

columns = ["employee_id", "salary"]
type_info = Types.ROW([
    Types.INT(),      # employee_id
    Types.FLOAT()     # salary
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
reference_stats = {
    "mean": 70000,
    "std": 5000
}

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "salary",
        "mode": "feature_drift",
        "reference_stats": reference_stats,
        "tolerance": 0.1  # 10% deviation allowed
    },
    run_id="2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
)

result = check.run(evaluation="advanced")
print(result)
{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "feature_drift",
  "column": "salary",
  "dqu_drift_mean": 12400.0,
  "dqu_drift_std": 18820.999139414787,
  "dqu_passed": false,
  "run_timestamp": "2025-08-07T09:16:26.464362+00:00",
  "run_id": "2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
}
```

### 3.10 Data Freshness Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from datetime import datetime, timedelta
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.datafreshness_check import DquDataFreshnessCheck

def datetime_to_milliseconds(dt_obj):
    return int(dt_obj.timestamp() * 1000)

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

now = datetime.utcnow()
past_time = now + timedelta(days=-3)
timestamp_ms = datetime_to_milliseconds(past_time)

data = [
    (1, timestamp_ms),
    (2, timestamp_ms),
    (3, timestamp_ms),
    (4, timestamp_ms)
]

columns = ["id", "created_at"]
type_info = Types.ROW([
    Types.INT(),     # id
    Types.LONG()     # created_at (epoch milliseconds)
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquDataFreshnessCheck(
    dqudf,
    config={
        "column": "created_at",
        "freshness_threshold": "2d"  # Accepts 'd' (days), 'h' (hours), 'm' (minutes)
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "datafreshness_check",
  "column": "created_at",
  "latest_timestamp": "2025-08-04T17:13:29.502000+00:00",
  "cutoff_timestamp": "2025-08-05T10:13:39.074587+00:00",
  "dqu_passed": false,
  "run_timestamp": "2025-08-07T10:13:39.076587+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}

```

### 3.11 Referential Integrity Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

# Main dataset (e.g., transactions)
main_data = [
    (101, 50.0),
    (102, 75.5),
    (103, 23.0),
    (104, 99.9),
]
main_columns = ["user_id", "amount"]
main_type_info = Types.ROW([Types.INT(), Types.FLOAT()])
main_ds = env.from_collection(main_data, type_info=main_type_info)
dqu_main = DquDataFrame(main_ds, columns=main_columns)

# 3. Reference dataset (e.g., users)
ref_data = [
    (101,),
    (102,),
    (103,),
    (104,),
]
ref_columns = ["id"]
ref_type_info = Types.ROW([Types.INT()])
ref_ds = env.from_collection(ref_data, type_info=ref_type_info)
dqu_ref = DquDataFrame(ref_ds, columns=ref_columns)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)
{
  "status": "Success",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-07T10:28:17.331309+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
[]

from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

# Main dataset (e.g., transactions)
main_data = [
    (101, 50.0),
    (102, 75.5),
    (103, 23.0),
    (104, 99.9),
]
main_columns = ["user_id", "amount"]
main_type_info = Types.ROW([Types.INT(), Types.FLOAT()])
main_ds = env.from_collection(main_data, type_info=main_type_info)
dqu_main = DquDataFrame(main_ds, columns=main_columns)

# 3. Reference dataset (e.g., users)
ref_data = [
    (101,),
    (102,),
    (103,),
    (107,),
]
ref_columns = ["id"]
ref_type_info = Types.ROW([Types.INT()])
ref_ds = env.from_collection(ref_data, type_info=ref_type_info)
dqu_ref = DquDataFrame(ref_ds, columns=ref_columns)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)
{
  "status": "Failed",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-07T10:34:10.810179+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
[{'user_id': 104, 'amount': 99.9}]
```

### 3.13 Row Count Check

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, "Alice"),
    (2, "Bob"),
    (3, "Charlie"),
    (4, "David"),
    (5, "Eva")
]

columns = ["id", "name"]
type_info = Types.ROW([
    Types.INT(),         # id
    Types.STRING()       # name
])

ds = env.from_collection(collection=data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 3,
        "max": 10
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result = check.run(evaluation="advanced")
print(result)
{
  "status": "Success",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 3,
  "max_allowed": 10,
  "run_timestamp": "2025-08-07T10:45:34.020306+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)

data = [
    (1, "Alice"),
    (2, "Bob"),
    (3, "Charlie"),
    (4, "David"),
    (5, "Eva")
]

columns = ["id", "name"]
type_info = Types.ROW([
    Types.INT(),         # id
    Types.STRING()       # name
])

ds = env.from_collection(collection=data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 2,
        "max": 4
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 2,
  "max_allowed": 4,
  "run_timestamp": "2025-08-07T10:47:51.442916+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
```

### 3.14 Custom Check - (Powerful)

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (1, 85),
    (2, 92),
    (3, -10),  # Should fail
    (4, 74)
]

columns = ["id", "score"]
type_info = Types.ROW([
    Types.INT(),  # id
    Types.INT()   # score
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquCustomCheck(
    dqudf,
    config={
        "column": "score",
        "func": lambda x: x >= 0
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "custom_check_column",
  "column": "score",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-07T11:00:43.159591+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
[{'id': 3, 'score': -10}]

from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck

env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(1)
data = [
    (1, 25, "US"),
    (2, 17, "US"),   # Fails: age < 18
    (3, 35, "CA"),   # Fails: country != US
    (4, 45, "IN")    # Fails: country != US
]

columns = ["id", "age", "country"]
type_info = Types.ROW([
    Types.INT(),  # id
    Types.INT(),   # score
    Types.STRING()  # country
])

ds = env.from_collection(data, type_info=type_info)
dqudf = DquDataFrame(ds, columns=columns)
check = DquCustomCheck(
    dqudf,
    config={
        "func": lambda row: row["age"] >= 18 and row["country"] == "US"
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
print(failed_rows)

{
  "status": "Failed",
  "dqu_check_type": "custom_check_row",
  "column": null,
  "dqu_total_count": 4,
  "dqu_failed_count": 3,
  "dqu_passed_count": 1,
  "run_timestamp": "2025-08-07T11:12:26.755124+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
[{'id': 2, 'age': 17, 'country': 'US'},
{'id': 3, 'age': 35, 'country': 'CA'},
{'id': 4, 'age': 45, 'country': 'IN'}]
```

## 4. Using with **Ray**

### 4.1 Duplicate Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dup_check import DquDupCheck
from datetime import datetime

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Alice", "age": 25, "score": 90, "category": "A", "date": datetime(2023, 1, 1)},
    {"id": 2, "name": "Bob", "age": 30, "score": 85, "category": "B", "date": datetime(2023, 1, 2)},
    {"id": 2, "name": "Bob", "age": 30, "score": 85, "category": "B", "date": datetime(2023, 1, 2)},  # duplicate
    {"id": 4, "name": "", "age": 0, "score": 70, "category": "C", "date": datetime(2023, 1, 3)},
]
ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)
check = DquDupCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)
{
  "status": "Failed",
  "dqu_check_type": "duplicate_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T07:20:17.121157+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
{'id': 2, 'name': 'Bob', 'age': 30, 'score': 85, 'category': 'B', 'date': datetime.datetime(2023, 1, 2, 0, 0)}
{'id': 2, 'name': 'Bob', 'age': 30, 'score': 85, 'category': 'B', 'date': datetime.datetime(2023, 1, 2, 0, 0)}
```

### 4.2 Empty Check

```python
import ray
from datetime import datetime
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.empty_check import DquEmptyCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "category": "A"},
    {"id": None, "category": "B"},
    {"id": 3, "category": "C"},
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

check = DquEmptyCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)


{
  "status": "Failed",
  "dqu_check_type": "empty_check",
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T07:44:47.722066+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
{'id': None, 'category': 'B'}
```

### 4.3 Unique Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.unique_check import DquUniqueCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Daniel"},
    {"id": 2, "name": "Bob"},
    {"id": 2, "name": "Bob"},  # Duplicate ID
    {"id": 3, "name": "Dave"},
]
ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)
check = DquUniqueCheck(
    dqudf,
    config={"columns": ["id"]},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)

{
  "status": "Failed",
  "dqu_check_type": "unique_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T08:13:09.995801+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
{'id': 2, 'name': 'Bob'}
{'id': 2, 'name': 'Bob'}
```

### 4.4 Data Type Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.dtype_check import DquDtypeCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Daniel"},
    {"id": 2, "name": "Bob"},
    {"id": 2, "name": "Bob"},
    {"id": 3, "name": "Dave"},
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

expected_types = {
    "id": "int",
    "name": "str"
}

check = DquDtypeCheck(
    dqudf,
    config={"columns": expected_types},
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)
{
  "status": "Success",
  "dqu_check_type": "dtype_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-06T08:23:47.847007+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
```

### 4.5 String Format (Regex) Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.stringformat_check import DquStringFormatCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Daniel"},
    {"id": 2, "name": "Bob123"},
    {"id": 3, "name": "Alice!"},
    {"id": 4, "name": "Dave"},
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)
check = DquStringFormatCheck(
    dqudf,
    config={
        "column": "name",
        "pattern": r"^[A-Za-z]+$"  # regex for alphabets only
    },
    run_id="fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)

{
  "status": "Failed",
  "dqu_check_type": "stringformat_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T08:28:23.087727+00:00",
  "run_id": "fe6e3991-6e3f-4f53-83cc-b8399bc8fc28"
}
{'id': 2, 'name': 'Bob123'}
{'id': 3, 'name': 'Alice!'}
```

### 4.6 Schema Validation

```python
import ray
from datetime import datetime
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.schema_check import DquSchemaValidationCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Alice", "age": "25", "signup_date": datetime(2023, 1, 1)},
    {"id": 2, "name": "Bob", "age": "30", "signup_date": datetime(2023, 2, 15)},
    {"id": 3, "name": "Charlie", "age": "35", "signup_date": datetime(2023, 3, 20)}
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)
expected_schema = {
    "id": "int64",
    "name": "string",
    "age": "int64",           # Mismatch here
    "signup_date": "timestamp[s]"
}

check = DquSchemaValidationCheck(
    dqudf,
    config={"expected_schema": expected_schema},
    run_id="a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "schemavalidation_check",
  "missing_columns": [],
  "type_mismatches": {
    "age": {
      "expected": "int64",
      "actual": "string"
    }
  },
  "dqu_total_count": 3,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T08:47:54.875097+00:00",
  "run_id": "a45b0020-f5b0-4a59-b418-0d9f7c3700a6"
}
```

### 4.7 Range Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.range_check import DquRangeCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "name": "Alice", "age": 22},
    {"id": 2, "name": "Bob", "age": 17},        # Out of range
    {"id": 3, "name": "Charlie", "age": 65},
    {"id": 4, "name": "Daisy", "age": 80}       # Out of range
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

check = DquRangeCheck(
    dqudf,
    config={"column": "age", "min": 18, "max": 65},
    run_id="cb376a28-2652-4cb3-a41f-5ec9c0b93dc6"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)

{
  "status": "Failed",
  "dqu_check_type": "range_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 2,
  "dqu_passed_count": 2,
  "run_timestamp": "2025-08-06T08:52:11.778664+00:00",
  "run_id": "cb376a28-2652-4cb3-a41f-5ec9c0b93dc6",
  "column": "age",
  "range": {
    "min": 18,
    "max": 65
  }
}
{'id': 2, 'name': 'Bob', 'age': 17}
{'id': 4, 'name': 'Daisy', 'age': 80}
```

### 4.8 Categorical Values Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.categoricalvalues_check import DquCategoricalValuesCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

# Sample data with one invalid department ("Magic")
data = [
    {"employee_id": 101, "name": "Alice", "department": "HR"},
    {"employee_id": 102, "name": "Bob", "department": "Finance"},
    {"employee_id": 103, "name": "Charlie", "department": "Legal"},
    {"employee_id": 104, "name": "Daisy", "department": "Magic"}  # Invalid
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

check = DquCategoricalValuesCheck(
    dqudf,
    config={
        "column": "department",
        "allowed_values": ["HR", "Finance", "Legal", "Engineering"]
    },
    run_id="ec5f4c82-d7a4-43de-9ff5-c18186a684f2"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)


{
  "status": "Failed",
  "dqu_check_type": "categoricalvalues_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T08:56:03.649586+00:00",
  "run_id": "ec5f4c82-d7a4-43de-9ff5-c18186a684f2",
  "allowed_values": [
    "HR",
    "Finance",
    "Legal",
    "Engineering"
  ]
}
{'employee_id': 104, 'name': 'Daisy', 'department': 'Magic'}
```

### 4.9 Statistical Distribution Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"employee_id": 1, "salary": 70000.0},
    {"employee_id": 2, "salary": 72000.0},
    {"employee_id": 3, "salary": 71000.0},
    {"employee_id": 4, "salary": 69000.0},
    {"employee_id": 5, "salary": 130000.0}  # drifted
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)
reference_stats = {
    "mean": 70000,
    "std": 5000
}

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "salary",
        "mode": "feature_drift",
        "reference_stats": reference_stats,
        "tolerance": 0.1  # Allow 10% deviation
    },
    run_id="2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "feature_drift",
  "column": "salary",
  "dqu_drift_mean": 12400.0,
  "dqu_drift_std": 21632.686683847725,
  "dqu_passed": false,
  "run_timestamp": "2025-08-06T09:01:14.122572+00:00",
  "run_id": "2a9b9370-2b7f-4d01-bd87-57b4c11c86be"
}
```

### 4.10 Label Balance Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 101, "label": "spam"},
    {"id": 102, "label": "spam"},
    {"id": 103, "label": "ham"},
    {"id": 104, "label": "spam"},
    {"id": 105, "label": "spam"},
    {"id": 106, "label": "spam"},
    {"id": 107, "label": "spam"},
    {"id": 108, "label": "ham"},
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)
{
  "status": "Success",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.75,
    "ham": 0.25
  },
  "dqu_passed": true,
  "run_timestamp": "2025-08-06T09:03:54.737445+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}

import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.statisticaldistribution_check import DquStatisticalDistributionCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

# imbalanced data (95% spam, 5% ham)
data = [{"id": i, "label": "spam"} for i in range(1, 20)] + [{"id": 20, "label": "ham"}]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

check = DquStatisticalDistributionCheck(
    dqudf,
    config={
        "column": "label",
        "mode": "label_balance"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "statisticaldistribution_check",
  "mode": "label_balance",
  "column": "label",
  "dqu_distribution": {
    "spam": 0.95,
    "ham": 0.05
  },
  "dqu_passed": false,
  "run_timestamp": "2025-08-06T09:28:15.245057+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
```

### 4.11 Data Freshness Check

```python
import ray
from datetime import datetime
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.datafreshness_check import DquDataFreshnessCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

now = datetime.utcnow()
data = [
    {"id": 1, "created_at": now},
    {"id": 2, "created_at": now},
    {"id": 3, "created_at": now},
    {"id": 4, "created_at": now}
]

ds = ray.data.from_items(data)
dqudf = DquDataFrame(ds)

# Run data freshness check with 2-day threshold
check = DquDataFreshnessCheck(
    dqudf,
    config={
        "column": "created_at",
        "freshness_threshold": "2d"  # 'd' for days, 'h' for hours, 'm' for minutes
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result = check.run(evaluation="advanced")
print(result)
{
  "status": "Success",
  "dqu_check_type": "datafreshness_check",
  "column": "created_at",
  "latest_timestamp": "2025-08-06 09:30:41.736244",
  "cutoff_timestamp": "2025-08-04 02:30:46.178669",
  "dqu_passed": true,
  "run_timestamp": "2025-08-06T09:30:46.183765+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}

```

### 4.12 Referential Integrity Check

```python
import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

# Main Ray Dataset (e.g., transactions)
main_data = [
    {"user_id": 101, "amount": 50.0},
    {"user_id": 102, "amount": 75.5},
    {"user_id": 103, "amount": 23.0},
    {"user_id": 104, "amount": 99.9}
]
main_ds = ray.data.from_items(main_data)
dqu_main = DquDataFrame(main_ds)

# Reference Ray Dataset (e.g., users)
ref_data = [
    {"id": 101},
    {"id": 102},
    {"id": 103},
    {"id": 104}
]
ref_ds = ray.data.from_items(ref_data)
dqu_ref = DquDataFrame(ref_ds)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)

{
  "status": "Success",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 0,
  "dqu_passed_count": 4,
  "run_timestamp": "2025-08-06T10:34:51.400277+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}

import ray
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.referential_integrity_check import DquReferentialIntegrityCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

# Main Ray Dataset (e.g., transactions)
main_data = [
    {"user_id": 101, "amount": 50.0},
    {"user_id": 102, "amount": 75.5},
    {"user_id": 103, "amount": 23.0},
    {"user_id": 104, "amount": 99.9}
]
main_ds = ray.data.from_items(main_data)
dqu_main = DquDataFrame(main_ds)

# Reference Ray Dataset (e.g., users)
ref_data = [
    {"id": 101},
    {"id": 102},
    {"id": 103},
    {"id": 107}
]
ref_ds = ray.data.from_items(ref_data)
dqu_ref = DquDataFrame(ref_ds)

check = DquReferentialIntegrityCheck(
    dqu_main,
    config={
        "column": "user_id",
        "reference_df": dqu_ref.df,
        "reference_column": "id"
    },
    run_id="c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
)

result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show(limit=10)

{
  "status": "Failed",
  "dqu_check_type": "referentialintegrity_check",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T10:36:55.054372+00:00",
  "run_id": "c8395aa5-ecf0-40c0-9cc9-0a99e22f73a9"
}
{'user_id': 104, 'amount': 99.9}
```

### 4.13 Row Count Check

```python
import ray
from ray.data import from_items
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)
data = [
    {"id": 1, "name": "Alice"},
    {"id": 2, "name": "Bob"},
    {"id": 3, "name": "Charlie"},
    {"id": 4, "name": "David"},
    {"id": 5, "name": "Eva"}
]

ds = from_items(data)
dqudf = DquDataFrame(ds)

# Row count check between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 3,
        "max": 10
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result = check.run(evaluation="advanced")
print(result)
{
  "status": "Success",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 3,
  "max_allowed": 10,
  "run_timestamp": "2025-08-06T11:13:09.950772+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

import ray
from ray.data import from_items
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.rowcount_check import DquRowCountCheck

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)
data = [
    {"id": 1, "name": "Alice"},
    {"id": 2, "name": "Bob"},
    {"id": 3, "name": "Charlie"},
    {"id": 4, "name": "David"},
    {"id": 5, "name": "Eva"}
]

ds = from_items(data)
dqudf = DquDataFrame(ds)

# Row count check between 3 and 10
check = DquRowCountCheck(
    dqudf,
    config={
        "min": 30,
        "max": 100
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)

result = check.run(evaluation="advanced")
print(result)

{
  "status": "Failed",
  "dqu_check_type": "rowcount_check",
  "dqu_total_count": 5,
  "min_required": 30,
  "max_allowed": 100,
  "run_timestamp": "2025-08-06T11:15:20.442758+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
```

### 4.14 Custom Check - (Powerful)

```python
import ray
from ray.data import from_items
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck
if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "score": 85},
    {"id": 2, "score": 92},
    {"id": 3, "score": -10},  # This should fail
    {"id": 4, "score": 74}
]

ds = from_items(data)
dqudf = DquDataFrame(ds)

# Custom check: score must be >= 0
check = DquCustomCheck(
    dqudf,
    config={
        "column": "score",
        "func": lambda x: x >= 0
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "custom_check_column",
  "column": "score",
  "dqu_total_count": 4,
  "dqu_failed_count": 1,
  "dqu_passed_count": 3,
  "run_timestamp": "2025-08-06T11:34:37.113549+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}
{'id': 3, 'score': -10}

import ray
from ray.data import from_items
from dqu.kernel.dataframe import DquDataFrame
from dqu.validators.custom_check import DquCustomCheck
if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

data = [
    {"id": 1, "age": 25, "country": "US"},
    {"id": 2, "age": 17, "country": "US"},  # Fails: age < 18
    {"id": 3, "age": 35, "country": "CA"},  # Fails: country != US
    {"id": 4, "age": 45, "country": "IN"}   # Fails: country != US
]

ds = from_items(data)
dqudf = DquDataFrame(ds)

# Apply custom row-level check
check = DquCustomCheck(
    dqudf,
    config={
        "func": lambda row: row["age"] >= 18 and row["country"] == "US"
    },
    run_id="123e4567-e89b-12d3-a456-426614174000"
)
result, failed_rows = check.run(evaluation="advanced")
print(result)
failed_rows.show()

{
  "status": "Failed",
  "dqu_check_type": "custom_check_row",
  "column": null,
  "dqu_total_count": 4,
  "dqu_failed_count": 3,
  "dqu_passed_count": 1,
  "run_timestamp": "2025-08-06T11:36:10.193768+00:00",
  "run_id": "123e4567-e89b-12d3-a456-426614174000"
}

{'id': 2, 'age': 17, 'country': 'US'}
{'id': 3, 'age': 35, 'country': 'CA'}
{'id': 4, 'age': 45, 'country': 'IN'}
```

---

## 5. YAML Config Driven Evaluation for **Spark/Ray/Pandas**

You can define a suite of data quality checks in a YAML file and run them on your dataset using Pandas, Spark, or Ray engines. This enables easy, declarative, and repeatable DQ validation.

**Runs DQU checks as specified in a YAML config file or YAML string.**

### API: `run_checks_from_yaml`

#### Parameters:

- **dataframe**: `DquDataFrame`
- **yaml_path**: Path to YAML config file (optional)
- **yaml_string**: YAML config as a string (optional)
  - Both `yaml_path` and `yaml_string` cannot be None; one must be provided.
- **write_to_file**: If `True`, writes results to a JSON file in current directory; if `False`, returns results as a JSON string
- **df_mapping**: A dictionary mapping reference DataFrame names to actual DataFrame objects (optional, used only for referential integrity)

#### Returns:

- If `write_to_file` is `False`, returns the results as a JSON string.
- If `write_to_file` is `True`, writes results to a file and returns nothing.

#### Raises:

- Exception with a helpful message if YAML or check config is invalid.

### Example YAML Config (`dqu_ray_check.yml`)

```yaml
run_id: "123e4567-e89b-12d3-a456-426614174000"
checks:
  - type: "duplicate"
    columns: ["id"]

  - type: "empty"
    columns: ["name", "age"]

  - type: "unique"
    columns: ["id"]

  - type: "dtype"
    columns:
      id: int
      name: str
      age: int

  - type: "stringformat"
    column: "email"
    pattern: '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$'

  - type: "schemavalidation"
    expected_schema:
      id: int
      name: str
      age: int
      email: str
      department: str
      salary: float
      label: int
      created_at: timestamp
      user_id: int
      score: int
      country: str

  - type: "range"
    column: "age"
    min: 18
    max: 65

  - type: "categoricalvalues"
    column: "department"
    allowed_values: ["HR", "Finance", "Engineering"]

  - type: "statisticaldistribution"
    column: "salary"
    mode: "feature_drift"
    reference_stats:
      mean: 70000
      std: 5000
    tolerance: 0.1

  - type: "statisticaldistribution"
    column: "label"
    mode: "label_balance"

  - type: "datafreshness"
    column: "created_at"
    freshness_threshold: "2h"

  - type: "referentialintegrity"
    column: "user_id"
    reference_df: "ref_df"
    reference_column: "id"

  - type: "rowcount"
    min: 30
    max: 100

  - type: "custom"
    column: "score"
    func: "lambda x: x >= 0"

  - type: "custom"
    func: "lambda row: row['age'] >= 18 and row['country'] == 'US'"
```

### Example Python Code to Run the YAML Config with Ray

```python
import ray
from datetime import datetime, timedelta
import numpy as np
from dqu.kernel.dataframe import DquDataFrame
from dqu.config_runner import DquConfigRunner

if not ray.is_initialized():
    ray.init(ignore_reinit_error=True)

# ---- MAIN DATASET ----
now = datetime.utcnow()
main_data = []
for i in range(1, 31):  # 30 rows to satisfy rowcount
    row = {
        "id": i,
        "name": f"User{i}",
        "age": np.random.randint(18, 65),
        "email": f"user{i}@example.com",
        "department": np.random.choice(["HR", "Finance", "Engineering"]),
        "salary": float(np.random.normal(70000, 5000)),
        "label": np.random.choice([0, 1]),
        "created_at": now - timedelta(minutes=30),
        "user_id": 100 + i,
        "score": np.random.randint(0, 100),
        "country": "US"
    }
    main_data.append(row)

main_ds = ray.data.from_items(main_data)
dqu_main = DquDataFrame(main_ds)

# ---- REFERENCE DATASET ----
ref_data = [{"id": 100 + i} for i in range(1, 41)]
ref_ds = ray.data.from_items(ref_data)
df_mapping = {"ref_df": ref_ds}

# ---- RUN ALL CHECKS ----
results = DquConfigRunner.run_checks_from_yaml(
    dataframe=dqu_main,
    yaml_path="<>/dqu_ray_check.yml",
    write_to_file=True,
    df_mapping=df_mapping
)

print(results)
```

```JSON
[
  {
    "status": "Success",
    "dqu_check_type": "duplicate_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:11.864689+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "duplicate",
      "columns": [
        "id"
      ]
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "empty_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:13.133235+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "empty",
      "columns": [
        "name",
        "age"
      ]
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "unique_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:15.717631+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "unique",
      "columns": [
        "id"
      ]
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "dtype_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:16.264573+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "dtype",
      "columns": {
        "id": "int",
        "name": "str",
        "age": "int"
      }
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "stringformat_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:17.010052+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "stringformat",
      "column": "email",
      "pattern": "^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$"
    }
  },
  {
    "status": "Failed",
    "dqu_check_type": "schemavalidation_check",
    "missing_columns": [],
    "type_mismatches": {
      "id": {
        "expected": "int",
        "actual": "int64"
      },
      "name": {
        "expected": "str",
        "actual": "string"
      },
      "age": {
        "expected": "int",
        "actual": "int64"
      },
      "email": {
        "expected": "str",
        "actual": "string"
      },
      "department": {
        "expected": "str",
        "actual": "string"
      },
      "salary": {
        "expected": "float",
        "actual": "double"
      },
      "label": {
        "expected": "int",
        "actual": "int32"
      },
      "created_at": {
        "expected": "timestamp",
        "actual": "timestamp[us]"
      },
      "user_id": {
        "expected": "int",
        "actual": "int64"
      },
      "score": {
        "expected": "int",
        "actual": "int64"
      },
      "country": {
        "expected": "str",
        "actual": "string"
      }
    },
    "dqu_total_count": 30,
    "dqu_failed_count": 11,
    "dqu_passed_count": 0,
    "run_timestamp": "2025-09-04T20:59:17.010708+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "schemavalidation",
      "expected_schema": {
        "id": "int",
        "name": "str",
        "age": "int",
        "email": "str",
        "department": "str",
        "salary": "float",
        "label": "int",
        "created_at": "timestamp",
        "user_id": "int",
        "score": "int",
        "country": "str"
      }
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "range_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:17.420218+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "column": "age",
    "range": {
      "min": 18,
      "max": 65
    },
    "dqu_eval_config": {
      "type": "range",
      "column": "age",
      "min": 18,
      "max": 65
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "categoricalvalues_check",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:18.128209+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "allowed_values": [
      "HR",
      "Finance",
      "Engineering"
    ],
    "dqu_eval_config": {
      "type": "categoricalvalues",
      "column": "department",
      "allowed_values": [
        "HR",
        "Finance",
        "Engineering"
      ]
    }
  },
  {
    "status": "Failed",
    "dqu_check_type": "statisticaldistribution_check",
    "mode": "feature_drift",
    "column": "salary",
    "dqu_drift_mean": 172.97654345190676,
    "dqu_drift_std": 989.9788967435034,
    "dqu_passed": false,
    "run_timestamp": "2025-09-04T20:59:21.223538+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "statisticaldistribution",
      "column": "salary",
      "mode": "feature_drift",
      "reference_stats": {
        "mean": 70000,
        "std": 5000
      },
      "tolerance": 0.1
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "statisticaldistribution_check",
    "mode": "label_balance",
    "column": "label",
    "dqu_distribution": {
      "1": 0.6,
      "0": 0.4
    },
    "dqu_passed": true,
    "run_timestamp": "2025-09-04T20:59:21.362669+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "statisticaldistribution",
      "column": "label",
      "mode": "label_balance"
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "datafreshness_check",
    "column": "created_at",
    "latest_timestamp": "2025-09-04 20:28:58.910817+00:00",
    "cutoff_timestamp": "2025-09-04 18:59:22.187068+00:00",
    "dqu_passed": true,
    "run_timestamp": "2025-09-04T20:59:22.187068+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "datafreshness",
      "column": "created_at",
      "freshness_threshold": "2h"
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "referentialintegrity_check",
    "column": "user_id",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:24.382812+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "referentialintegrity",
      "column": "user_id",
      "reference_df": "ref_df",
      "reference_column": "id"
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "rowcount_check",
    "dqu_total_count": 30,
    "min_required": 30,
    "max_allowed": 100,
    "run_timestamp": "2025-09-04T20:59:24.383478+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "rowcount",
      "min": 30,
      "max": 100
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "custom_check_column",
    "column": "score",
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:24.894960+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "custom",
      "column": "score",
      "func": "lambda x: x >= 0"
    }
  },
  {
    "status": "Success",
    "dqu_check_type": "custom_check_row",
    "column": null,
    "dqu_total_count": 30,
    "dqu_failed_count": 0,
    "dqu_passed_count": 30,
    "run_timestamp": "2025-09-04T20:59:25.280227+00:00",
    "run_id": "123e4567-e89b-12d3-a456-426614174000",
    "dqu_eval_config": {
      "type": "custom",
      "func": "lambda row: row['age'] >= 18 and row['country'] == 'US'"
    }
  }
]
```

### Example for Pandas Python

```python
yaml_string = """
run_id: "123e4567-e89b-12d3-a456-426614174000"
checks:
  - type: "duplicate"
    columns: ["id"]

  - type: "empty"
    columns: ["name", "age"]

  - type: "unique"
    columns: ["id"]

  - type: "dtype"
    columns:
      id: int
      name: str
      age: int

  - type: "stringformat"
    column: "email"
    pattern: '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$'

  - type: "schemavalidation"
    expected_schema:
      id: int
      name: object
      age: int

  - type: "range"
    column: "age"
    min: 18
    max: 65

  - type: "categoricalvalues"
    column: "department"
    allowed_values: ["HR", "Finance", "Engineering"]

  - type: "statisticaldistribution"
    column: "salary"
    mode: "feature_drift"
    reference_stats:
      mean: 70000
      std: 5000
    tolerance: 0.1

  - type: "statisticaldistribution"
    column: "label"
    mode: "label_balance"

  - type: "datafreshness"
    column: "created_at"
    freshness_threshold: "-2h"

  - type: "referentialintegrity"
    column: "user_id"
    reference_df: "ref_df"
    reference_column: "id"

  - type: "rowcount"
    min: 30
    max: 100

  - type: "custom"
    column: "score"
    func: "lambda x: x >= 0"

  - type: "custom"
    func: "lambda row: row['age'] >= 18 and row['country'] == 'US'"
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Main DataFrame
main_data = {
    "id": range(1, 31),  # 30 unique IDs (meets rowcount + unique + no duplicate)
    "name": [f"User{i}" for i in range(1, 31)],
    "age": np.random.randint(18, 60, size=30),  # within 18–65
    "email": [f"user{i}@example.com" for i in range(1, 30)] + ["test@example.com"],
    "department": np.random.choice(["HR", "Finance", "Engineering"], size=30),
    "salary": np.random.normal(loc=70000, scale=5000, size=30),  # matches reference stats
    "label": np.random.choice([0, 1], size=30),
    "created_at": [datetime.now() - timedelta(minutes=30)] * 30,  # fresh within 2h
    "user_id": range(101, 131),  # will match ref_df
    "score": np.random.randint(0, 100, size=30),
    "country": ["US"] * 30  # satisfies custom func row['country'] == 'US'
}
main_df = pd.DataFrame(main_data)

# Reference DataFrame for referential integrity
ref_data = {
    "id": list(range(100, 140))  # includes all main_df user_id values
}
ref_df = pd.DataFrame(ref_data)

from dqu.kernel.dataframe import DquDataFrame
from dqu.config_runner import DquConfigRunner

dqu_main = DquDataFrame(main_df)
df_mapping = {"ref_df": ref_df}

results = DquConfigRunner.run_checks_from_yaml(
    dataframe=dqu_main,
    yaml_string=yaml_string,
    write_to_file=False,
    df_mapping=df_mapping
)

print(results)

```

### Example for Spark PySpark

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import *
import numpy as np
from datetime import datetime, timedelta


spark = SparkSession.builder.appName("DQU_Test_Data").getOrCreate()

# ----- Main Data -----
main_data = {
    "id": list(range(1, 31)),  # 30 unique IDs
    "name": [f"User{i}" for i in range(1, 31)],
    "age": np.random.randint(18, 60, size=30).tolist(),  # within 18–65
    "email": [f"user{i}@example.com" for i in range(1, 30)] + ["test@example.com"],
    "department": np.random.choice(["HR", "Finance", "Engineering"], size=30).tolist(),
    "salary": np.random.normal(loc=70000, scale=5000, size=30).tolist(),
    "label": np.random.choice([0, 1], size=30).tolist(),
    "created_at": [datetime.now() - timedelta(minutes=30)] * 30,  # fresh within 2h
    "user_id": list(range(101, 131)),  # will match ref_df
    "score": np.random.randint(0, 100, size=30).tolist(),
    "country": ["US"] * 30
}

main_rows = [dict(zip(main_data.keys(), values)) for values in zip(*main_data.values())]

main_schema = StructType([
    StructField("id", IntegerType(), False),
    StructField("name", StringType(), False),
    StructField("age", IntegerType(), False),
    StructField("email", StringType(), False),
    StructField("department", StringType(), False),
    StructField("salary", DoubleType(), False),
    StructField("label", IntegerType(), False),
    StructField("created_at", TimestampType(), False),
    StructField("user_id", IntegerType(), False),
    StructField("score", IntegerType(), False),
    StructField("country", StringType(), False),
])

# Create Spark DataFrame
main_spark_df = spark.createDataFrame(main_rows, schema=main_schema)

# ----- Reference Data -----
ref_data = {"id": list(range(100, 140))}
ref_rows = [{"id": i} for i in ref_data["id"]]

ref_schema = StructType([StructField("id", IntegerType(), False)])
ref_spark_df = spark.createDataFrame(ref_rows, schema=ref_schema)

from dqu.kernel.dataframe import DquDataFrame
from dqu.config_runner import DquConfigRunner

dqu_main = DquDataFrame(main_spark_df)
df_mapping = {"ref_df": ref_spark_df}

results = DquConfigRunner.run_checks_from_yaml(
    dataframe=dqu_main,
    yaml_path=r"/Workspace/Users/<>/dqu_check.yml",
    write_to_file=True,
    df_mapping=df_mapping
)

print(results)
### Writes results JSON in current directory
```

---

## 🌐 Logging & Monitoring Integration

DQU supports **enterprise-grade logging** for your data quality results, enabling seamless integration with monitoring dashboards and alerting systems. You can log DQU results to:

- **Console** (for local development and debugging)
- **Azure Log Analytics** (for cloud-scale monitoring on Azure)
- **Google Cloud Logging** (for GCP-native observability)

### How Logging Works

After running your DQU checks, simply pass the results and your chosen logger(s) to `log_dqu_results`. Each check result will be logged individually, with a computed `dqu_score` (percentage of passed rows).

### Example: Logging to Console, Azure, and GCP

```python
from dqu.log.logger import log_dqu_results, ConsoleLogger, AzureLogAnalyticsLogger, GCPLogger

workspaceId = "<YOUR_AZURE_WORKSPACE_ID>"
workspaceKey = "<YOUR_AZURE_SHARED_KEY>"

loggers = [
    ConsoleLogger(),
    AzureLogAnalyticsLogger(workspaceId, workspaceKey, "dquLogs"),
    GCPLogger("dquLogs")
]

# results = ... # Output from DquConfigRunner.run_checks_from_yaml(..., write_to_file=False)

log_dqu_results(results, loggers, dqu_tags)
**dqu_tags (dict, optional): Additional tags to be added to each logged result.**
                                   **Defaults to None.**
```

You can use any combination of loggers, e.g.:

```python
loggers = [GCPLogger("dquLogs")]
```

### What Gets Logged

- Each check result (one log entry per check)
- `dqu_score` field: percentage of passed rows (0 for non-success checks)
- All metadata (run_id, timestamp, config, etc.)

### Why Use Logging?

- **Monitor DQ health** in real time
- **Build dashboards** in Azure Monitor or Google Cloud Operations
- **Set up alerts** for failed checks or low data quality scores

---

**Tip:**  
You can extend logging to other platforms by implementing the `DQULoggerBase` interface.

---

## 🤝 Contributing

We welcome contributions from the community! If you have ideas for enhancements, bug fixes, or documentation improvements, please open an issue or submit a pull request.

**How to contribute:**

- Fork the repository and create your branch from `main`.
- Make your changes with clear commit messages.
- Ensure your code passes all tests and style checks.
- Submit a pull request describing your changes.

For major changes, please open an issue first to discuss what you would like to change.

---

## 📜 License

This project is licensed under the [MIT License](LICENSE).
All rights reserved.
