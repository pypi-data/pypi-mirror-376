
from __future__ import annotations
import argparse, os, json, sys
import pandas as pd
from .core.checks import run_checks
from .core.report import render_report, write_fix_script, write_meta
from .core.simulator import run_time_series_simulation
from .core.cv_policy import audit_cv_policy
from .core.export import export_report
from .core.loader import load_data, estimate_memory_usage
from .core.parallel import ParallelProcessor
from .api import audit, plan_fixes, apply_fixes_to_dataframe, export_audit_result

# é€€å‡ºç å®šä¹‰
EXIT_OK = 0
EXIT_WARNINGS = 2
EXIT_HIGH_LEAKAGE = 3
EXIT_INVALID_CONFIG = 4

def run(train_path: str, target: str, time_col: str | None, out_dir: str, 
        cv_type: str | None = None, simulate_cv: str | None = None, 
        leak_threshold: float = 0.02, cv_policy_file: str | None = None,
        export: str | None = None, export_sarif: str | None = None, 
        auto_fix: str | None = None, fix_json: str | None = None, 
        fixed_train: str | None = None, engine: str = "pandas",
        n_jobs: int = -1, memory_cap: int = 4096, sample_ratio: float | None = None):
    """è¿è¡Œæ³„æ¼æ£€æµ‹ - v1.0ç‰ˆæœ¬"""
    try:
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(train_path):
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "FileNotFoundError",
                    "message": f"Training file not found: {train_path}",
                    "details": {"file": train_path}
                }
            }
        
        # ä¼°ç®—å†…å­˜ä½¿ç”¨
        try:
            memory_info = estimate_memory_usage(train_path)
            print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: {memory_info['total_rows']:,} è¡Œ, {memory_info['columns']} åˆ—")
            print(f"ğŸ’¾ é¢„ä¼°å†…å­˜: {memory_info['estimated_memory_mb']:.1f} MB")
            
            # å¦‚æœé¢„ä¼°å†…å­˜è¶…è¿‡é™åˆ¶ï¼Œå¯ç”¨é‡‡æ ·
            if memory_info['estimated_memory_mb'] > memory_cap * 0.8:
                if sample_ratio is None:
                    sample_ratio = min(0.5, memory_cap / memory_info['estimated_memory_mb'])
                    print(f"âš ï¸  å†…å­˜è¶…é™ï¼Œè‡ªåŠ¨å¯ç”¨é‡‡æ ·: {sample_ratio:.1%}")
        except Exception as e:
            print(f"âš ï¸  å†…å­˜ä¼°ç®—å¤±è´¥: {e}")
        
        # è¯»å–æ•°æ®
        try:
            print(f"ğŸ”„ åŠ è½½æ•°æ® (å¼•æ“: {engine})...")
            df = load_data(
                train_path, 
                engine=engine, 
                memory_cap_mb=memory_cap,
                sample_ratio=sample_ratio
            )
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")
        except Exception as e:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "FileNotFoundError",
                    "message": f"Failed to read CSV file: {str(e)}",
                    "details": {"file": train_path, "error": str(e)}
                }
            }
        
        # éªŒè¯ç›®æ ‡åˆ—
        if target not in df.columns:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "ValidationError",
                    "message": f"Target column '{target}' not found in data",
                    "details": {"column": target, "available_columns": list(df.columns)}
                }
            }
        
        # éªŒè¯æ—¶é—´åˆ—
        if time_col and time_col not in df.columns:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "ValidationError",
                    "message": f"Time column '{time_col}' not found in data",
                    "details": {"column": time_col, "available_columns": list(df.columns)}
                }
            }
        
        # ä½¿ç”¨APIè¿›è¡Œå®¡è®¡
        try:
            print("ğŸ” å¼€å§‹å®¡è®¡...")
            audit_result = audit(
                df, target=target, time_col=time_col, cv_type=cv_type,
                simulate_cv=simulate_cv, leak_threshold=leak_threshold,
                cv_policy_file=cv_policy_file, engine=engine, n_jobs=n_jobs,
                memory_cap=memory_cap, sample_ratio=sample_ratio
            )
            print(f"âœ… å®¡è®¡å®Œæˆ: å‘ç° {audit_result.risk_count} ä¸ªé£é™©")
        except Exception as e:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "RuntimeError",
                    "message": f"Audit failed: {str(e)}",
                    "details": {"error": str(e)}
                }
            }
        
        # ç¡®å®šé€€å‡ºç 
        exit_code = EXIT_OK
        if audit_result.has_high_risk:
            exit_code = EXIT_HIGH_LEAKAGE
            print("ğŸš¨ æ£€æµ‹åˆ°é«˜å±æ³„æ¼ï¼")
        elif audit_result.has_medium_risk:
            exit_code = EXIT_WARNINGS
            print("âš ï¸  æ£€æµ‹åˆ°ä¸­å±é£é™©")
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾é£é™©")
        
        # å¤„ç†auto-fix
        fix_plan = None
        if auto_fix == "plan":
            try:
                print("ğŸ“‹ ç”Ÿæˆä¿®å¤è®¡åˆ’...")
                fix_plan = plan_fixes(audit_result, train_path)
                # å†™å…¥ä¿®å¤è®¡åˆ’JSON
                if fix_json:
                    os.makedirs(os.path.dirname(fix_json), exist_ok=True)
                    with open(fix_json, 'w', encoding='utf-8') as f:
                        json.dump(fix_plan.model_dump(), f, ensure_ascii=False, indent=2)
                    print(f"âœ… ä¿®å¤è®¡åˆ’å·²ä¿å­˜: {fix_json}")
            except Exception as e:
                return {
                    "status": "error",
                    "exit_code": EXIT_INVALID_CONFIG,
                    "error": {
                        "type": "RuntimeError",
                        "message": f"Fix planning failed: {str(e)}",
                        "details": {"error": str(e)}
                    }
                }
        
        elif auto_fix == "apply":
            try:
                print("ğŸ”§ åº”ç”¨ä¿®å¤...")
                fix_plan = plan_fixes(audit_result, train_path)
                fixed_df = apply_fixes_to_dataframe(df, fix_plan)
                # å†™å…¥ä¿®å¤åçš„æ•°æ®
                if fixed_train:
                    os.makedirs(os.path.dirname(fixed_train), exist_ok=True)
                    fixed_df.to_csv(fixed_train, index=False)
                    print(f"âœ… ä¿®å¤åæ•°æ®å·²ä¿å­˜: {fixed_train}")
            except Exception as e:
                return {
                    "status": "error",
                    "exit_code": EXIT_INVALID_CONFIG,
                    "error": {
                        "type": "RuntimeError",
                        "message": f"Fix application failed: {str(e)}",
                        "details": {"error": str(e)}
                    }
                }
        
        # å‡†å¤‡å…ƒæ•°æ®
        meta = {
            "args": {
                "train": train_path, 
                "target": target, 
                "time_col": time_col, 
                "out": out_dir, 
                "cv_type": cv_type,
                "simulate_cv": simulate_cv,
                "leak_threshold": leak_threshold,
                "cv_policy_file": cv_policy_file,
                "export": export,
                "export_sarif": export_sarif,
                "auto_fix": auto_fix,
                "fix_json": fix_json,
                "fixed_train": fixed_train,
                "engine": engine,
                "n_jobs": n_jobs,
                "memory_cap": memory_cap,
                "sample_ratio": sample_ratio
            },
            "n_rows": int(len(df)),
            "n_cols": int(df.shape[1]),
            "target": target,
            "time_col": time_col,
            "cv_type": cv_type,
            "simulate_cv": simulate_cv,
            "leak_threshold": leak_threshold,
            "cv_policy_file": cv_policy_file,
            "export": export,
            "export_sarif": export_sarif,
            "auto_fix": auto_fix,
            "fix_json": fix_json,
            "fixed_train": fixed_train,
            "engine": engine,
            "n_jobs": n_jobs,
            "memory_cap": memory_cap,
            "sample_ratio": sample_ratio,
            "git_hash": os.popen('git rev-parse HEAD 2>/dev/null || echo "unknown"').read().strip(),
            "random_seed": "42"
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        try:
            os.makedirs(out_dir, exist_ok=True)
        except Exception as e:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "FileNotFoundError",
                    "message": f"Failed to create output directory: {str(e)}",
                    "details": {"directory": out_dir, "error": str(e)}
                }
            }
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        try:
            print("ğŸ“„ ç”ŸæˆæŠ¥å‘Š...")
            write_meta(meta, out_dir)
            report_path = render_report(audit_result.data, meta, out_dir, audit_result.simulation, audit_result.policy_audit)
            fix_path = write_fix_script(audit_result.data, out_dir)
            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        except Exception as e:
            return {
                "status": "error",
                "exit_code": EXIT_INVALID_CONFIG,
                "error": {
                    "type": "RuntimeError",
                    "message": f"Failed to generate output files: {str(e)}",
                    "details": {"error": str(e)}
                }
            }
        
        # å¤„ç†å¯¼å‡º
        export_results = {}
        if export:
            try:
                print(f"ğŸ“¤ å¯¼å‡º {export.upper()}...")
                if export == "pdf":
                    pdf_path = os.path.join(out_dir, "report.pdf")
                    export_result = export_report(report_path, pdf_path, "pdf")
                    export_results["pdf"] = export_result
                    print(f"âœ… PDFå·²å¯¼å‡º: {pdf_path}")
                else:
                    export_results["export"] = {"status": "error", "message": f"Unsupported export type: {export}"}
            except Exception as e:
                export_results["export"] = {"status": "error", "message": f"Export failed: {str(e)}"}
        
        if export_sarif:
            try:
                print("ğŸ“¤ å¯¼å‡ºSARIF...")
                sarif_path = export_sarif
                export_result = export_report(None, sarif_path, "sarif", audit_result.data)
                export_results["sarif"] = export_result
                print(f"âœ… SARIFå·²å¯¼å‡º: {sarif_path}")
            except Exception as e:
                export_results["sarif"] = {"status": "error", "message": f"SARIF export failed: {str(e)}"}
        
        # è¿”å›æˆåŠŸç»“æœ
        result_data = {
            "report": report_path,
            "fix_script": fix_path,
            "meta": meta,
            "risks": audit_result.risks,
            "summary": {
                "total_risks": audit_result.risk_count,
                "high_risks": audit_result.high_risk_count,
                "medium_risks": audit_result.medium_risk_count,
                "low_risks": audit_result.low_risk_count,
                "has_high_risk": audit_result.has_high_risk,
                "has_medium_risk": audit_result.has_medium_risk
            }
        }
        
        # æ·»åŠ æ¨¡æ‹Ÿç»“æœ
        if audit_result.simulation:
            result_data["simulation"] = audit_result.simulation
        
        # æ·»åŠ ç­–ç•¥å®¡è®¡ç»“æœ
        if audit_result.policy_audit:
            result_data["policy_audit"] = audit_result.policy_audit
        
        # æ·»åŠ å¯¼å‡ºç»“æœ
        if export_results:
            result_data["exports"] = export_results
        
        # æ·»åŠ ä¿®å¤è®¡åˆ’
        if fix_plan:
            result_data["fix_plan"] = fix_plan.model_dump()
        
        return {
            "status": "success",
            "exit_code": exit_code,
            "data": result_data
        }
        
    except Exception as e:
        # æ•è·æœªé¢„æœŸçš„é”™è¯¯
        return {
            "status": "error",
            "exit_code": EXIT_INVALID_CONFIG,
            "error": {
                "type": "RuntimeError",
                "message": f"Unexpected error: {str(e)}",
                "details": {"error": str(e)}
            }
        }

def build_parser():
    p = argparse.ArgumentParser(
        prog="leakage-buster", 
        description="Data leakage detection and audit tool v1.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # åŸºæœ¬æ£€æµ‹
  leakage-buster run --train data.csv --target y --out runs/audit
  
  # é«˜æ€§èƒ½æ£€æµ‹
  leakage-buster run --train data.csv --target y --time-col date --out runs/audit \\
    --engine pandas --n-jobs 8 --memory-cap 4096
  
  # ç”Ÿæˆä¿®å¤è®¡åˆ’
  leakage-buster run --train data.csv --target y --out runs/audit \\
    --auto-fix plan --fix-json runs/audit/fix_plan.json
  
  # åº”ç”¨ä¿®å¤
  leakage-buster run --train data.csv --target y --out runs/audit \\
    --auto-fix apply --fixed-train runs/audit/fixed_data.csv
  
  # å¯¼å‡ºPDFå’ŒSARIF
  leakage-buster run --train data.csv --target y --out runs/audit \\
    --export pdf --export-sarif runs/audit/leakage.sarif
        """
    )
    sub = p.add_subparsers(dest="cmd")
    run_p = sub.add_parser("run", help="Run leakage audit")
    
    # åŸºç¡€å‚æ•°
    run_p.add_argument("--train", type=str, required=True, help="Training data CSV file")
    run_p.add_argument("--target", type=str, required=True, help="Target column name")
    run_p.add_argument("--time-col", type=str, default=None, help="Time column name (optional)")
    run_p.add_argument("--out", type=str, required=True, help="Output directory")
    
    # CVç­–ç•¥å‚æ•°
    run_p.add_argument("--cv-type", type=str, choices=["kfold", "timeseries", "group"], 
                       default=None, help="CV strategy: kfold/timeseries/group")
    run_p.add_argument("--simulate-cv", type=str, choices=["time"], default=None,
                       help="Enable time series simulation: time")
    run_p.add_argument("--leak-threshold", type=float, default=0.02,
                       help="Leak threshold for simulation (default: 0.02)")
    run_p.add_argument("--cv-policy-file", type=str, default=None,
                       help="CV policy configuration file (YAML)")
    
    # æ€§èƒ½å‚æ•°
    run_p.add_argument("--engine", type=str, choices=["pandas", "polars"], default="pandas",
                       help="Data processing engine (default: pandas)")
    run_p.add_argument("--n-jobs", type=int, default=-1,
                       help="Number of parallel jobs (default: auto)")
    run_p.add_argument("--memory-cap", type=int, default=4096,
                       help="Memory limit in MB (default: 4096)")
    run_p.add_argument("--sample-ratio", type=float, default=None,
                       help="Sample ratio for large datasets (0.0-1.0)")
    
    # å¯¼å‡ºå‚æ•°
    run_p.add_argument("--export", type=str, choices=["pdf"], default=None,
                       help="Export report format: pdf")
    run_p.add_argument("--export-sarif", type=str, default=None,
                       help="Export SARIF file path for GitHub Code Scanning")
    
    # è‡ªåŠ¨ä¿®å¤å‚æ•°
    run_p.add_argument("--auto-fix", type=str, choices=["plan", "apply"], default=None,
                       help="Auto-fix mode: plan (generate fix plan) or apply (apply fixes)")
    run_p.add_argument("--fix-json", type=str, default=None,
                       help="Fix plan JSON output path (used with --auto-fix plan)")
    run_p.add_argument("--fixed-train", type=str, default=None,
                       help="Fixed training data CSV output path (used with --auto-fix apply)")
    
    return p

def main():
    parser = build_parser()
    args = parser.parse_args()
    
    if args.cmd == "run" or (args.cmd is None and hasattr(args, "train")):
        result = run(args.train, args.target, args.time_col, args.out, 
                    args.cv_type, args.simulate_cv, args.leak_threshold,
                    args.cv_policy_file, args.export, args.export_sarif,
                    args.auto_fix, args.fix_json, args.fixed_train,
                    args.engine, args.n_jobs, args.memory_cap, args.sample_ratio)
        
        # è¾“å‡ºJSONç»“æœ
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
        # è®¾ç½®é€€å‡ºç 
        sys.exit(result["exit_code"])
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()

