{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mxlpy as mb2\n",
    "from example_models import (\n",
    "    get_linear_chain_2v,\n",
    ")\n",
    "from mxlpy import make_protocol, plot, scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter scans\n",
    "\n",
    "\n",
    "Parameter scans allow you to systematically assess the behaviour of your model dependent on the value of one or more parameters.  \n",
    "*mxlpy* has routines to scan over, and easily visualise **time courses**, **protocol time courses**, and **steady states** for one or more parameters.  \n",
    "\n",
    "<div>\n",
    "    <img src=\"assets/time-course-by-parameter.png\" \n",
    "         style=\"vertical-align:middle; max-height: 175px;\" />\n",
    "    <img src=\"assets/parameter-scan-2d.png\" \n",
    "         style=\"vertical-align:middle; max-height: 175px;\" />\n",
    "</div>\n",
    "\n",
    "For this, we import the `scan` and `plot` modules from which contain the respective routines.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady-state\n",
    "\n",
    "The steady-state scan takes a `pandas.DataFrame` of parameters to be scanned as an input and returns the steady-states at the respective parameter values.  \n",
    "\n",
    "The DataFrame can take an arbitrary number of parameters and should be in the following format \n",
    "\n",
    "|  n |   k1 |\n",
    "|---:|-----:|\n",
    "|  0 |  1   |\n",
    "|  1 |  1.2 |\n",
    "|  2 |  1.4 |\n",
    "\n",
    "As an example we will use a linear chain of two reactions like this\n",
    "\n",
    "$$ \\varnothing \\xrightarrow{v_1} S \\xrightarrow{v_2} P \\xrightarrow{v_3} \\varnothing$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scan.steady_state(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 3, 11)}),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 3))\n",
    "plot.lines(res.variables, ax=ax1)  # access concentrations by name\n",
    "plot.lines(res.fluxes, ax=ax2)  # access fluxes by name\n",
    "\n",
    "ax1.set(ylabel=\"Concentration / a.u.\")\n",
    "ax2.set(ylabel=\"Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scans return a result object, which allow multiple access patterns for convenience. \n",
    "\n",
    "Namely, the concentrations and fluxes can be accessed by name, unpacked or combined into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access by name\n",
    "_ = res.variables\n",
    "_ = res.fluxes\n",
    "\n",
    "# scan can be unpacked\n",
    "concs, fluxes = res\n",
    "\n",
    "# combine concs and fluxes as single dataframe\n",
    "_ = res.combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinations\n",
    "\n",
    "Often you want to scan over multiple parameters at the same time.  \n",
    "The recommended way to do this is to use the `cartesian_product` function, which takes a `parameter_name: values` mapping and creates a `pandas.DataFrame` of their combinations from it (think nested for loop).  \n",
    "\n",
    "In the case the parameters `DataFrame` contains more than one column, the returned `pandas.DataFrame` will contain a `pandas.MultiIndex`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb2.cartesian_product(\n",
    "    {\n",
    "        \"k1\": [1, 2],\n",
    "        \"k2\": [3, 4],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scan.steady_state(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 3),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "res.variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the results of a **single variable** of this scan using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap_from_2d_idx(res.variables, variable=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or create heatmaps of all passed variables at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmaps_from_2d_idx(res.variables)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine more than two parameters, however, visualisation then becomes challenging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scan.steady_state(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 3),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "            \"k3\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "res.variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course\n",
    "\n",
    "You can perform a time course for each of the parameter values, resulting in a **distribution of time courses**.    \n",
    "The index now also contains the time, so even for one parameter a `pandas.MultiIndex` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = scan.time_course(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),\n",
    "    time_points=np.linspace(0, 1, 11),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n",
    "\n",
    "ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\n",
    "ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this works for an arbitray number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = scan.time_course(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 11),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    "    time_points=np.linspace(0, 1, 11),\n",
    ")\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n",
    "ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\n",
    "ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scan object returned has a `pandas.MultiIndex` of `n x time`, where `n` is an index that references parameter combinations.  \n",
    "You can access the referenced parameters using `.to_scan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.to_scan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily access common aggregates like `mean` and `standard deviation (std)` using `get_agg_per_time`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.get_agg_per_time(\"std\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol\n",
    "\n",
    "The same can be done for protocols.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scan.protocol_time_course(\n",
    "    get_linear_chain_2v(),\n",
    "    to_scan=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),\n",
    "    time_points=np.linspace(0, 6, 21),\n",
    "    protocol=make_protocol(\n",
    "        [\n",
    "            (1, {\"k1\": 1}),\n",
    "            (2, {\"k1\": 2}),\n",
    "            (3, {\"k1\": 1}),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(res.variables, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(res.fluxes, ax=ax2)\n",
    "ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\n",
    "ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    plot.shade_protocol(res.protocol[\"k1\"], ax=ax, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #ffffff; background-color: #04AA6D; padding: 3rem 1rem 3rem 1rem; box-sizing: border-box\">\n",
    "    <h2>First finish line</h2>\n",
    "    With that you now know most of what you will need from a day-to-day basis about parameter scans in mxlpy.\n",
    "    <br />\n",
    "    <br />\n",
    "    Congratulations!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any\n",
    "\n",
    "from mxlpy.parallel import Cache, parallelise\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Hashable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel execution\n",
    "\n",
    "By default, all scans are executed in parallel.  \n",
    "To do this, they internally use the `parallelise` function defined by `mxlpy`.  \n",
    "\n",
    "> Tip: You can also use this function for other analyses as it is not specific to any `mxlpy` constructs.  \n",
    "\n",
    "The `parallelise` takes a function of type `T` and an iterable of a `key: T` pair.  \n",
    "The key is used to map the results to a given input and for caching (see below).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x: float) -> float:\n",
    "    return x**2\n",
    "\n",
    "\n",
    "output = parallelise(square, [(\"a\", 2), (\"b\", 3), (\"c\", 4)])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "In case the simulations take a significant amount of time to run, it makes sense to cache the results on disk.  \n",
    "You can do that by adding a `cache` to the `parallelise` function (and thus to all `scan` functions as well).  \n",
    "\n",
    "```python\n",
    "parallelise(...,  cache=Cache())\n",
    "```\n",
    "\n",
    "The first time the scan is run, the calculations are done, every subsequent time the results are loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = parallelise(\n",
    "    square,\n",
    "    [(\"a\", 2), (\"b\", 3), (\"c\", 4)],\n",
    "    cache=Cache(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overwriting cache results by different analyses we recommend saving each of them in a respective folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = Cache(tmp_dir=Path(\".cache\") / \"analysis-name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `key` of `parallelise` is used to create a pickle file called `{k}.p`.  \n",
    "You can customise this behaviour by changing the `name_fn`, `load_fn` and `save_fn` arguments respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pickle_name(k: Hashable) -> str:\n",
    "    return f\"{k}.p\"\n",
    "\n",
    "\n",
    "def _pickle_load(file: Path) -> Any:\n",
    "    with file.open(\"rb\") as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "\n",
    "def _pickle_save(file: Path, data: Any) -> None:\n",
    "    with file.open(\"wb\") as fp:\n",
    "        pickle.dump(data, fp)\n",
    "\n",
    "\n",
    "_ = Cache(\n",
    "    name_fn=_pickle_name,\n",
    "    load_fn=_pickle_load,\n",
    "    save_fn=_pickle_save,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
