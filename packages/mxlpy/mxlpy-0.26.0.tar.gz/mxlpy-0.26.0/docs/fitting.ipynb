{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from example_models import get_linear_chain_2v\n",
    "from mxlpy import Simulator, fit, make_protocol, plot, unwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "Almost every model at some point needs to be fitted to experimental data to be **validated**.  \n",
    "\n",
    "*mxlpy* offers highly customisable local and global routines for fitting either **time series** or **steady-states**.  \n",
    "\n",
    "<img src=\"assets/fitting.png\" style=\"max-height: 175px;\" />\n",
    "\n",
    "For this tutorial we are going to use the `fit` module to optimise our parameter values and the `plot` module to plot some results.  \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating synthetic data\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, for the sake of simplicity, we will generate some synthetic data.  \n",
    "\n",
    "Checkout the [basics tutorial](basics.ipynb) if you need a refresher on building and simulating models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a small trick, let's define a variable for the model function\n",
    "# That way, we can re-use it all over the file and easily replace\n",
    "# it with another model\n",
    "model_fn = get_linear_chain_2v\n",
    "\n",
    "res = unwrap(\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_time_course(np.linspace(0, 10, 101))\n",
    "    .get_result()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady-states\n",
    "\n",
    "For the steady-state fit we need two inputs:\n",
    "\n",
    "1. the steady state data, which we supply as a `pandas.Series`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will compare all data contained in that series to the model output.  \n",
    "\n",
    "> Note that the data both contains concentrations and fluxes!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.iloc[-1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit.steady_state(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res.iloc[-1],\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only some of the data is required, you can use a subset of it.  \n",
    "The fitting routine will only try to fit concentrations and fluxes contained in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit.steady_state(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=data.loc[[\"x\", \"y\"]],\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course\n",
    "\n",
    "For the time course fit we need again need two inputs\n",
    "\n",
    "1. the time course data, which we supply as a `pandas.DataFrame`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will create data at every time points specified in the `DataFrame` and compare all of them.  \n",
    "\n",
    "Other than that, the same rules of the steady-state fitting apply.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protcol time courses\n",
    "\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, again, for the sake of simplicity, we will generate some synthetic data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = make_protocol(\n",
    "    [\n",
    "        (1, {\"k1\": 1.0}),\n",
    "        (1, {\"k1\": 2.0}),\n",
    "        (1, {\"k1\": 1.0}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "res_protocol = unwrap(\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_protocol(\n",
    "        protocol,\n",
    "        time_points_per_step=10,\n",
    "    )\n",
    "    .get_result()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res_protocol)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the protocol time course fit we need three inputs\n",
    "\n",
    "1. an initial parameter guess\n",
    "2. the time course data, which we supply as a `pandas.DataFrame`\n",
    "3. the protocol, which we supply as a `pandas.DataFrame`\n",
    "\n",
    "> Note that the parameter given by the protocol cannot be fitted anymore  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit.protocol_time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol\n",
    "        data=res_protocol,\n",
    "        protocol=protocol,\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #ffffff; background-color: #04AA6D; padding: 3rem 1rem 3rem 1rem; box-sizing: border-box\">\n",
    "    <h2>First finish line</h2>\n",
    "    With that you now know most of what you will need from a day-to-day basis about fitting in mxlpy.\n",
    "    <br />\n",
    "    <br />\n",
    "    Congratulations!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics / customisation\n",
    "\n",
    "\n",
    "All fitting routines internally are build in a way that they will call a tree of functions. \n",
    "\n",
    "- `minimizer`\n",
    "  - `residual_fn`\n",
    "    - `integrator`\n",
    "    - `loss_fn`\n",
    "  \n",
    "\n",
    "You can therefore use dependency injection to overwrite the minimisation function, the loss function, the residual function and the integrator if need be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "from mxlpy.integrators import Scipy\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import pandas as pd\n",
    "\n",
    "    from mxlpy.fit import LossFn, ResidualFn\n",
    "    from mxlpy.model import Model\n",
    "    from mxlpy.types import Array, IntegratorType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterising scipy optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = fit.LocalScipyMinimizer(tol=1e-6, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function\n",
    "\n",
    "You can change the loss function that is being passed to the minimsation function using the `loss_fn` keyword.  \n",
    "Depending on the use case (time course vs steady state) this function will be passed two pandas `DataFrame`s or `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(\n",
    "    x: pd.DataFrame | pd.Series,\n",
    "    y: pd.DataFrame | pd.Series,\n",
    ") -> float:\n",
    "    \"\"\"Mean absolute error between two dataframes.\"\"\"\n",
    "    return cast(float, np.mean(np.abs(x - y)))\n",
    "\n",
    "\n",
    "fit_result = unwrap(\n",
    "    fit.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        loss_fn=mean_absolute_error,\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom integrator\n",
    "\n",
    "You can change the default integrator to an integrator of your choice by partially application of the class of any of the existing ones.  \n",
    "\n",
    "Here, for example, we choose the `Scipy` solver suite and set the default relative and absolute tolerances to `1e-6` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        integrator=partial(Scipy, rtol=1e-6, atol=1e-6),\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxlpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
