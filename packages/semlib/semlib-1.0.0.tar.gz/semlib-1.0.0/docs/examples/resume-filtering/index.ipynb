{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e728341",
   "metadata": {},
   "source": [
    "# Resume Filtering\n",
    "\n",
    "This notebook analyzes a [collection of resumes](https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset), extracting out the education info (university, degree, etc.), and filters resumes according to a criteria.\n",
    "\n",
    "This notebook shows how to use Semlib with local models using [Ollama](https://ollama.com/). It employs a model cascade to extract information using a higher-capacity model and then turns that into structured data using a smaller model (to work around [this bug](https://github.com/ollama/ollama/issues/11691) with `gpt-oss` in Ollama).\n",
    "\n",
    "The processing is implemented with the following pipeline:\n",
    "\n",
    "- (third-party tool) Convert PDF to Markdown with [Marker](https://github.com/datalab-to/marker).\n",
    "- ([map](../../api/#semlib.Session.map)) Use `gpt-oss:20b` to extract education information from resume Markdown content.\n",
    "- ([map](../../api/#semlib.Session.map)) Use `qwen3:8b` to turn the education information into structured data.\n",
    "- (non-semantic filter) Filter out the resumes that have master's degrees.\n",
    "\n",
    "## Install and configure dependencies\n",
    "\n",
    "### Ollama\n",
    "\n",
    "This notebook relies on [Ollama](https://ollama.com/), which you can use to run LLMs on your local machine. Download Ollama and start it before you proceed.\n",
    "\n",
    "We use two different open-source LLMs, [gpt-oss](https://ollama.com/library/gpt-oss) and [qwen3](https://ollama.com/library/qwen3).\n",
    "\n",
    "You will need a reasonably powerful machine to run these models locally. If they fail to run, or they run too slowly, you can consider trying smaller open-source models instead, or use a hosted model (e.g., via the OpenAI API) to run this notebook.\n",
    "\n",
    "First, we make sure these models are present on your local machine (if not, it's a **20 GB download**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull gpt-oss:20b\n",
    "!ollama pull qwen3:8b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74cb1b1",
   "metadata": {},
   "source": [
    "### Python packages\n",
    "\n",
    "In addition to Semlib, this notebook uses [Marker](https://github.com/datalab-to/marker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd187e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semlib marker-pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5715b0",
   "metadata": {},
   "source": [
    "We start by initializing a Semlib [Session](../../api/#semlib.Session). A session provides a context for performing Semlib operations. We configure the session to cache LLM responses on disk in `cache.db`, and we configure the default model to the open-source `gpt-oss:20b` via the local provider `ollama_chat/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3c4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semlib import OnDiskCache, Session\n",
    "\n",
    "session = Session(cache=OnDiskCache(\"cache.db\"), model=\"ollama_chat/gpt-oss:20b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3e9d2",
   "metadata": {},
   "source": [
    "## Download and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adeecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -L -o resume-dataset.zip https://www.kaggle.com/api/v1/datasets/download/snehaanbhawal/resume-dataset\n",
    "!unzip -q -o resume-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef034e",
   "metadata": {},
   "source": [
    "This dataset contains resumes in PDF format (feel free to examine them in your PDF viewer: the resumes will be in the `data/` directory).\n",
    "\n",
    "We use [Marker](https://github.com/VikParuchuri/marker) to convert these to Markdown. We sub-sample the resumes to reduce processing time, considering only 10 resumes in the dataset.\n",
    "\n",
    "The first time you use Marker, it needs to download some ML models (up to about **3 GB** of data).\n",
    "\n",
    "The following cell takes about 2 minutes to run on an M3 MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "\n",
    "converter = PdfConverter(\n",
    "    artifact_dict=create_model_dict(),\n",
    ")\n",
    "\n",
    "directory = \"data/data/ENGINEERING\"\n",
    "files = sorted(os.listdir(directory))[:10]\n",
    "texts = []\n",
    "for file in files:\n",
    "    rendered = converter(os.path.join(directory, file))\n",
    "    texts.append(rendered.markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2207cd",
   "metadata": {},
   "source": [
    "Now, we can preview what one of these resume texts looks like. We note that there are some parsing errors (the PDFs are not high-quality to begin with, and there are additional errors introduced in the conversion to Markdown). LLMs end up being pretty effective at processing data like this, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3362edbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ENGINEERINGLABTECHNICIAN Career Focus Mymain objectivein seeking employment withTriumphActuation Systems Inc. is to work in a professionalatmosphere whereIcan utilize my skillsand continueto gain experiencein theaerospaceindustry to advanceinmy career. ProfessionalExperience EngineeringLab TechnicianOct 2016 to Current\n",
      "\n",
      "CompanyNameï¼ City , State\n",
      "\n",
      "- Responsiblefor testing various seatstructures to meetspecificcertification requirements. Â\n",
      "- Maintain and calibratetest instruments to ensuretesting capabilitiesare maintained.\n",
      "- Ensure dataiscaptured and recorded correctly forcertification test reports.\n",
      "- Dutiesalso dynamictestset-up and staticsuitetesting.\n",
      "\n",
      "EngineeringLab Technician, Sr. Specialist Apr 2012 to Oct 2016 CompanyNameï¼ City , State\n",
      "\n",
      "- Utilized skills learned fromLabViewCourse 1 training to constructand maintainLabViewVI programs.\n",
      "- Responsiblefor fabricating and maintaining hydraulic/electricaltestequipment to complete developmentand qualification programs.\n",
      "- Apply engine...\n"
     ]
    }
   ],
   "source": [
    "print(f\"{texts[0][:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95592be",
   "metadata": {},
   "source": [
    "## Filter resumes\n",
    "\n",
    "### Extract education information\n",
    "\n",
    "We begin with a semantic [map](../../api/#semlib.Session.map) to extract education information from the resume. We use the high-capacity `gpt-oss:20b` model (set as the default in the Session constructor above). At this time, there is a bug which prevents structured outputs from this model in Ollama, so we just use it to extract a textual description of the education information as a first step.\n",
    "\n",
    "The following cell takes about 2 minutes to run on an M3 MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847e6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_education_texts = await session.map(\n",
    "    texts,\n",
    "    \"\"\"\n",
    "Given a resume, extract the university, graduation year, degree, and area of study for the most advanced degree the individual has.\n",
    "\n",
    "If some of this information is not present, omit it. If no university education is present, return \"(none)\".\n",
    "\n",
    "Resume:\n",
    "\n",
    "{}\n",
    "\"\"\".strip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70921317",
   "metadata": {},
   "source": [
    "Some of the resumes don't have education information present, in which case the LLM returns \"(none)\". We filter these out using a non-semantic filter, and preview what one of the education infos looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d8a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forsyth Technical Community College, 2011, Associates, Applied Science, Electronics Engineering\n"
     ]
    }
   ],
   "source": [
    "education_texts = [i for i in all_education_texts if i != \"(none)\"]\n",
    "print(education_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92cc95",
   "metadata": {},
   "source": [
    "### Extract structured data\n",
    "\n",
    "We begin by defining a Pydantic model that describes the structured data we want to get. For the `degree` field, we use a `typing.Literal` annotation to restrict the set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b03de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import pydantic\n",
    "\n",
    "\n",
    "class EducationInfo(pydantic.BaseModel):\n",
    "    university: str | None\n",
    "    graduation_year: int | None\n",
    "    degree: Literal[\"Associate\", \"Bachelor\", \"Master\", \"Doctorate\"] | None\n",
    "    area: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998786be",
   "metadata": {},
   "source": [
    "Now, we call `qwen3:8b`, a smaller-capacity LLM (but one that supports structured outputs in Ollama), to convert the text-based descriptions of educational information to the structured data type we defined above.\n",
    "\n",
    "The following cell takes about 30 seconds to run on an M3 MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f2f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "educations = await session.map(\n",
    "    education_texts,\n",
    "    \"\"\"\n",
    "Given the following description of an individual's education, extract the university, graduation year, degree, and area of study.\n",
    "\n",
    "{}\n",
    "\"\"\".strip(),\n",
    "    return_type=EducationInfo,\n",
    "    model=\"ollama_chat/qwen3:8b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac64189",
   "metadata": {},
   "source": [
    "We can take a look at what one of these items looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91aa186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EducationInfo(university='Forsyth Technical Community College', graduation_year=2011, degree='Associate', area='Electronics Engineering')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f90e5",
   "metadata": {},
   "source": [
    "### Filter for resumes with master's degrees\n",
    "\n",
    "As a first step, we construct an `all_educations` list that contains `EducationInfo`s that correspond to the resumes in `files` and `texts` (the `educations` doesn't necessarily contain these, as we filtered out the \"(none)\" cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbce5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_educations: list[EducationInfo | None] = []\n",
    "i = 0\n",
    "for text in all_education_texts:\n",
    "    if text != \"(none)\":\n",
    "        all_educations.append(educations[i])\n",
    "        i += 1\n",
    "    else:\n",
    "        all_educations.append(None)\n",
    "\n",
    "masters = []\n",
    "for file, edu in zip(files, all_educations, strict=False):\n",
    "    if edu is not None and edu.degree == \"Master\":\n",
    "        masters.append((file, edu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2952ad9",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0248351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 resumes with a Master's degree:\n",
      "\n",
      "- data/data/ENGINEERING/10624813.pdf: Union College, 1989, Computer Science\n",
      "- data/data/ENGINEERING/10985403.pdf: Illinois Institute of Technology, 2017, Mechanical & Aerospace Engineering\n",
      "- data/data/ENGINEERING/11890896.pdf: San Francisco State University, 2007, Decision Sciences\n",
      "- data/data/ENGINEERING/11981094.pdf: Illinois Institute of Technology, None, Computer Science\n",
      "- data/data/ENGINEERING/12011623.pdf: University of New Hampshire, 2017, Analytics\n",
      "- data/data/ENGINEERING/12022566.pdf: University at Buffalo, 2014, Industrial Engineering\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(masters)} resumes with a Master's degree:\\n\")\n",
    "for file, edu in masters:\n",
    "    print(f\"- {os.path.join(directory, file)}: {edu.university}, {edu.graduation_year}, {edu.area}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
