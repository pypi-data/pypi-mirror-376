{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a06ca3c",
   "metadata": {},
   "source": [
    "# Medical Tumor Detection and Segmentation System - Development Roadmap\n",
    "\n",
    "This notebook outlines the development plan and implementation strategy for enhancing our medical imaging AI system. We'll cover:\n",
    "\n",
    "1. Advanced model architectures with attention mechanisms\n",
    "2. Optimized data pipelines for medical images\n",
    "3. Production deployment and clinical integration\n",
    "4. Testing and validation protocols\n",
    "5. Performance optimization strategies\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "- **Current Stack**: MONAI, PyTorch, FastAPI, React/TypeScript\n",
    "- **Target Features**: Multi-modal tumor detection, clinical workflow integration, HIPAA compliance\n",
    "- **Focus Areas**: Accuracy, reliability, scalability, clinical usability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c827e6",
   "metadata": {},
   "source": [
    "## 1. Development Environment Setup\n",
    "\n",
    "First, let's ensure our development environment is properly configured with all required dependencies and GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import monai\n",
    "from monai.utils import set_determinism\n",
    "import pytorch_lightning as pl\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set up MONAI deterministic training\n",
    "set_determinism(seed=42)\n",
    "\n",
    "# Configure mixed precision training\n",
    "torch.backends.cudnn.benchmark = True\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Initialize PyTorch Lightning trainer with GPU support\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    precision=16,  # Mixed precision training\n",
    "    max_epochs=100,\n",
    "    logger=True,\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath='checkpoints',\n",
    "            filename='best_model',\n",
    "            monitor='val_loss',\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfda90",
   "metadata": {},
   "source": [
    "## 2. Advanced Model Architecture\n",
    "\n",
    "We'll implement a state-of-the-art architecture for tumor segmentation based on an attention-enhanced UNet with the following features:\n",
    "1. Multi-scale feature extraction\n",
    "2. Self-attention mechanisms\n",
    "3. Deep supervision\n",
    "4. Uncertainty estimation through Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ea448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.blocks import Convolution, UpSample\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv3d(in_channels, in_channels // 8, 1)\n",
    "        self.key = nn.Conv3d(in_channels, in_channels // 8, 1)\n",
    "        self.value = nn.Conv3d(in_channels, in_channels, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, D, H, W = x.size()\n",
    "        query = self.query(x).view(batch_size, -1, D*H*W).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch_size, -1, D*H*W)\n",
    "        energy = torch.bmm(query, key)\n",
    "        attention = self.softmax(energy)\n",
    "        value = self.value(x).view(batch_size, -1, D*H*W)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, D, H, W)\n",
    "        return self.gamma * out + x\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: int = 3,\n",
    "        in_channels: int = 1,\n",
    "        out_channels: int = 1,\n",
    "        features: Tuple[int, ...] = (32, 64, 128, 256, 512),\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.unet = UNet(\n",
    "            dimensions=dimensions,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            channels=features,\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Add attention blocks\n",
    "        self.attention_blocks = nn.ModuleList([\n",
    "            AttentionBlock(feat) for feat in features\n",
    "        ])\n",
    "        \n",
    "        # Deep supervision heads\n",
    "        self.deep_supervision = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv3d(feat, out_channels, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for feat in features\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        features = []\n",
    "        \n",
    "        # Enable dropout during inference for uncertainty estimation\n",
    "        if self.training or return_features:\n",
    "            self.unet.eval()\n",
    "            for m in self.unet.modules():\n",
    "                if isinstance(m, nn.Dropout):\n",
    "                    m.train()\n",
    "        \n",
    "        # Extract features with attention\n",
    "        for i, block in enumerate(self.unet.encoder):\n",
    "            x = block(x)\n",
    "            x = self.attention_blocks[i](x)\n",
    "            features.append(x)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        deep_outputs = [head(feat) for head, feat in zip(self.deep_supervision, features)]\n",
    "        \n",
    "        # Main output\n",
    "        output = self.unet.decoder(features[-1])\n",
    "        \n",
    "        if return_features:\n",
    "            return output, deep_outputs, features\n",
    "        return output\n",
    "\n",
    "# Create model instance\n",
    "model = AttentionUNet(\n",
    "    dimensions=3,  # 3D images\n",
    "    in_channels=1,  # Single channel input (e.g., T1 MRI)\n",
    "    out_channels=1,  # Binary segmentation\n",
    "    features=(32, 64, 128, 256, 512),\n",
    "    dropout=0.3  # For Monte Carlo Dropout uncertainty estimation\n",
    ")\n",
    "\n",
    "# Example of uncertainty estimation using Monte Carlo Dropout\n",
    "def predict_with_uncertainty(\n",
    "    model: nn.Module,\n",
    "    input_tensor: torch.Tensor,\n",
    "    num_samples: int = 30\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform inference with uncertainty estimation using MC Dropout.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        input_tensor: Input image tensor\n",
    "        num_samples: Number of Monte Carlo samples\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (mean prediction, uncertainty)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            pred = model(input_tensor, return_features=False)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    # Stack predictions\n",
    "    predictions = torch.stack(predictions)\n",
    "    \n",
    "    # Calculate mean and uncertainty\n",
    "    mean_pred = torch.mean(predictions, dim=0)\n",
    "    uncertainty = torch.std(predictions, dim=0)\n",
    "    \n",
    "    return mean_pred, uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d565ebf",
   "metadata": {},
   "source": [
    "## 3. Medical Image Pipeline\n",
    "\n",
    "Let's implement an efficient data pipeline for handling medical images with:\n",
    "1. Memory-efficient DICOM loading\n",
    "2. Advanced augmentation strategies\n",
    "3. Quality control checks\n",
    "4. Multi-modal fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20467f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    ScaleIntensityd,\n",
    "    RandRotate90d,\n",
    "    RandZoomd,\n",
    "    RandGaussianNoised,\n",
    "    RandAdjustContrastd,\n",
    "    RandGaussianSmoothd,\n",
    "    SpatialPadd,\n",
    "    RandSpatialCropd,\n",
    "    ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset, ThreadDataLoader, partition_dataset\n",
    "\n",
    "class MedicalImageDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        cache_rate: float = 1.0,\n",
    "        num_workers: int = 4\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.cache_rate = cache_rate\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # Define transforms for training\n",
    "        self.train_transforms = Compose([\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            ScaleIntensityd(keys=[\"image\"]),\n",
    "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 1]),\n",
    "            RandZoomd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                min_zoom=0.9,\n",
    "                max_zoom=1.1,\n",
    "                prob=0.5\n",
    "            ),\n",
    "            RandGaussianNoised(keys=[\"image\"], prob=0.3),\n",
    "            RandAdjustContrastd(keys=[\"image\"], prob=0.3),\n",
    "            RandGaussianSmoothd(keys=[\"image\"], prob=0.3),\n",
    "            SpatialPadd(keys=[\"image\", \"label\"], spatial_size=[192, 192, 64]),\n",
    "            RandSpatialCropd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                roi_size=[192, 192, 64],\n",
    "                random_size=False\n",
    "            ),\n",
    "            ToTensord(keys=[\"image\", \"label\"])\n",
    "        ])\n",
    "        \n",
    "        # Define transforms for validation (no augmentation)\n",
    "        self.val_transforms = Compose([\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            ScaleIntensityd(keys=[\"image\"]),\n",
    "            SpatialPadd(keys=[\"image\", \"label\"], spatial_size=[192, 192, 64]),\n",
    "            ToTensord(keys=[\"image\", \"label\"])\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self, train_files, val_files):\n",
    "        # Create CacheDataset for efficient memory usage\n",
    "        train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=self.train_transforms,\n",
    "            cache_rate=self.cache_rate\n",
    "        )\n",
    "        \n",
    "        val_ds = CacheDataset(\n",
    "            data=val_files,\n",
    "            transform=self.val_transforms,\n",
    "            cache_rate=self.cache_rate\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = ThreadDataLoader(\n",
    "            train_ds,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        val_loader = ThreadDataLoader(\n",
    "            val_ds,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def verify_dicom_quality(dicom_file: str) -> bool:\n",
    "        \"\"\"Verify DICOM file quality and metadata.\"\"\"\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(dicom_file)\n",
    "            \n",
    "            # Check required metadata\n",
    "            required_tags = [\n",
    "                'PatientID',\n",
    "                'StudyDate',\n",
    "                'Modality',\n",
    "                'PixelSpacing',\n",
    "                'SliceThickness'\n",
    "            ]\n",
    "            \n",
    "            for tag in required_tags:\n",
    "                if not hasattr(dcm, tag):\n",
    "                    print(f\"Missing required tag: {tag}\")\n",
    "                    return False\n",
    "            \n",
    "            # Check image quality\n",
    "            if not hasattr(dcm, 'pixel_array'):\n",
    "                print(\"No pixel data found\")\n",
    "                return False\n",
    "            \n",
    "            pixel_array = dcm.pixel_array\n",
    "            \n",
    "            # Check for empty or corrupted images\n",
    "            if pixel_array.size == 0:\n",
    "                print(\"Empty pixel array\")\n",
    "                return False\n",
    "            \n",
    "            # Check image statistics\n",
    "            mean_val = np.mean(pixel_array)\n",
    "            std_val = np.std(pixel_array)\n",
    "            \n",
    "            if mean_val == 0 or std_val == 0:\n",
    "                print(\"Image has no variation\")\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading DICOM file: {e}\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def fuse_modalities(mr_image: torch.Tensor, ct_image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Fuse MR and CT images using attention-based fusion.\n",
    "        \n",
    "        Args:\n",
    "            mr_image: MRI image tensor\n",
    "            ct_image: CT image tensor\n",
    "            \n",
    "        Returns:\n",
    "            Fused image tensor\n",
    "        \"\"\"\n",
    "        # Ensure same size\n",
    "        if mr_image.shape != ct_image.shape:\n",
    "            ct_image = F.interpolate(\n",
    "                ct_image,\n",
    "                size=mr_image.shape[2:],\n",
    "                mode='trilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        mr_attention = torch.sigmoid(mr_image)\n",
    "        ct_attention = torch.sigmoid(ct_image)\n",
    "        \n",
    "        # Normalize attention weights\n",
    "        total_attention = mr_attention + ct_attention\n",
    "        mr_weight = mr_attention / total_attention\n",
    "        ct_weight = ct_attention / total_attention\n",
    "        \n",
    "        # Weighted fusion\n",
    "        fused_image = (mr_weight * mr_image) + (ct_weight * ct_image)\n",
    "        \n",
    "        return fused_image\n",
    "\n",
    "# Example usage\n",
    "dataset = MedicalImageDataset(data_dir=\"path/to/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71407e24",
   "metadata": {},
   "source": [
    "## 4. Production System Design\n",
    "\n",
    "Implement production-ready features including:\n",
    "1. FastAPI endpoints for clinical integration\n",
    "2. HIPAA-compliant security measures\n",
    "3. Monitoring and logging\n",
    "4. Containerized deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Security\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from typing import List, Optional\n",
    "import jwt\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import prometheus_client\n",
    "from prometheus_client import Counter, Histogram\n",
    "import time\n",
    "\n",
    "# Initialize FastAPI app with security\n",
    "app = FastAPI(title=\"Medical Imaging API\")\n",
    "security = HTTPBearer()\n",
    "\n",
    "# CORS configuration\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:3000\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Prometheus metrics\n",
    "PREDICTION_TIME = Histogram(\n",
    "    'prediction_request_latency_seconds',\n",
    "    'Time spent processing prediction request'\n",
    ")\n",
    "PREDICTION_REQUESTS = Counter(\n",
    "    'prediction_requests_total',\n",
    "    'Total number of prediction requests'\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/app.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Security utilities\n",
    "def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)) -> dict:\n",
    "    \"\"\"Verify JWT token and return payload.\"\"\"\n",
    "    try:\n",
    "        payload = jwt.decode(\n",
    "            credentials.credentials,\n",
    "            \"your-secret-key\",  # Use environment variable in production\n",
    "            algorithms=[\"HS256\"]\n",
    "        )\n",
    "        return payload\n",
    "    except jwt.InvalidTokenError:\n",
    "        raise HTTPException(\n",
    "            status_code=401,\n",
    "            detail=\"Invalid authentication token\"\n",
    "        )\n",
    "\n",
    "# API endpoints\n",
    "@app.post(\"/api/v1/predict\")\n",
    "async def predict(\n",
    "    files: List[UploadFile] = File(...),\n",
    "    token: dict = Security(verify_token)\n",
    "):\n",
    "    \"\"\"\n",
    "    Process medical images and return predictions with HIPAA compliance.\n",
    "    \"\"\"\n",
    "    PREDICTION_REQUESTS.inc()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Log request (excluding PHI)\n",
    "        logger.info(\n",
    "            f\"Processing prediction request from user {token['sub']}, \"\n",
    "            f\"files: {len(files)}\"\n",
    "        )\n",
    "        \n",
    "        # Process files\n",
    "        results = []\n",
    "        for file in files:\n",
    "            # Verify DICOM quality\n",
    "            if not MedicalImageDataset.verify_dicom_quality(file.file):\n",
    "                raise HTTPException(\n",
    "                    status_code=400,\n",
    "                    detail=f\"Quality check failed for file {file.filename}\"\n",
    "                )\n",
    "            \n",
    "            # Process image and get prediction\n",
    "            # (Implementation details omitted for brevity)\n",
    "            \n",
    "            results.append({\n",
    "                \"filename\": file.filename,\n",
    "                \"prediction\": \"prediction_result\",\n",
    "                \"confidence\": 0.95,\n",
    "                \"processing_time\": time.time() - start_time\n",
    "            })\n",
    "        \n",
    "        return {\"results\": results}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing request: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=\"Error processing medical images\"\n",
    "        )\n",
    "    finally:\n",
    "        PREDICTION_TIME.observe(time.time() - start_time)\n",
    "\n",
    "# Dockerfile content for containerization\n",
    "dockerfile_content = \"\"\"\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    build-essential \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy requirements and install Python packages\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Create non-root user\n",
    "RUN useradd -m appuser && chown -R appuser:appuser /app\n",
    "USER appuser\n",
    "\n",
    "# Set environment variables\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV MODEL_PATH=/app/models/tumor_detection.pt\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Start application\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\"\"\"\n",
    "\n",
    "print(\"Dockerfile content for containerized deployment:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5d802",
   "metadata": {},
   "source": [
    "## 5. Performance Optimization\n",
    "\n",
    "Implement strategies for optimizing model performance:\n",
    "1. Mixed precision training\n",
    "2. Efficient data loading\n",
    "3. Model quantization\n",
    "4. Batch processing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.quantization\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "class OptimizedInference:\n",
    "    def __init__(self, model: nn.Module, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Enable mixed precision\n",
    "        self.model = self.model.to(device)\n",
    "        if device.type == 'cuda':\n",
    "            self.model = torch.cuda.amp.autocast()(self.model)\n",
    "        \n",
    "        # Quantize model for CPU inference\n",
    "        if device.type == 'cpu':\n",
    "            self.model = torch.quantization.quantize_dynamic(\n",
    "                self.model,\n",
    "                {torch.nn.Linear, torch.nn.Conv3d},\n",
    "                dtype=torch.qint8\n",
    "            )\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_batch(\n",
    "        self,\n",
    "        batch: torch.Tensor,\n",
    "        batch_size: int = 4\n",
    "    ) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Perform efficient batch prediction with mixed precision.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(batch), batch_size):\n",
    "            batch_slice = batch[i:i + batch_size].to(self.device)\n",
    "            \n",
    "            with autocast(enabled=True):\n",
    "                output = self.model(batch_slice)\n",
    "            \n",
    "            results.append(output.cpu())\n",
    "        \n",
    "        return torch.cat(results, dim=0)\n",
    "    \n",
    "    def profile_inference(self, sample_input: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Profile model inference performance.\n",
    "        \"\"\"\n",
    "        with profile(\n",
    "            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            with_stack=True\n",
    "        ) as prof:\n",
    "            with record_function(\"model_inference\"):\n",
    "                self.predict_batch(sample_input)\n",
    "        \n",
    "        print(prof.key_averages().table(\n",
    "            sort_by=\"cuda_time_total\", row_limit=10\n",
    "        ))\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimized_model = OptimizedInference(model, device)\n",
    "\n",
    "# Profile performance\n",
    "sample_input = torch.randn(10, 1, 192, 192, 64)\n",
    "optimized_model.profile_inference(sample_input)\n",
    "\n",
    "# Benchmark inference speed\n",
    "def benchmark_inference(model, input_tensor, num_runs=100):\n",
    "    \"\"\"\n",
    "    Benchmark inference speed.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        with torch.no_grad():\n",
    "            _ = model.predict_batch(input_tensor)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    avg_time = (end_time - start_time) / num_runs\n",
    "    \n",
    "    print(f\"Average inference time: {avg_time:.4f} seconds\")\n",
    "    print(f\"Throughput: {1/avg_time:.2f} images/second\")\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_inference(optimized_model, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29720234",
   "metadata": {},
   "source": [
    "## Next Steps and Implementation Timeline\n",
    "\n",
    "1. Immediate Tasks (1-2 weeks):\n",
    "   - Set up development environment and testing infrastructure\n",
    "   - Implement basic model architecture with attention mechanisms\n",
    "   - Create efficient data pipeline for DICOM processing\n",
    "\n",
    "2. Short-term Goals (2-4 weeks):\n",
    "   - Enhance model with multi-modal fusion and uncertainty estimation\n",
    "   - Implement production API endpoints and security measures\n",
    "   - Set up monitoring and logging infrastructure\n",
    "\n",
    "3. Medium-term Goals (1-2 months):\n",
    "   - Optimize model performance and deployment\n",
    "   - Complete clinical validation and testing\n",
    "   - Implement full GUI functionality\n",
    "   - Prepare documentation and deployment guides\n",
    "\n",
    "4. Long-term Goals (2-3 months):\n",
    "   - Clinical integration and workflow optimization\n",
    "   - Performance monitoring and continuous improvement\n",
    "   - Advanced feature implementation (longitudinal analysis, etc.)\n",
    "\n",
    "## Action Items\n",
    "\n",
    "1. [ ] Create development environment setup script\n",
    "2. [ ] Implement attention-enhanced UNet model\n",
    "3. [ ] Set up DICOM processing pipeline\n",
    "4. [ ] Create API endpoints with security measures\n",
    "5. [ ] Implement performance optimization features\n",
    "6. [ ] Set up monitoring and logging\n",
    "7. [ ] Complete documentation and deployment guides\n",
    "\n",
    "Monitor the GitHub project board for detailed task tracking and progress updates."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
