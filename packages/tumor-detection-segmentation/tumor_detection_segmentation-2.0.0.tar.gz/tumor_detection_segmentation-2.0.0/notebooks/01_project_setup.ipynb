{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffce7d9",
   "metadata": {},
   "source": [
    "# Project Setup: Tumor Detection and Segmentation with MONAI\n",
    "\n",
    "This notebook guides you through setting up the directory structure and essential files for a MONAI-based tumor detection and segmentation project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530273c2",
   "metadata": {},
   "source": [
    "## 1. Create Directory Structure\n",
    "\n",
    "Run the following commands in your terminal to create the recommended project structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ef21d",
   "metadata": {},
   "source": [
    "### (Optional) Create and Activate a Virtual Environment\n",
    "\n",
    "It is recommended to use a Python virtual environment for dependency isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0a95b",
   "metadata": {},
   "source": [
    "#### If you get a \"Permission denied\" error when creating directories, use `sudo`:\n",
    "\n",
    "You may need administrator rights to create directories in some locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1db60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'sudo' if you get a permission error (run in terminal)\n",
    "!sudo mkdir -p tumor-detection-segmentation/data tumor-detection-segmentation/models tumor-detection-segmentation/notebooks tumor-detection-segmentation/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and activate a virtual environment (run in terminal)\n",
    "!python3 -m venv venv\n",
    "# On Linux/macOS, activate with:\n",
    "# source venv/bin/activate\n",
    "# On Windows, activate with:\n",
    "# .\\venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa60161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get a permission error, try running with 'sudo' (in terminal, not in Jupyter):\n",
    "# !sudo mkdir -p tumor-detection-segmentation/data tumor-detection-segmentation/models tumor-detection-segmentation/notebooks tumor-detection-segmentation/src\n",
    "# !sudo touch tumor-detection-segmentation/src/__init__.py\n",
    "# !sudo touch tumor-detection-segmentation/src/train.py tumor-detection-segmentation/src/evaluate.py tumor-detection-segmentation/src/inference.py\n",
    "# !sudo touch tumor-detection-segmentation/src/data_preprocessing.py tumor-detection-segmentation/src/dataset.py tumor-detection-segmentation/src/utils.py\n",
    "# !sudo touch tumor-detection-segmentation/requirements.txt tumor-detection-segmentation/.gitignore tumor-detection-segmentation/README.md tumor-detection-segmentation/config.json\n",
    "\n",
    "# If you do not have sudo access or are working in a restricted environment (e.g., JupyterHub), \n",
    "# create the project inside your home directory or another location where you have write permissions:\n",
    "import os\n",
    "\n",
    "base_dir = os.path.expanduser(\"~/tumor-detection-segmentation\")\n",
    "os.makedirs(os.path.join(base_dir, \"data\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, \"models\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, \"notebooks\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, \"src\"), exist_ok=True)\n",
    "\n",
    "for fname in [\n",
    "    \"src/__init__.py\",\n",
    "    \"src/train.py\",\n",
    "    \"src/evaluate.py\",\n",
    "    \"src/inference.py\",\n",
    "    \"src/data_preprocessing.py\",\n",
    "    \"src/dataset.py\",\n",
    "    \"src/utils.py\",\n",
    "    \"requirements.txt\",\n",
    "    \".gitignore\",\n",
    "    \"README.md\",\n",
    "    \"config.json\"\n",
    "]:\n",
    "    fpath = os.path.join(base_dir, fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        open(fpath, \"a\").close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf553b4",
   "metadata": {},
   "source": [
    "## 2. Add Python Dependencies\n",
    "\n",
    "List the required Python libraries in `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd26894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dependencies to requirements.txt\n",
    "requirements = \"\"\"monai\n",
    "torch\n",
    "torchvision\n",
    "numpy\n",
    "matplotlib\n",
    "pandas\n",
    "scikit-learn\n",
    "scipy\n",
    "tqdm\n",
    "jupyter\n",
    "\"\"\"\n",
    "with open(\"tumor-detection-segmentation/requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f408cd",
   "metadata": {},
   "source": [
    "## 3. Configure .gitignore\n",
    "\n",
    "Add common patterns to ignore unnecessary files and folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e446604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write .gitignore content\n",
    "gitignore = \"\"\"# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "\n",
    "# Jupyter Notebook checkpoints\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Virtual environments\n",
    "venv/\n",
    ".env/\n",
    "\n",
    "# Data and models\n",
    "data/\n",
    "models/\n",
    "\"\"\"\n",
    "with open(\"tumor-detection-segmentation/.gitignore\", \"w\") as f:\n",
    "    f.write(gitignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41deae",
   "metadata": {},
   "source": [
    "## 4. Create Project Documentation\n",
    "\n",
    "Add a `README.md` file to describe the project and setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9401b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write README.md content\n",
    "readme = \"\"\"# Tumor Detection and Segmentation using MONAI\n",
    "\n",
    "This project uses MONAI for detecting and segmenting tumors in MRI or CT images.\n",
    "\n",
    "## Directory Structure\n",
    "- `data/`: Store datasets here.\n",
    "- `models/`: Save trained models here.\n",
    "- `notebooks/`: Jupyter notebooks for experiments.\n",
    "- `src/`: Source code for training, evaluation, and inference.\n",
    "\n",
    "## Setup\n",
    "1. Clone the repository.\n",
    "2. Install dependencies:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. Run the training script:\n",
    "   ```bash\n",
    "   python src/train.py\n",
    "   ```\n",
    "\"\"\"\n",
    "with open(\"tumor-detection-segmentation/README.md\", \"w\") as f:\n",
    "    f.write(readme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed7ed3",
   "metadata": {},
   "source": [
    "## 5. Add Configuration File\n",
    "\n",
    "Create a `config.json` file with default settings for training and data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f827c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write config.json content\n",
    "import json\n",
    "config = {\n",
    "  \"data_path\": \"./data\",\n",
    "  \"model_save_path\": \"./models\",\n",
    "  \"batch_size\": 16,\n",
    "  \"epochs\": 50,\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"image_size\": [128, 128, 128],\n",
    "  \"num_workers\": 4,\n",
    "  \"device\": \"cuda\"\n",
    "}\n",
    "with open(\"tumor-detection-segmentation/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb7cbb",
   "metadata": {},
   "source": [
    "## 6. Example Training Script\n",
    "\n",
    "Below is a starter script for training a UNet model using MONAI. Save this as `src/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d5e493",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example: src/train.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmonai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnetworks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNet\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmonai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Compose, LoadImage, EnsureChannelFirst, Resize, ScaleIntensity, ToTensor\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Example: src/train.py\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Compose, LoadImage, EnsureChannelFirst, Resize, ScaleIntensity, ToTensor\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load configuration\n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(config[\"device\"] if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    EnsureChannelFirst(),\n",
    "    Resize(config[\"image_size\"]),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataset and dataloaders\n",
    "train_dataset = Dataset(data=[], transform=train_transforms)  # Replace `data=[]` with your dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"])\n",
    "\n",
    "# Define model, loss, and optimizer\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{config['epochs']}, Loss: {epoch_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a25c6",
   "metadata": {},
   "source": [
    "## 7. Open in VS Code\n",
    "\n",
    "Open the project directory in VS Code and install the Python extension for best experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3586b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the project in VS Code (run in terminal)\n",
    "!code tumor-detection-segmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
