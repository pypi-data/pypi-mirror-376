{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fda24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative Review Task 01: Tumor Detection Model Assessment\n",
    "\n",
    "This notebook provides comprehensive qualitative assessment of the tumor detection segmentation model, including:\n",
    "\n",
    "1. **Training Progress Review** - Visualize training overlays\n",
    "2. **Inference Results Review** - Examine inference overlays\n",
    "3. **Model Performance Analysis** - Compare ground truth vs predictions\n",
    "4. **Visual Quality Assessment** - Multi-slice overlay panels\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ff2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd68b52",
   "metadata": {},
   "source": [
    "## 1. Training Overlay Review\n",
    "\n",
    "Examine training validation overlays to assess model learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find training overlay files\n",
    "training_overlay_dir = project_root / \"models\" / \"unetr\" / \"overlays\"\n",
    "training_overlays = list(training_overlay_dir.glob(\"*.png\")) if training_overlay_dir.exists() else []\n",
    "\n",
    "print(f\"Training overlay directory: {training_overlay_dir}\")\n",
    "print(f\"Found {len(training_overlays)} training overlay files\")\n",
    "\n",
    "if training_overlays:\n",
    "    print(\"\\nAvailable training overlays:\")\n",
    "    for i, overlay_path in enumerate(training_overlays[:10]):  # Show first 10\n",
    "        print(f\"  {i+1:2d}. {overlay_path.name}\")\n",
    "    if len(training_overlays) > 10:\n",
    "        print(f\"  ... and {len(training_overlays) - 10} more\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training overlays found. Run training with validation to generate overlays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80647b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display recent training overlays\n",
    "if training_overlays:\n",
    "    # Show the most recent 6 overlays in a 2x3 grid\n",
    "    recent_overlays = sorted(training_overlays)[-6:]  # Last 6 files\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, overlay_path in enumerate(recent_overlays):\n",
    "        if i < len(axes):\n",
    "            img = Image.open(overlay_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Training: {overlay_path.name}\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(recent_overlays), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.suptitle(\"Recent Training Validation Overlays (Green=GT, Red=Pred)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"üìù To generate training overlays:\")\n",
    "    print(\"   1. Run: python src/training/train_enhanced.py --validate\")\n",
    "    print(\"   2. Overlays will be saved to models/unetr/overlays/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109e56c",
   "metadata": {},
   "source": [
    "## 2. Inference Results Review\n",
    "\n",
    "Examine inference overlays to assess model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e721eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find inference overlay files\n",
    "inference_overlay_dirs = list(project_root.glob(\"reports/**/inference_overlays\"))\n",
    "all_inference_overlays = []\n",
    "\n",
    "for overlay_dir in inference_overlay_dirs:\n",
    "    overlays = list(overlay_dir.glob(\"*.png\"))\n",
    "    all_inference_overlays.extend(overlays)\n",
    "\n",
    "print(f\"Found {len(inference_overlay_dirs)} inference overlay directories\")\n",
    "print(f\"Total inference overlays: {len(all_inference_overlays)}\")\n",
    "\n",
    "if all_inference_overlays:\n",
    "    print(\"\\nAvailable inference overlays:\")\n",
    "    for i, overlay_path in enumerate(all_inference_overlays[:10]):  # Show first 10\n",
    "        print(f\"  {i+1:2d}. {overlay_path.parent.parent.name}/{overlay_path.name}\")\n",
    "    if len(all_inference_overlays) > 10:\n",
    "        print(f\"  ... and {len(all_inference_overlays) - 10} more\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No inference overlays found. Run inference with --save_overlays to generate overlays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e640be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference overlays\n",
    "if all_inference_overlays:\n",
    "    # Show up to 6 inference overlays in a 2x3 grid\n",
    "    display_overlays = all_inference_overlays[:6]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, overlay_path in enumerate(display_overlays):\n",
    "        if i < len(axes):\n",
    "            img = Image.open(overlay_path)\n",
    "            axes[i].imshow(img)\n",
    "            case_name = overlay_path.name.replace('_overlay.png', '')\n",
    "            axes[i].set_title(f\"Inference: {case_name}\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(display_overlays), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.suptitle(\"Inference Results Overlays (Green=GT, Red=Pred)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"üìù To generate inference overlays:\")\n",
    "    print(\"   1. Run: python src/inference/inference.py --input data/ --save_overlays\")\n",
    "    print(\"   2. Overlays will be saved to reports/inference_overlays/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee48dd8",
   "metadata": {},
   "source": [
    "## 3. Visual Quality Assessment\n",
    "\n",
    "Interactive review of overlay quality and recommendations for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality assessment checklist\n",
    "quality_checklist = {\n",
    "    \"Multi-slice Visualization\": \"‚úì Implemented (25%, 50%, 75% depth slices)\",\n",
    "    \"Color Coding\": \"‚úì Green for Ground Truth, Red for Predictions\",\n",
    "    \"Transparency\": \"‚úì Alpha blending for overlay clarity\",\n",
    "    \"Directory Organization\": \"‚úì Proper subdirectories for training/inference\",\n",
    "    \"File Naming\": \"‚úì Consistent naming convention\",\n",
    "    \"Resolution\": \"‚úì High DPI (150) for clear visualization\"\n",
    "}\n",
    "\n",
    "print(\"Overlay Quality Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "for feature, status in quality_checklist.items():\n",
    "    print(f\"{feature:25s}: {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Recommendations for Model Review:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. üîç Examine overlap patterns: Good predictions show red-green overlap\",\n",
    "    \"2. üìè Check tumor size detection: Compare small vs large tumor accuracy\",\n",
    "    \"3. üéØ Assess edge quality: Sharp boundaries indicate good segmentation\",\n",
    "    \"4. üß† Review false positives: Red areas without green indicate over-prediction\",\n",
    "    \"5. ‚ö†Ô∏è  Check false negatives: Green areas without red indicate under-prediction\",\n",
    "    \"6. üìä Monitor training progression: Later validation overlays should show improvement\",\n",
    "    \"7. üîÑ Compare slice consistency: Adjacent slices should show coherent segmentation\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c458b2",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides a comprehensive framework for qualitative assessment of the tumor detection model. \n",
    "\n",
    "### Key Features:\n",
    "- **Training Progress Monitoring**: Visual assessment of model learning through validation overlays\n",
    "- **Inference Quality Review**: Examination of model performance on test cases\n",
    "- **Multi-slice Visualization**: Enhanced overlay panels showing 25%, 50%, 75% depth slices\n",
    "- **Systematic Analysis**: Framework for overlay coverage and quality assessment\n",
    "\n",
    "### Usage Workflow:\n",
    "1. **During Training**: Monitor validation overlays to assess learning progress\n",
    "2. **After Training**: Run inference with overlay generation on test data\n",
    "3. **Model Review**: Use this notebook to systematically evaluate results\n",
    "4. **Iteration**: Identify areas for improvement and retrain as needed\n",
    "\n",
    "### Next Steps:\n",
    "- Run training with validation to generate training overlays\n",
    "- Run inference with `--save_overlays` flag to generate test overlays\n",
    "- Use the recommendations above to assess model quality\n",
    "- Iterate on model architecture or training parameters based on visual feedback"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
