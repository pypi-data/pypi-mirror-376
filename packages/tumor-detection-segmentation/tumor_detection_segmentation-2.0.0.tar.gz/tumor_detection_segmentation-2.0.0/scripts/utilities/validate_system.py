#!/usr/bin/env python3
"""
System validation and feature demonstration script
Tests all implemented features and provides comprehensive overview
"""

import json
import os
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

print("ğŸ¥ Enhanced Medical Imaging AI System Validation")
print("=" * 55)

# Test imports and availability
print("\nğŸ“¦ Testing Package Availability:")

# Core packages
packages = {
    "torch": "PyTorch",
    "numpy": "NumPy",
    "monai": "MONAI",
    "mlflow": "MLflow",
    "nibabel": "NiBabel",
    "pydicom": "PyDICOM",
    "matplotlib": "Matplotlib",
    "sklearn": "Scikit-learn"
}

available_packages = {}
for package, name in packages.items():
    try:
        __import__(package)
        print(f"  âœ… {name}")
        available_packages[package] = True
    except ImportError:
        print(f"  âŒ {name} - Not available")
        available_packages[package] = False

# Test custom modules
print("\nğŸ§© Testing Custom Modules:")
custom_modules = {
    "src.data.preprocess": "Enhanced Data Preprocessing",
    "src.fusion.attention_fusion": "Multi-modal Fusion",
    "src.models.cascade_detector": "Cascade Detection",
    "src.utils.logging_mlflow": "MLflow Integration",
    "src.training.train_enhanced": "Enhanced Training"
}

available_modules = {}
for module, name in custom_modules.items():
    try:
        __import__(module)
        print(f"  âœ… {name}")
        available_modules[module] = True
    except ImportError as e:
        print(f"  âŒ {name} - {e}")
        available_modules[module] = False

# Test MONAI features if available
if available_packages.get("monai", False):
    print("\nğŸ§  Testing MONAI Features:")

    try:
        from monai.networks.nets import UNETR, UNet
        print("  âœ… Neural Networks (UNet, UNETR)")
    except ImportError:
        print("  âŒ Neural Networks")

    try:
        from monai.transforms import Compose, LoadImaged
        print("  âœ… Data Transforms")
    except ImportError:
        print("  âŒ Data Transforms")

    try:
        from monai.losses import DiceLoss, FocalLoss
        print("  âœ… Loss Functions")
    except ImportError:
        print("  âŒ Loss Functions")

    try:
        from monai.metrics import DiceMetric, HausdorffDistanceMetric
        print("  âœ… Evaluation Metrics")
    except ImportError:
        print("  âŒ Evaluation Metrics")

# Test MLflow if available
if available_packages.get("mlflow", False):
    print("\nğŸ“Š Testing MLflow Integration:")

    try:
        import mlflow
        mlflow.set_tracking_uri("file:scripts/validation/test_mlruns")
        print("  âœ… MLflow Tracking")

        # Test logging
        with mlflow.start_run():
            mlflow.log_param("test_param", "test_value")
            mlflow.log_metric("test_metric", 0.85)
        print("  âœ… Parameter & Metric Logging")

    except Exception as e:
        print(f"  âŒ MLflow Integration - {e}")

# Test GPU availability
print("\nâš¡ Testing GPU Availability:")
if available_packages.get("torch", False):
    import torch

    if torch.cuda.is_available():
        print(f"  âœ… CUDA GPU: {torch.cuda.get_device_name(0)}")
        print(f"     Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        print(f"     CUDA Version: {torch.version.cuda}")
    else:
        print("  âš ï¸  No CUDA GPU detected")

    # Test ROCm
    try:
        if torch.version.hip:
            print(f"  âœ… ROCm GPU Support: {torch.version.hip}")
    except:
        print("  âš ï¸  No ROCm support detected")
else:
    print("  âŒ Cannot test GPU - PyTorch not available")

# Test model creation
print("\nğŸ¤– Testing Model Creation:")
if available_modules.get("src.fusion.attention_fusion", False):
    try:
        from src.fusion.attention_fusion import create_multi_modal_model

        # Test UNETR creation
        model = create_multi_modal_model("unetr", "early")
        params = sum(p.numel() for p in model.parameters())
        print(f"  âœ… Multi-modal UNETR: {params:,} parameters")

        # Test UNet creation
        model = create_multi_modal_model("unet")
        params = sum(p.numel() for p in model.parameters())
        print(f"  âœ… Standard UNet: {params:,} parameters")

    except Exception as e:
        print(f"  âŒ Model Creation - {e}")

# Test cascade pipeline
if available_modules.get("src.models.cascade_detector", False):
    try:
        from src.models.cascade_detector import create_cascade_pipeline

        pipeline = create_cascade_pipeline()
        total_params = sum(p.numel() for p in pipeline.parameters())
        print(f"  âœ… Cascade Pipeline: {total_params:,} parameters")

    except Exception as e:
        print(f"  âŒ Cascade Pipeline - {e}")

# Test configuration recipes
print("\nâš™ï¸  Testing Configuration Recipes:")
config_dir = project_root / "config" / "recipes"
if config_dir.exists():
    configs = list(config_dir.glob("*.json"))
    for config_file in configs:
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            print(f"  âœ… {config_file.name}")
        except Exception as e:
            print(f"  âŒ {config_file.name} - {e}")
else:
    print("  âŒ Configuration directory not found")

# Test data preprocessing
print("\nğŸ“Š Testing Data Preprocessing:")
if available_modules.get("src.data.preprocess", False):
    try:
        from src.data.preprocess import EnhancedDataPreprocessing

        config = {
            "target_spacing": [1.0, 1.0, 1.0],
            "spatial_size": [128, 128, 128],
            "patch_size": [96, 96, 96],
            "max_epochs": 100,
        }

        preprocessor = EnhancedDataPreprocessing(config)
        print("  âœ… Enhanced Data Preprocessing")

        # Test transforms
        train_transforms = preprocessor.get_training_transforms()
        val_transforms = preprocessor.get_validation_transforms()
        print(f"  âœ… Training Transforms: {len(train_transforms.transforms)} steps")
        print(f"  âœ… Validation Transforms: {len(val_transforms.transforms)} steps")

    except Exception as e:
        print(f"  âŒ Data Preprocessing - {e}")

# Test file structure
print("\nğŸ“ Testing File Structure:")
required_dirs = [
    "src/data",
    "src/models",
    "src/training",
    "src/fusion",
    "src/utils",
    "config/recipes",
    "scripts/setup",
    "scripts/utilities",
    "monai_label_app"
]

for dir_path in required_dirs:
    full_path = project_root / dir_path
    if full_path.exists():
        print(f"  âœ… {dir_path}")
    else:
        print(f"  âŒ {dir_path}")

# Test scripts
print("\nğŸ”§ Testing Scripts:")
script_files = [
    "scripts/setup/setup_monai_label.sh",
    "scripts/utilities/run_monai_label.sh",
    "scripts/utilities/start_medical_gui.sh"
]

for script_path in script_files:
    full_path = project_root / script_path
    if full_path.exists() and os.access(full_path, os.X_OK):
        print(f"  âœ… {script_path} (executable)")
    elif full_path.exists():
        print(f"  âš ï¸  {script_path} (not executable)")
    else:
        print(f"  âŒ {script_path} (missing)")

# Test Docker files
print("\nğŸ³ Testing Docker Configuration:")
docker_files = [
    "config/docker/Dockerfile.cuda",
    "config/docker/Dockerfile.rocm",
    "config/docker/docker-compose.yml"
]

for docker_file in docker_files:
    full_path = project_root / docker_file
    if full_path.exists():
        print(f"  âœ… {docker_file}")
    else:
        print(f"  âŒ {docker_file}")

# Generate summary report
print("\nğŸ“‹ SYSTEM VALIDATION SUMMARY")
print("=" * 40)

total_packages = len(packages)
available_package_count = sum(available_packages.values())
package_score = (available_package_count / total_packages) * 100

total_modules = len(custom_modules)
available_module_count = sum(available_modules.values())
module_score = (available_module_count / total_modules) * 100

print(f"Package Availability: {available_package_count}/{total_packages} ({package_score:.1f}%)")
print(f"Custom Modules: {available_module_count}/{total_modules} ({module_score:.1f}%)")

# Overall system status
overall_score = (package_score + module_score) / 2

if overall_score >= 90:
    status = "ğŸŸ¢ EXCELLENT"
elif overall_score >= 75:
    status = "ğŸŸ¡ GOOD"
elif overall_score >= 50:
    status = "ğŸŸ  FAIR"
else:
    status = "ğŸ”´ NEEDS WORK"

print(f"\nOverall System Status: {status} ({overall_score:.1f}%)")

# Next steps recommendations
print("\nğŸ¯ NEXT STEPS:")
if available_package_count < total_packages:
    print("1. Install missing packages: pip install -r requirements.txt")

if not available_packages.get("monai", False):
    print("2. Install MONAI: pip install monai")

if not available_packages.get("mlflow", False):
    print("3. Install MLflow: pip install mlflow")

print("4. Run setup script: ./scripts/setup/setup_monai_label.sh")
print("5. Start system: ./scripts/utilities/start_medical_gui.sh")
print("6. Test training: python src/training/train_enhanced.py --config config/recipes/unetr_multimodal.json")

print("\nğŸ‰ ENHANCED FEATURES AVAILABLE:")
print("â€¢ Multi-modal MRI processing (T1, T1c, T2, FLAIR)")
print("â€¢ Cross-attention fusion architectures")
print("â€¢ Detection + segmentation cascade")
print("â€¢ MONAI Label interactive annotation")
print("â€¢ MLflow experiment tracking")
print("â€¢ Modality-specific normalization")
print("â€¢ Curriculum augmentation")
print("â€¢ Test-time augmentation")
print("â€¢ Uncertainty estimation")
print("â€¢ Docker deployment")
print("â€¢ Comprehensive configuration recipes")

print("\nâœ… System validation completed!")
print("ğŸ¥ Ready for advanced medical imaging AI research and applications!")
