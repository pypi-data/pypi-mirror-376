Metadata-Version: 2.3
Name: exploitai
Version: 0.4.0
Summary: AI Model Security Testing Framework for research and education
Keywords: machine-learning,security,privacy,federated-learning,attacks
Author: Tanguy VANSNICK
Author-email: Tanguy VANSNICK <191451@umons.ac.be>
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Security
Requires-Dist: torch>=2.0.0
Requires-Dist: torchvision>=0.15.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: matplotlib>=3.6.0
Requires-Dist: tqdm>=4.64.0
Requires-Dist: pytest>=7.0.0 ; extra == 'dev'
Requires-Dist: pytest-cov>=4.0.0 ; extra == 'dev'
Requires-Dist: ruff>=0.1.0 ; extra == 'dev'
Requires-Dist: mypy>=1.5.0 ; extra == 'dev'
Requires-Python: >=3.11
Provides-Extra: dev
Description-Content-Type: text/markdown

# ExploitAI

AI Model Security Testing Framework for research and education.

## Overview

ExploitAI is a Python library designed to demonstrate and test security vulnerabilities in machine learning models. It focuses on:

- **Gradient Inversion Attacks** (DLG, iDLG, GIAS)
- **Membership Inference Attacks** (Shokri et al., variations)  
- **Model Poisoning Attacks** (data poisoning, Byzantine attacks)

## Installation

```bash
pip install exploitai
```

## Quick Start

```python
import exploitai as ea

# Load a pre-trained model
model = ea.models.load_model("resnet18", pretrained=True)

# Run gradient inversion attack
attack = ea.GradientInversion(method="idlg")
results = attack.run(model, target_gradients)

# Generate security report
ea.generate_report(results, output="security_audit.html")
```

## Purpose

This library is developed for:

- **Security Research**: Understanding ML model vulnerabilities
- **Educational Use**: Teaching AI security concepts  
- **Defensive Testing**: Evaluating model robustness

**Note**: This tool is intended for defensive security research and education only.

## Development Status

ðŸš§ **Alpha Release** - Core framework and basic attacks in development

## License

MIT License - see LICENSE file for details.