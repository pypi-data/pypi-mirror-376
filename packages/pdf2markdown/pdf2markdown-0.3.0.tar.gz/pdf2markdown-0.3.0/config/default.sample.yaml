# PDF to Markdown Converter - Configuration File
# =================================================
# This is a sample configuration file for the pdf2markdown application.
# 
# To use this configuration:
# 1. Copy this file to 'default.yaml' in the same directory
# 2. Update the values according to your setup
# 3. Ensure sensitive values (like API keys) are set via environment variables
#
# Configuration values are loaded in the following priority order:
# 1. Default values in code
# 2. This configuration file
# 3. Environment variables (override config file)
# 4. Command-line arguments (highest priority)
#
# Environment variables can be referenced using ${VARIABLE_NAME} syntax

# ==============================================================================
# LLM PROVIDER CONFIGURATION
# ==============================================================================
# The LLM provider section configures how the application connects to and uses
# Large Language Models for converting PDF pages to Markdown.
# This configuration is shared across all components that need LLM access.

llm_provider:
  # Provider type - determines which LLM integration to use
  # Currently supported: "openai" (for any OpenAI-compatible API)
  # Future support planned for: "transformers", "ollama", "anthropic", "google"
  provider_type: openai
  
  # API endpoint URL
  # For OpenAI: https://api.openai.com/v1
  # For Azure OpenAI: https://your-resource.openai.azure.com/
  # For local servers: http://localhost:8080/v1
  # Can use environment variable: ${OPENAI_API_ENDPOINT}
  endpoint: https://api.openai.com/v1
  
  # API authentication key
  # IMPORTANT: Use environment variables for production!
  # Example: ${OPENAI_API_KEY}
  # For local servers without auth, you can use: "not-required"
  api_key: ${OPENAI_API_KEY}
  
  # Model identifier
  # OpenAI models: gpt-4o, gpt-4o-mini, gpt-4-vision-preview
  # Local models: depends on your server (e.g., llava:13b, cogvlm-chat, etc.)
  # Can use environment variable: ${OPENAI_MODEL}
  model: gpt-4o-mini
  
  # Maximum tokens in the response
  # Higher values allow longer responses but cost more
  # Typical ranges: 2048-8192 for most models, up to 128000 for some
  max_tokens: 4096
  
  # Temperature for generation (0.0 to 2.0)
  # Lower = more deterministic/consistent
  # Higher = more creative/varied
  # Recommended: 0.1-0.3 for technical documents
  temperature: 0.3
  
  # Request timeout in seconds
  # Increase for slower servers or large documents
  # Local models might need 300-900 seconds
  timeout: 60
  
  # ==== REPETITION PENALTY PARAMETERS ====
  # These parameters help reduce repetitive text in generated markdown
  # Not all providers support all parameters - unused ones are ignored
  
  # Presence penalty (-2.0 to 2.0) - OpenAI style
  # Positive values penalize tokens that have appeared
  # Recommended: 0.0-0.5 for technical documents
  presence_penalty: 0.1
  
  # Frequency penalty (-2.0 to 2.0) - OpenAI style  
  # Positive values penalize tokens based on their frequency
  # Recommended: 0.0-0.5 for technical documents
  frequency_penalty: 0.1
  
  # Repetition penalty (0.0 to 2.0) - Alternative parameter
  # Used by some local models instead of presence/frequency
  # Values > 1.0 reduce repetition
  # Recommended: 1.05-1.15 for technical documents
  repetition_penalty: 1.05

# ==============================================================================
# DOCUMENT PARSER CONFIGURATION
# ==============================================================================
# Controls how PDF documents are processed and converted to images

document_parser:
  # Parser implementation type
  # Currently only "simple" is available (uses PyMuPDF)
  type: simple
  
  # Resolution for rendering PDF pages to images (DPI)
  # Higher = better quality but larger files and slower processing
  # Recommended: 200-300 for text, 300-400 for detailed diagrams
  resolution: 300
  
  # Maximum dimension for the longest side of rendered images (in pixels)
  # If specified, images will be resized after rendering to ensure the
  # longest side (width or height) is exactly this many pixels
  # This helps control memory usage and processing time for very large documents
  # Leave unset (or set to null) to use the original rendered size
  # Example: 2048 would resize images so the longest side is 2048 pixels
  # max_dimension: 2048  # Optional, uncomment to enable
  
  # Directory for caching rendered page images
  # Images are automatically cleaned up after processing
  # Use absolute paths or paths relative to working directory
  # Note: This is used for legacy compatibility. New cache system uses cache.base_dir
  cache_dir: /tmp/pdf2markdown/cache
  
  # Enable caching of rendered images (recommended)
  # Set to false to always re-render images (slower but uses less disk space)
  use_cache: true
  
  # Maximum size for a single page image in bytes
  # Pages exceeding this will generate warnings
  # 50MB default should handle most documents
  max_page_size: 50000000  # 50MB
  
  # Timeout for rendering operations in seconds
  # Increase if you have very complex PDFs
  timeout: 30

# ==============================================================================
# PAGE PARSER CONFIGURATION
# ==============================================================================
# Controls how individual pages are converted from images to Markdown

page_parser:
  # Parser implementation type
  # Currently only "simple_llm" is available
  type: simple_llm
  
  # Table format configuration
  # "html" - Use HTML <table> tags for complex table layouts (default, recommended)
  #          Preserves merged cells, nested tables, complex alignments
  # "markdown" - Use Markdown pipe syntax for simple tables
  #              Better for simple tables, may lose complex formatting
  table_format: html
  
  # Path to custom prompt template (Jinja2 format)
  # Leave as null to use the default template
  # Path can be absolute or relative to working directory
  # prompt_template: /path/to/custom/template.j2
  
  # Additional instructions to append to the LLM prompt
  # Useful for document-specific requirements
  # Example: "Pay special attention to chemical formulas"
  # additional_instructions: null
  
  # ==== CONTENT VALIDATION PIPELINE ====
  # Controls validation and correction of generated content
  
  # Enable/disable content validation entirely
  validate_content: true
  
  # Enable caching of LLM-generated markdown (recommended)
  # Set to false to always regenerate content (more expensive but always fresh)
  use_cache: true
  
  # Validation pipeline configuration
  validation:
    # List of validators to run (in order)
    # Available validators: "markdown", "repetition"
    validators: ["markdown", "repetition"]
    
    # Maximum number of correction attempts
    # If issues persist after this many attempts, use the best version
    max_correction_attempts: 2
    
    # ==== MARKDOWN VALIDATOR ====
    # Validates markdown syntax and formatting
    markdown:
      # Enable/disable this validator
      enabled: true
      
      # Attempt to correct validation issues by re-prompting the LLM
      attempt_correction: true
      
      # Strict mode applies more rigorous validation rules
      # Recommended: false for LLM-generated content
      strict_mode: false
      
      # Maximum line length for MD013 rule
      # Technical content often needs longer lines
      max_line_length: 1000
      
      # Additional rules to disable beyond the defaults
      # Format: ["MD001", "MD002"] using rule IDs from pymarkdownlnt
      disabled_rules: []
      
      # Specific rules to enable that are disabled by default
      # Format: ["MD001", "MD002"] using rule IDs from pymarkdownlnt
      enabled_rules: []
      
      # Default disabled rules (for reference):
      # - MD013: Line length (technical content often has long lines)
      # - MD047: Files must end with single newline
      # - MD041: First line should be a top-level heading
      # - MD012: Multiple consecutive blank lines
      # - MD022: Headings should be surrounded by blank lines
      # - MD031: Fenced code blocks should be surrounded by blank lines
      # - MD032: Lists should be surrounded by blank lines
      # - MD025: Multiple top-level headings
      # - MD024: Multiple headings with the same content
      # - MD040: Fenced code blocks should have a language specified
      # - MD033: Inline HTML (common in technical documents and tables)
      # - MD026: Trailing punctuation in headings (common in PDF headings)
      # - MD042: No empty links (LLMs may generate placeholder links)
      # - MD036: Emphasis possibly used instead of a heading element
    
    # ==== REPETITION VALIDATOR ====
    # Detects and corrects unwanted repetition in content
    repetition:
      # Enable/disable this validator
      enabled: true
      
      # Attempt to correct repetition issues by re-prompting the LLM
      attempt_correction: true
      
      # Detection thresholds
      consecutive_threshold: 3  # Flag if line repeats 3+ times consecutively
      window_size: 10  # Check for duplicates within 10-line windows
      window_threshold: 3  # Flag if line appears 3+ times in window
      
      # What to check
      check_exact_lines: true  # Exact line matches
      check_normalized_lines: true  # Ignore whitespace/punctuation differences
      check_paragraphs: true  # Check for duplicate paragraphs
      check_patterns: true  # Detect repetitive patterns
      
      # Pattern detection settings
      min_pattern_length: 20  # Minimum chars for pattern detection
      pattern_similarity_threshold: 0.9  # How similar patterns must be (0-1)
      min_line_length: 5  # Minimum line length to check

# ==============================================================================
# PIPELINE CONFIGURATION
# ==============================================================================
# Controls the processing pipeline and worker management

pipeline:
  # Number of document processing workers
  # MUST BE 1 - PyMuPDF requires sequential document access
  document_workers: 1
  
  # Number of parallel page processing workers
  # Each worker processes one page at a time
  # More workers = faster processing (limited by API rate limits)
  # Recommended: 5-10 for cloud APIs, 1-3 for local models
  page_workers: 10
  
  # Queue size configuration
  queues:
    # Maximum documents in the document queue
    document_queue_size: 100
    
    # Maximum pages in the page queue
    # Should be large enough to hold all pages from your largest PDF
    page_queue_size: 1000
    
    # Maximum processed pages in the output queue
    output_queue_size: 500
  
  # Show progress information in logs
  # Disable for quieter operation in automated environments
  enable_progress: true
  
  # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  # DEBUG shows detailed processing information
  # INFO shows normal progress
  # WARNING and above only show problems
  log_level: INFO

# ==============================================================================
# CACHE CONFIGURATION
# ==============================================================================
# Controls caching of rendered images and LLM-generated markdown for performance
# and cost optimization. Caches are automatically invalidated when configuration changes.

cache:
  # Enable or disable the caching system entirely
  enabled: true
  
  # Base directory for all cache data
  # Each document gets its own subdirectory based on content hash
  base_dir: /tmp/pdf2markdown/cache
  
  # Maximum cache size in GB (automatic cleanup when exceeded)
  max_size_gb: 10
  
  # Automatically clean up caches older than this many days
  cleanup_after_days: 7
  
  # Resume processing by default (use cached data when available)
  # Can be overridden with --resume or --clear-cache CLI flags
  resume_by_default: false

# ==============================================================================
# OUTPUT CONFIGURATION
# ==============================================================================

# Default directory for output files
# Can be overridden with -o/--output command line option
output_dir: ./output

# Temporary directory for processing files
# Used for caching and intermediate files
temp_dir: /tmp/pdf2markdown

# Page separator format
# This text is inserted between pages in the final markdown output
# Use {page_number} as a placeholder for the page number that follows
# 
# Examples:
#   "\n---\n"                              # Simple horizontal rule (no page number)
#   "\n\n<!-- Page {page_number} -->\n\n"  # HTML comment with page number (invisible in rendered markdown)
#   "\n\n--[PAGE: {page_number}]--\n\n"    # Visible separator with page number
#   "\n\n# Page {page_number}\n\n"         # Heading style separator
#   "\n<div style=\"page-break-after: always;\"></div>\n"  # HTML page break
#
# Note: The separator is added BEFORE each page (except the first)
# The {page_number} placeholder refers to the page that follows the separator
page_separator: "\n\n--[PAGE: {page_number}]--\n\n"

# ==============================================================================
# EXAMPLE CONFIGURATIONS
# ==============================================================================

# ---- Example: OpenAI GPT-4 Vision ----
# llm_provider:
#   provider_type: openai
#   endpoint: https://api.openai.com/v1
#   api_key: ${OPENAI_API_KEY}
#   model: gpt-4o
#   max_tokens: 8192
#   temperature: 0.1
#   presence_penalty: 0.3
#   frequency_penalty: 0.3

# ---- Example: Azure OpenAI ----
# llm_provider:
#   provider_type: openai
#   endpoint: https://your-resource.openai.azure.com/
#   api_key: ${AZURE_OPENAI_KEY}
#   model: gpt-4-vision
#   max_tokens: 4096
#   temperature: 0.2

# ---- Example: Local Ollama Server ----
# llm_provider:
#   provider_type: openai
#   endpoint: http://localhost:11434/v1
#   api_key: not-required
#   model: llava:13b
#   max_tokens: 8192
#   temperature: 0.7
#   timeout: 600
#   repetition_penalty: 1.1

# ---- Example: Local vLLM Server ----
# llm_provider:
#   provider_type: openai
#   endpoint: http://localhost:8000/v1
#   api_key: token-abc123
#   model: cogvlm-chat
#   max_tokens: 8192
#   temperature: 0.5
#   timeout: 300
#   repetition_penalty: 1.15

# ---- Example: High-Performance Configuration ----
# document_parser:
#   resolution: 400  # Higher quality
# pipeline:
#   page_workers: 20  # More parallel processing

# ---- Example: Low-Resource Configuration ----
# document_parser:
#   resolution: 200  # Lower quality but faster
# pipeline:
#   page_workers: 3  # Fewer workers
# llm_provider:
#   max_tokens: 2048  # Smaller responses