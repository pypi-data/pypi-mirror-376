Metadata-Version: 2.4
Name: agent-redis-framework
Version: 1.1.0
Summary: A clean, elegant Python library for Redis-based multi-task scheduling with SortedSets and Streams.
Requires-Python: >=3.12
Requires-Dist: redis<7.0,>=5.0
Requires-Dist: typing-extensions<5.0,>=4.12
Provides-Extra: dev
Requires-Dist: fastapi>=0.104.0; extra == 'dev'
Requires-Dist: pydantic>=2.0.0; extra == 'dev'
Requires-Dist: uvicorn[standard]>=0.24.0; extra == 'dev'
Description-Content-Type: text/markdown

# Agent Redis Framework

ä¸€ä¸ªä¼˜é›…ã€é«˜æ•ˆçš„ Python Redis æ¡†æ¶ï¼Œä¸“ä¸ºå¤šä»»åŠ¡è°ƒåº¦ä¸æ¶ˆæ¯æµå¤„ç†è€Œè®¾è®¡ã€‚æä¾›åŸºäº Redis Sorted Sets çš„è½»é‡ä»»åŠ¡é˜Ÿåˆ—å’ŒåŸºäº Redis Streams çš„æ¶ˆè´¹ç»„å°è£…ï¼Œé€‚åˆæ„å»ºå¯æ‰©å±•çš„åˆ†å¸ƒå¼ä»»åŠ¡ç³»ç»Ÿã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸš€ SortedSetQueue - æ™ºèƒ½ä»»åŠ¡é˜Ÿåˆ—
- **ä¼˜å…ˆçº§è°ƒåº¦**: åŸºäº Redis Sorted Set å®ç°çš„è½»é‡ä»»åŠ¡é˜Ÿåˆ—
- **åŸå­æ“ä½œ**: ä½¿ç”¨ `ZPOPMIN`/`ZPOPMAX` ç¡®ä¿å¤šæ¶ˆè´¹è€…åœºæ™¯ä¸‹çš„ä»»åŠ¡å®‰å…¨åˆ†å‘
- **çµæ´»æ’åº**: æ”¯æŒæŒ‰åˆ†æ•°å‡åº/é™åºå¼¹å‡ºä»»åŠ¡
- **å¤±è´¥å¤„ç†**: å†…ç½®ä»»åŠ¡å¤„ç†å¤±è´¥çš„å›è°ƒæœºåˆ¶
- **æ‰¹é‡å¤„ç†**: æ”¯æŒä¸€æ¬¡æ€§å¼¹å‡ºå¹¶å¤„ç†å¤šä¸ªä»»åŠ¡

### ğŸ“¡ RedisStreamsClient - æµå¼æ¶ˆæ¯å¤„ç†
- **æ¶ˆè´¹ç»„ç®¡ç†**: å®Œæ•´çš„ Redis Streams æ¶ˆè´¹ç»„å°è£…
- **è‡ªåŠ¨ ACK**: æ¶ˆæ¯å¤„ç†æˆåŠŸåè‡ªåŠ¨ç¡®è®¤
- **æµé‡æ§åˆ¶**: æ”¯æŒæµé•¿åº¦é™åˆ¶å’Œè‡ªåŠ¨ä¿®å‰ª
- **é˜»å¡æ¶ˆè´¹**: å¯é…ç½®çš„é˜»å¡æ—¶é—´å’Œæ‰¹é‡æ¶ˆè´¹
- **é”™è¯¯æ¢å¤**: å¤„ç†å¾…ç¡®è®¤æ¶ˆæ¯å’Œæ¶ˆè´¹è€…æ•…éšœæ¢å¤

### ğŸ”§ ä¼ä¸šçº§ç‰¹æ€§
- **è¿æ¥æ± ç®¡ç†**: è‡ªåŠ¨è¿æ¥æ± å¤ç”¨ï¼Œä¼˜åŒ–é«˜å¹¶å‘æ€§èƒ½
- **ç¯å¢ƒé…ç½®**: çµæ´»çš„ `.env` æ–‡ä»¶å’Œç¯å¢ƒå˜é‡æ”¯æŒ
- **ç±»å‹å®‰å…¨**: å®Œæ•´çš„ Python ç±»å‹æ³¨è§£
- **çº¿ç¨‹å®‰å…¨**: æ‰€æœ‰æ ¸å¿ƒç»„ä»¶æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘
- **é›¶ä¾èµ–**: ä»…ä¾èµ– `redis` å’Œ `typing-extensions`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Redis è¿æ¥é…ç½®

#### æ–¹å¼ä¸€ï¼šç¯å¢ƒå˜é‡é…ç½®ï¼ˆæ¨èï¼‰

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=your_password
REDIS_MAX_CONNECTIONS=20
```

```python
from agent_redis_framework import get_redis

# è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
redis_client = get_redis()
print(redis_client.ping())  # True
```

### SortedSetQueue - ä»»åŠ¡é˜Ÿåˆ—ç¤ºä¾‹

```python
from agent_redis_framework import SortedSetQueue, Task, get_redis
import time

# åˆå§‹åŒ–
redis_client = get_redis()
queue = SortedSetQueue(redis_client=redis_client)
queue_key = "my_task_queue"

# æ¸…ç©ºé˜Ÿåˆ—ï¼ˆå¯é€‰ï¼‰
queue.clear(queue_key)

# æ¨é€ä»»åŠ¡ï¼ˆåˆ†æ•°è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
import json
queue.push(queue_key, Task(id="urgent_task", payload=json.dumps({"priority": "high"})), score=1)
queue.push(queue_key, Task(id="normal_task", payload=json.dumps({"priority": "normal"})), score=5)
queue.push(queue_key, Task(id="delayed_task", payload=json.dumps({"priority": "low"})), score=10)

# å®šä¹‰ä»»åŠ¡å¤„ç†å‡½æ•°
def process_task(task: Task) -> bool:
    print(f"Processing task {task.id}: {task.payload}")
    # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†
    time.sleep(0.1)
    return True  # è¿”å› True è¡¨ç¤ºå¤„ç†æˆåŠŸ

# å®šä¹‰å¤±è´¥å¤„ç†å‡½æ•°
def handle_failure(task: Task) -> None:
    print(f"Task {task.id} failed, logging for retry...")

# åŸå­å¼¹å‡ºå¹¶å¤„ç†ä»»åŠ¡
processed = queue.pop_and_handle(
    queue_key,
    callback=process_task,
    on_failure=handle_failure,
    count=2  # ä¸€æ¬¡å¤„ç† 2 ä¸ªä»»åŠ¡
)

print(f"Processed {len(processed)} tasks")
print(f"Remaining tasks: {queue.size(queue_key)}")
```

### RedisStreamsClient - æµå¼æ¶ˆæ¯ç¤ºä¾‹

```python
from agent_redis_framework import RedisStreamsClient, StreamMsg, get_redis
import threading
import time

# åˆå§‹åŒ–
redis_client = get_redis()
stream_client = RedisStreamsClient(redis_client=redis_client)

stream_name = "user_events"
group_name = "analytics_group"
consumer_name = "consumer_1"

# åˆ›å»ºæ¶ˆè´¹ç»„ï¼ˆå¹‚ç­‰æ“ä½œï¼‰
stream_client.ensure_group(stream_name, group_name)

# æ¨é€æ¶ˆæ¯
message_id = stream_client.push(stream_name, {
    "event_type": "user_login",
    "user_id": "12345",
    "timestamp": time.time(),
    "ip_address": "192.168.1.100"
})
print(f"Message pushed with ID: {message_id}")

# å®šä¹‰æ¶ˆæ¯å¤„ç†å‡½æ•°
def handle_message(msg: StreamMsg) -> None:
    print(f"Processing message {msg.message_id} from {msg.stream}")
    print(f"Payload: {dict(msg.payload)}")
    # å¤„ç†ä¸šåŠ¡é€»è¾‘
    time.sleep(0.1)

# åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¯åŠ¨æ¶ˆè´¹è€…
def start_consumer():
    stream_client.consume(
        streams=[stream_name],
        group=group_name,
        consumer=consumer_name,
        callback=handle_message,
        block_ms=5000,  # 5ç§’é˜»å¡è¶…æ—¶
        count=10        # æ¯æ¬¡æœ€å¤šè¯»å–10æ¡æ¶ˆæ¯
    )

# å¯åŠ¨æ¶ˆè´¹è€…çº¿ç¨‹
consumer_thread = threading.Thread(target=start_consumer, daemon=True)
consumer_thread.start()

# ç»§ç»­æ¨é€æ›´å¤šæ¶ˆæ¯
for i in range(5):
    stream_client.push(stream_name, {
        "event_type": "page_view",
        "user_id": f"user_{i}",
        "page": f"/page/{i}",
        "timestamp": time.time()
    })
    time.sleep(1)
```

## ğŸ—ï¸ é«˜çº§ç”¨æ³•

### å»¶æ—¶ä»»åŠ¡è°ƒåº¦

```python
import time
from agent_redis_framework import SortedSetQueue, Task, get_redis

queue = SortedSetQueue(redis_client=get_redis())
delay_queue = "delayed_tasks"

# æ¨é€å»¶æ—¶ä»»åŠ¡ï¼ˆ5åˆ†é’Ÿåæ‰§è¡Œï¼‰
future_time = time.time() + 300  # 5åˆ†é’Ÿå
queue.push(delay_queue, Task(
    id="send_email",
    payload=json.dumps({"to": "user@example.com", "subject": "Welcome!"})
), score=future_time)

# å¤„ç†åˆ°æœŸä»»åŠ¡
def process_if_ready(task: Task) -> bool:
    current_time = time.time()
    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åˆ°æœŸï¼ˆè¿™é‡Œéœ€è¦ä»Redisé‡æ–°è·å–åˆ†æ•°ï¼‰
    return True  # ç®€åŒ–ç¤ºä¾‹

# å®šæœŸæ£€æŸ¥å¹¶å¤„ç†åˆ°æœŸä»»åŠ¡
while True:
    processed = queue.pop_and_handle(delay_queue, process_if_ready, count=5)
    if not processed:
        time.sleep(10)  # æ²¡æœ‰ä»»åŠ¡æ—¶ç­‰å¾…10ç§’
```

### æµæ¶ˆæ¯æ‰¹é‡å¤„ç†

```python
from agent_redis_framework import RedisStreamsClient, StreamMsg, get_redis

stream_client = RedisStreamsClient(redis_client=get_redis())

# æ‰¹é‡æ¨é€æ¶ˆæ¯
messages = [
    {"order_id": f"order_{i}", "amount": i * 100, "status": "pending"}
    for i in range(100)
]

for msg in messages:
    stream_client.push("order_stream", msg, maxlen=1000)  # é™åˆ¶æµé•¿åº¦

# æ‰¹é‡æ¶ˆè´¹å¤„ç†
def batch_process_orders(msg: StreamMsg) -> None:
    order_data = json.loads(msg.payload) if msg.payload else {}
    print(f"Processing order: {order_data.get('order_id', 'unknown')}")
    # æ‰¹é‡å¤„ç†é€»è¾‘

stream_client.consume(
    streams=["order_stream"],
    group="order_processors",
    consumer="processor_1",
    callback=batch_process_orders,
    count=50,  # æ¯æ¬¡æ‰¹é‡å¤„ç†50æ¡æ¶ˆæ¯
    block_ms=1000
)
```

## ğŸ”§ é…ç½®é€‰é¡¹

### RedisConfig å®Œæ•´é…ç½®

```python
from agent_redis_framework import RedisConfig

config = RedisConfig(
    host="localhost",                    # Redis ä¸»æœºåœ°å€
    port=6379,                          # Redis ç«¯å£
    db=0,                               # æ•°æ®åº“ç¼–å·
    username="myuser",                  # ç”¨æˆ·åï¼ˆRedis 6.0+ï¼‰
    password="mypassword",              # å¯†ç 
    ssl=False,                          # æ˜¯å¦ä½¿ç”¨ SSL
    socket_timeout=30.0,                # Socket è¶…æ—¶æ—¶é—´
    socket_connect_timeout=10.0,        # è¿æ¥è¶…æ—¶æ—¶é—´
    health_check_interval=30,           # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    max_connections=20,                 # è¿æ¥æ± æœ€å¤§è¿æ¥æ•°
    retry_on_timeout=True               # è¶…æ—¶æ—¶æ˜¯å¦é‡è¯•
)
```

### ç¯å¢ƒå˜é‡é…ç½®

æ”¯æŒçš„ç¯å¢ƒå˜é‡ï¼š

```bash
# åŸºç¡€è¿æ¥é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_USERNAME=myuser
REDIS_PASSWORD=mypassword
REDIS_SSL=false

# è¿æ¥æ± é…ç½®
REDIS_MAX_CONNECTIONS=20
REDIS_SOCKET_TIMEOUT=30.0
REDIS_SOCKET_CONNECT_TIMEOUT=10.0
REDIS_HEALTH_CHECK_INTERVAL=30
REDIS_RETRY_ON_TIMEOUT=true
```

## ğŸ§ª æµ‹è¯•å’Œå¼€å‘

é¡¹ç›®æä¾›äº†å®Œæ•´çš„æµ‹è¯• APIï¼Œæ–¹ä¾¿å¼€å‘å’Œè°ƒè¯•ï¼š

```bash
# å®‰è£…å¼€å‘ä¾èµ–
uv sync --extra dev

# å¯åŠ¨æµ‹è¯• API æœåŠ¡
UV_INDEX_URL=https://pypi.org/simple/ uv run uvicorn tests.test_api:app --host 0.0.0.0 --port 8081
```

è®¿é—® http://localhost:8081/docs æŸ¥çœ‹äº¤äº’å¼ API æ–‡æ¡£ã€‚

è¯¦ç»†çš„æµ‹è¯•è¯´æ˜è¯·å‚è€ƒ [tests/README.md](tests/README.md)ã€‚

## ğŸ­ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 1. è¿æ¥æ± ä¼˜åŒ–

```python
# æ ¹æ®å¹¶å‘éœ€æ±‚è°ƒæ•´è¿æ¥æ± å¤§å°
config = RedisConfig(
    max_connections=50,  # é«˜å¹¶å‘åœºæ™¯
    health_check_interval=30,  # å®šæœŸå¥åº·æ£€æŸ¥
    socket_timeout=10.0,  # é¿å…é•¿æ—¶é—´é˜»å¡
    retry_on_timeout=True  # è‡ªåŠ¨é‡è¯•
)
```

### 2. é”™è¯¯å¤„ç†å’Œç›‘æ§

```python
import logging
from agent_redis_framework import SortedSetQueue, Task

logger = logging.getLogger(__name__)

def robust_task_handler(task: Task) -> bool:
    try:
        # ä»»åŠ¡å¤„ç†é€»è¾‘
        process_business_logic(task.payload)
        return True
    except Exception as e:
        logger.error(f"Task {task.id} failed: {e}")
        return False

def failure_handler(task: Task) -> None:
    # è®°å½•å¤±è´¥ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦é‡è¯•
    logger.warning(f"Task {task.id} marked for retry")
    # å¯ä»¥å°†å¤±è´¥ä»»åŠ¡é‡æ–°å…¥é˜Ÿæˆ–å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
```

### 3. ä¼˜é›…å…³é—­

```python
import signal
import threading
from agent_redis_framework import RedisStreamsClient

class GracefulConsumer:
    def __init__(self):
        self.running = True
        self.stream_client = RedisStreamsClient()
        
    def signal_handler(self, signum, frame):
        print("Received shutdown signal, stopping consumer...")
        self.running = False
        
    def consume_loop(self):
        while self.running:
            try:
                # ä½¿ç”¨è¾ƒçŸ­çš„é˜»å¡æ—¶é—´ä»¥ä¾¿åŠæ—¶å“åº”å…³é—­ä¿¡å·
                self.stream_client.consume(
                    streams=["my_stream"],
                    group="my_group",
                    consumer="my_consumer",
                    callback=self.handle_message,
                    block_ms=1000  # 1ç§’è¶…æ—¶
                )
            except KeyboardInterrupt:
                break
                
    def handle_message(self, msg):
        if not self.running:
            return
        # å¤„ç†æ¶ˆæ¯é€»è¾‘
        
# ä½¿ç”¨ç¤ºä¾‹
consumer = GracefulConsumer()
signal.signal(signal.SIGINT, consumer.signal_handler)
signal.signal(signal.SIGTERM, consumer.signal_handler)
consumer.consume_loop()
```

## ğŸ“š API å‚è€ƒ

### SortedSetQueue

- `push(key, task, score=None)` - æ¨é€ä»»åŠ¡åˆ°é˜Ÿåˆ—
- `pop_and_handle(key, callback, on_failure=None, ascending=True, count=1)` - åŸå­å¼¹å‡ºå¹¶å¤„ç†ä»»åŠ¡
- `size(key)` - è·å–é˜Ÿåˆ—å¤§å°
- `clear(key)` - æ¸…ç©ºé˜Ÿåˆ—

### RedisStreamsClient

- `push(stream, fields, maxlen=None)` - æ¨é€æ¶ˆæ¯åˆ°æµ
- `ensure_group(stream, group, id='0')` - ç¡®ä¿æ¶ˆè´¹ç»„å­˜åœ¨
- `consume(streams, group, consumer, callback, block_ms=5000, count=1)` - æ¶ˆè´¹æ¶ˆæ¯

### æ•°æ®ç±»

- `Task(id, payload, meta={})` - ä»»åŠ¡æ•°æ®ç±»ï¼Œpayload ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆJSON æˆ–åŸç”Ÿå­—ç¬¦ä¸²ï¼‰
- `StreamMsg(stream, message_id, payload, meta={})` - æµæ¶ˆæ¯æ•°æ®ç±»ï¼Œpayload ä¸ºå­—ç¬¦ä¸²æ ¼å¼
- `RedisConfig(...)` - Redis è¿æ¥é…ç½®

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ”— ç›¸å…³é“¾æ¥

- [Redis å®˜æ–¹æ–‡æ¡£](https://redis.io/documentation)
- [Redis Streams æŒ‡å—](https://redis.io/topics/streams-intro)
- [Redis Sorted Sets æŒ‡å—](https://redis.io/topics/data-types#sorted-sets)