## Set to any of the following values: gemini, openai, watsonx
## You'll need to set corresponding APIKeys below to use the selected LLM

SELECTED_LLM = "gemini" 


## GEMINI
GEMINI_API_KEY=
GEMINI_MODEL_ID= "gemini/gemini-2.0-flash"


## Set one of the following LLM providers before using agentics
## WatsonX AI credentials (Optional)
MODEL_ID=watsonx/meta-llama/llama-3-3-70b-instruct
WATSONX_URL=https://us-south.ml.cloud.ibm.com 
WATSONX_APIKEY=
WATSONX_PROJECTID=

## OpenAI credentials (Optional)
OPENAI_API_KEY=
OPENAI_MODEL_ID="openai/gpt-4"

## VLLM (Optional)
VLLM_URL=<http://base_url:PORT/v1>
VLLM_MODEL_ID="hosted_vllm/meta-llama/Llama-3.3-70B-Instruct"

## OLLAMA (Optional)
OLLAMA_MODEL_ID="ollama/deepseek-r1:latest"


###### MCP SERVERS #####

MCP_SERVER_PATH="src/agentics/tools/DDG_search_tool_mcp.py"