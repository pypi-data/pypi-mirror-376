{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32543613",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62180815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /Users/gliozzo/miniforge3/envs/agentics\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m\n",
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    load_dotenv(\"/content/drive/MyDrive/.env\")\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d8ee7",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<crewai.llm.LLM object at 0x12edaf8c0>\n"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,    # Adjust based on task\n",
    "    max_tokens=4096,    # Set based on output needs\n",
    "    timeout=300)        # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617590f4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in **Paris, France**. More specifically, it's situated on the Champ de Mars, near the Seine River, in the 7th arrondissement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.call(\"where is the Eiffel Tower?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fc4d0",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984913a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"short_answer\": \"Rayleigh scattering of sunlight by air molecules.\",\n",
      "  \"detailed_answer\": \"The sky appears blue due to a phenomenon called Rayleigh scattering. Sunlight is made up of all the colors of the rainbow. When sunlight enters the Earth's atmosphere, it collides with air molecules (mostly nitrogen and oxygen). This causes the sunlight to scatter in different directions. Blue and violet light have shorter wavelengths and are scattered more strongly than other colors like red and yellow. Our eyes are more sensitive to blue than violet, so we perceive the sky as blue. At sunrise and sunset, the sunlight travels through more of the atmosphere. The blue light is scattered away, leaving the longer wavelengths like red and orange to dominate, resulting in colorful sunrises and sunsets.\",\n",
      "  \"confidence\": 0.95\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Why is the sky blue?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4834b1",
   "metadata": {},
   "source": [
    "## You can also use structured decoding for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc8c2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"title\": \"Tractatus Logico-Philosophicus\",\n",
      "      \"publisher\": \"Routledge and Kegan Paul\",\n",
      "      \"year\": 1961,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Philosophical Investigations\",\n",
      "      \"publisher\": \"Basil Blackwell\",\n",
      "      \"year\": 1963,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"On Certainty\",\n",
      "      \"publisher\": \"Basil Blackwell\",\n",
      "      \"year\": 1979,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"name\": \"Ludwig Wittgenstein\",\n",
      "      \"city\": \"Vienna\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Bertrand Russell\",\n",
      "      \"city\": \"Cambridge\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gottlob Frege\",\n",
      "      \"city\": \"Wismar\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Arthur Schopenhauer\",\n",
      "      \"city\": \"Gdańsk\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Immanuel Kant\",\n",
      "      \"city\": \"Königsberg\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    city: str\n",
    "    occupation: str\n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    publisher: str\n",
    "    year: int\n",
    "    author: Person\n",
    "\n",
    "class InformationExtraction(BaseModel):\n",
    "    books: list[Book]\n",
    "    people: list[Person]\n",
    "    \n",
    "person_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=InformationExtraction)\n",
    "print(person_llm.call(requests.get(\"https://iep.utm.edu/wittgens/\").text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b53bbc",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 09:22:01.390 | DEBUG    | agentics.core.llm_connections:<module>:90 - AGENTICS is connecting to the following LLM API providers:\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:93 - 0 - WatsonX\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:98 - 1 - Gemini\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:102 - 2 - OpenAI\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:104 - Please add API keys in .env file to add or disconnect providers.\n",
      "2025-09-05 09:22:01.399 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 09:22:01.399 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n",
      "2025-09-05 09:22:01.401 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 09:22:01.401 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watsonx': <crewai.llm.LLM object at 0x168c535c0>, 'gemini': <crewai.llm.LLM object at 0x13fb5e870>, 'openai': <crewai.llm.LLM object at 0x168c53740>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 09:22:02.819 | DEBUG    | agentics.core.llm_connections:get_llm_provider:38 - Using specified LLM provider: watsonx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rome is the capital city of Italy, located in the central region of the country, within the Lazio region. It is situated on the Tiber River and is about 30 kilometers inland from the Tyrrhenian Sea.\n",
      "Rome is the capital city of Italy, located in the central region of the country, within the Lazio region. It is situated on the Tiber River and is home to many historical landmarks, including the Colosseum and the Vatican City.\n"
     ]
    }
   ],
   "source": [
    "from agentics.core.llm_connections import available_llms, get_llm_provider\n",
    "print(available_llms)\n",
    "\n",
    "llm=get_llm_provider() ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm=get_llm_provider(\"gemini\") ## get a specific LLM provider from the available ones,change \"gemini\" with \"openai\", \"watsonx\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c44e41",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Play with different data models on your favourite domain (e.g. stocks) providing relevant data. Enjoy tructured decoding magic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
