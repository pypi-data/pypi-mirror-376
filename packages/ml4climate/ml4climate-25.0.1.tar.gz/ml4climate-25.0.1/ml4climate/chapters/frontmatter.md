# Frontmatter

## Syllabus

The amount of data produced in environmental sciences (energy and climate
prediction) paves the way to new applications.  While traditionnal statistical
methods are still essential, advanced machine-learning methods are more and more
needed to make sense of such big data, whether it is for analysis or to make
predictions.  One goal of machine learning is to extract identifiable patterns
from these complex data sets.  These patterns can then be used to take informed
decisions.  Another is to model relationships between different variables and
then use these models to predict one variable from information of the other.

Examples of such big data sets are 
- If we want to optimize the energy performance of a building, we can set
  sensors in different places of the building that will give us a good overview
  of the energy consumption and energy loss. Analyzing such data set with
  machine learning will help us predict or optimize our energy consumption.

- The IPCC provides forecast of the average temperature for the next 100
  years. This forecast is based on about 30 different predictions made by
  complex models. Machine learning provides a way to trak reliable patterns in
  this complex data set 

The objective of this course is to provide an introduction to statistical
analysis and machine learning in order to help the students apply relevant
methods to analyze specific data sets.
Different families of unsupervised and supervised methods will be covered,
while also proving a general approach to validate and test results.
We encourage students to develop their
critical thinking skills when facing a new dataset and applying a method
in order to draw robust conclusions.
We illustrate this course with examples from environmental
sciences. These datasets correspond to concrete cases of analysis presented in
the form of ipython notebook.

## Organisation of the course

1. Introduction
2. Supervised learning problem
3. Bias, variance and validation
4. Regularization
5. Classification
6. Unsupervised learning
7. Ensemble methods
8. Neural network I
9. Neural network II

## References

- I M. P. Deisenroth, A. A. Faisal, and C. S. Ong. Mathematics for machine
  learning. Cambridge University Press, 2020. URL: http://mml-book.github.io
- I G. James et al. An introduction to statistical learning. Springer, 2013. URL: http://statlearning.com
- T. Hastie, R. Tibshirani, and J. Friedman. The elements of statistical
  learning. 2009. URL: http://web.stanford.edu/~hastie/ElemStatLearn



<!-- ```{bibliography} references.bib -->
<!-- ``` -->
