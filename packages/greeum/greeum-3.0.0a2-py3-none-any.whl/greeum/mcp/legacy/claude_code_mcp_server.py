#!/usr/bin/env python3
"""
Claude Code í˜¸í™˜ MCP ì„œë²„
- Claude Codeì˜ MCP í”„ë¡œí† ì½œ ê·œê²©ì— ì •í™•íˆ ë§ì¶¤
- ë„êµ¬ ì¸ì‹ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì™„ì „ í˜¸í™˜ ë²„ì „

ğŸ”§ TOOL USAGE WORKFLOW:
1. NEW INFO: add_memory (permanent) vs stm_add (temporary)
2. FIND INFO: search_memory (searches both permanent & temporary)
3. CHECK SYSTEM: get_memory_stats (before bulk operations)
4. MANAGE TEMPORARY: stm_promote (tempâ†’permanent) + stm_cleanup (maintenance)
5. ANALYZE DATA: ltm_analyze (patterns) â†’ ltm_verify (integrity) â†’ ltm_export (backup)

âš ï¸  BEST PRACTICES:
- Use add_memory for insights you want to keep across conversations
- Use stm_add for current session context that expires
- Always dry_run stm_promote first to preview
- Check get_memory_stats before ltm_analyze (need 10+ memories)
- Don't set importance > 0.8 unless truly critical
"""

import asyncio
import json
import sys
import logging
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
import subprocess
import os
from pathlib import Path

# Import enhanced tool schemas, duplicate detection, quality validation, and usage analytics
from .enhanced_tool_schema import EnhancedToolSchema
from greeum.core.duplicate_detector import DuplicateDetector
from greeum.core.quality_validator import QualityValidator
from greeum.core.usage_analytics import UsageAnalytics

# Greeum ëª¨ë“ˆ ì§ì ‘ import
try:
    from greeum.core.block_manager import BlockManager
    from greeum.core.database_manager import DatabaseManager  
    from greeum.core.stm_manager import STMManager
    GREEUM_AVAILABLE = True
except ImportError:
    GREEUM_AVAILABLE = False

# ë¡œê¹… ì„¤ì • (stderrë¡œë§Œ)
logging.basicConfig(level=logging.INFO, stream=sys.stderr, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger("claude_code_mcp")

class ClaudeCodeMCPServer:
    """Claude Code ì™„ì „ í˜¸í™˜ MCP ì„œë²„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.server_info = {
            "name": "greeum",
            "version": "2.1.0"
        }
        self.protocol_version = "2024-11-05"
        self.capabilities = {
            "tools": {},
            "resources": {},
            "prompts": {},
            "logging": {}
        }
        
        # Greeum ì»´í¬ë„ŒíŠ¸ ì§ì ‘ ì´ˆê¸°í™”
        if GREEUM_AVAILABLE:
            try:
                self.db_manager = DatabaseManager()
                self.block_manager = BlockManager(self.db_manager)
                self.stm_manager = STMManager(self.db_manager)
                # v2.0.5: ì¤‘ë³µ ê²€ì‚¬ê¸°, í’ˆì§ˆ ê²€ì¦ê¸°, ì‚¬ìš© ë¶„ì„ê¸° ì´ˆê¸°í™”
                self.duplicate_detector = DuplicateDetector(self.db_manager)
                self.quality_validator = QualityValidator()
                self.usage_analytics = UsageAnalytics(self.db_manager)
                self.direct_mode = True
                # ì„œë²„ ì„¸ì…˜ ì‹œì‘
                self.server_session_id = f"mcp_server_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                self.usage_analytics.start_session(self.server_session_id, "Claude Code MCP", "mcp_server")
                logger.info("Claude Code MCP Server v2.0.5 initialized with full analytics suite (duplicate detection + quality validation + usage analytics)")
            except Exception as e:
                logger.warning(f"Failed to initialize Greeum modules: {e}")
                self.direct_mode = False
        else:
            self.direct_mode = False
    
    def __del__(self):
        """Ensure proper cleanup of analytics session"""
        if hasattr(self, 'usage_analytics') and hasattr(self, 'server_session_id'):
            try:
                self.usage_analytics.end_session(self.server_session_id)
                logger.info(f"Analytics session {self.server_session_id} properly closed")
            except Exception:
                pass  # Cleanup should never raise
            
        # CLI ê²½ë¡œ ì„¤ì • (ì¼ë¶€ ëª…ë ¹ì–´ëŠ” CLI í•„ìš”)
        try:
            self.greeum_cli = self._find_greeum_cli()
        except Exception as e:
            logger.warning(f"Failed to find Greeum CLI: {e}")
            self.greeum_cli = "python3 -m greeum.cli"  # ì•ˆì „í•œ ê¸°ë³¸ê°’
            
        if not self.direct_mode:
            logger.info(f"Claude Code MCP Server initialized with CLI fallback: {self.greeum_cli}")
        else:
            logger.info(f"Claude Code MCP Server initialized with direct mode, CLI available: {self.greeum_cli}")
        
    def _find_greeum_cli(self) -> str:
        """Greeum CLI ê²½ë¡œ ìë™ ê°ì§€"""
        current_dir = Path(__file__).parent.parent.parent
        
        # ë°©ë²• 1: Python ëª¨ë“ˆ ì‹¤í–‰
        if (current_dir / "greeum" / "cli" / "__init__.py").exists():
            return f"python3 -m greeum.cli"
            
        # ë°©ë²• 2: ì„¤ì¹˜ëœ ëª…ë ¹ì–´
        try:
            subprocess.run(["greeum", "--version"], capture_output=True, check=True)
            return "greeum"
        except (subprocess.CalledProcessError, FileNotFoundError):
            pass
            
        # ê¸°ë³¸ê°’
        return f"python3 -m greeum.cli"
    
    def _run_cli_command(self, command: List[str]) -> Dict[str, Any]:
        """CLI ëª…ë ¹ì–´ ì‹¤í–‰"""
        try:
            # ì•ˆì „í•œ CLI ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            greeum_cli = getattr(self, 'greeum_cli', None)
            if not greeum_cli:
                return {"success": False, "error": "CLI path not configured"}
                
            full_command = greeum_cli.split() + command
            logger.info(f"Running: {' '.join(full_command)}")
            
            # ë³´ì•ˆ: í—ˆìš©ëœ ëª…ë ¹ì–´ë§Œ ì‹¤í–‰
            allowed_commands = [
                "memory", "add", "search", "stats", "--version", "--help",
                "ltm", "analyze", "verify", "export", "stm", "promote", "cleanup",
                "--period", "--output", "--trends", "--repair", "--format", "--limit",
                "--threshold", "--dry-run", "--ttl", "--importance", "--smart", "--expired"
            ]
            for cmd_part in command:
                if cmd_part not in allowed_commands and not cmd_part.startswith(('-', '=')):
                    # ëª…ë ¹ì–´ ì¸ì ì…˜ ë°©ì§€: ì•ˆì „í•œ í…ìŠ¤íŠ¸ë§Œ í—ˆìš©
                    if not all(c.isalnum() or c in ' .-_ê°€-í£ã„±-ã…ã…-ã…£' for c in cmd_part):
                        raise ValueError(f"Unsafe command detected: {cmd_part}")
            
            result = subprocess.run(
                full_command,
                capture_output=True,
                text=True,
                check=True,
                timeout=30  # ë³´ì•ˆ: íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            
            return {"success": True, "output": result.stdout.strip()}
                
        except subprocess.CalledProcessError as e:
            logger.error(f"CLI command failed: {e}")
            return {"success": False, "error": f"Command failed: {e.stderr or str(e)}"}
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            return {"success": False, "error": str(e)}
    
    def _add_memory_direct(self, content: str, importance: float = 0.5) -> Dict[str, Any]:
        """CLIì™€ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì¶”ê°€"""
        from greeum.text_utils import process_user_input
        from datetime import datetime
        import json
        import hashlib
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
        result = process_user_input(content)
        result["importance"] = importance
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        timestamp = datetime.now().isoformat()
        result["timestamp"] = timestamp
        
        # ë¸”ë¡ ì¸ë±ìŠ¤ ìƒì„± (ë§ˆì§€ë§‰ ë¸”ë¡ + 1)
        last_block_info = self.db_manager.get_last_block_info()
        if last_block_info is None:
            last_block_info = {"block_index": -1}
        block_index = last_block_info.get("block_index", -1) + 1
        
        # ì´ì „ í•´ì‹œ ê°€ì ¸ì˜¤ê¸°
        prev_hash = ""
        if block_index > 0:
            prev_block = self.db_manager.get_block(block_index - 1)
            if prev_block:
                prev_hash = prev_block.get("hash", "")
        
        # í•´ì‹œ ê³„ì‚°
        hash_data = {
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "prev_hash": prev_hash
        }
        hash_str = json.dumps(hash_data, sort_keys=True)
        hash_value = hashlib.sha256(hash_str.encode()).hexdigest()
        
        # ìµœì¢… ë¸”ë¡ ë°ì´í„°
        block_data = {
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "keywords": result.get("keywords", []),
            "tags": result.get("tags", []),
            "embedding": result.get("embedding", []),
            "importance": result.get("importance", 0.5),
            "hash": hash_value,
            "prev_hash": prev_hash
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        self.db_manager.add_block(block_data)
        
        return block_data
    
    def _search_memory_direct(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """CLIì™€ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        from greeum.embedding_models import get_embedding
        
        try:
            # ì„ë² ë”© ê²€ìƒ‰ ì‹œë„
            embedding = get_embedding(query)
            blocks = self.db_manager.search_blocks_by_embedding(embedding, top_k=limit)
        except Exception:
            # ì„ë² ë”© ì‹¤íŒ¨ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰
            keywords = query.split()
            blocks = self.db_manager.search_blocks_by_keyword(keywords, limit=limit)
        
        return blocks

    async def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """MCP ìš”ì²­ ì²˜ë¦¬ (Claude Code ê·œê²© ì¤€ìˆ˜)"""
        try:
            method = request.get('method', '')
            params = request.get('params', {})
            request_id = request.get('id', 1)
            
            logger.info(f"Handling method: {method}")
            
            # 1. Initialize
            if method == 'initialize':
                return {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "protocolVersion": self.protocol_version,
                        "capabilities": self.capabilities,
                        "serverInfo": self.server_info
                    }
                }
            
            # 2. Tools list - Using Enhanced Tool Schemas v2.0.5
            elif method == 'tools/list':
                # Get all enhanced tool schemas with improved guidance
                enhanced_tools = EnhancedToolSchema.get_all_enhanced_schemas()
                
                return {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "tools": enhanced_tools
                    }
                }
                
            # 3. Tools call
            elif method == 'tools/call':
                tool_name = params.get('name', '')
                arguments = params.get('arguments', {})
                
                logger.info(f"Calling tool: {tool_name} with args: {arguments}")
                
                # add_memory ë„êµ¬ - v2.0.5 Enhanced with Analytics, Duplicate Detection & Quality Validation
                if tool_name == 'add_memory':
                    content = arguments.get('content', '')
                    importance = arguments.get('importance', 0.5)
                    start_time = time.time()
                    
                    if self.direct_mode:
                        try:
                            # v2.0.5: í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰
                            quality_result = self.quality_validator.validate_memory_quality(content, importance)
                            
                            # í’ˆì§ˆì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì €ì¥ ì¤‘ë‹¨
                            if not quality_result["should_store"]:
                                duration_ms = int((time.time() - start_time) * 1000)
                                
                                # Analytics: í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ë¡œê¹…
                                self.usage_analytics.log_event(
                                    "tool_usage", tool_name, 
                                    {"quality_score": quality_result['quality_score'], "quality_level": quality_result['quality_level']},
                                    duration_ms, False, "Quality validation failed", session_id=self.server_session_id
                                )
                                self.usage_analytics.log_quality_metrics(
                                    len(content), quality_result['quality_score'], quality_result['quality_level'],
                                    importance, quality_result['adjusted_importance'], False, 0.0, len(quality_result['suggestions'])
                                )
                                
                                quality_warning = f"""[ERROR] **Low Quality Content Detected!**

**Quality Score**: {quality_result['quality_score']:.1%} ({quality_result['quality_level']})
**Issues Found**: Quality below acceptable threshold

**Suggestions for Improvement**:
{chr(10).join('â€¢ ' + suggestion for suggestion in quality_result['suggestions'])}

**Warnings**:
{chr(10).join('â€¢ ' + warning for warning in quality_result['warnings'])}

âš ï¸ **Memory NOT stored** due to low quality. Please improve content and try again."""
                                
                                return {
                                    "jsonrpc": "2.0",
                                    "id": request_id,
                                    "result": {
                                        "content": [
                                            {
                                                "type": "text",
                                                "text": quality_warning
                                            }
                                        ]
                                    }
                                }
                            
                            # v2.0.5: ì¤‘ë³µ ê²€ì‚¬ ìˆ˜í–‰
                            duplicate_check = self.duplicate_detector.check_duplicate(content, importance)
                            
                            # ì¤‘ë³µ ë°œê²¬ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                            if duplicate_check["is_duplicate"]:
                                duration_ms = int((time.time() - start_time) * 1000)
                                similar_memory = duplicate_check["similar_memories"][0] if duplicate_check["similar_memories"] else {}
                                block_index = similar_memory.get("block_index", "unknown")
                                similarity = duplicate_check["similarity_score"]
                                
                                # Analytics: ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨ ë¡œê¹…
                                self.usage_analytics.log_event(
                                    "tool_usage", tool_name,
                                    {"duplicate_similarity": similarity, "existing_block": block_index},
                                    duration_ms, False, "Duplicate content detected", session_id=self.server_session_id
                                )
                                self.usage_analytics.log_quality_metrics(
                                    len(content), quality_result['quality_score'], quality_result['quality_level'],
                                    importance, quality_result['adjusted_importance'], True, similarity, len(quality_result['suggestions'])
                                )
                                
                                warning_text = f"""ğŸš« **Duplicate Content Detected!**

**Similarity**: {similarity:.1%} match found
**Existing Memory**: Block #{block_index}
**Content Preview**: {similar_memory.get('context', '')[:100]}...

**Recommendation**: {duplicate_check['recommendation']}

ğŸ’¡ **Suggested Actions**:
â€¢ Use `search_memory` to review existing content
â€¢ Update existing memory if needed  
â€¢ Add only truly new information

âš ï¸ **Memory NOT stored** to prevent duplication."""
                                
                                return {
                                    "jsonrpc": "2.0",
                                    "id": request_id,
                                    "result": {
                                        "content": [
                                            {
                                                "type": "text",
                                                "text": warning_text
                                            }
                                        ]
                                    }
                                }
                            
                            # í’ˆì§ˆ ê²€ì¦ ë° ì¤‘ë³µ ê²€ì‚¬ í†µê³¼ - ì‹¤ì œ ì €ì¥
                            # í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¼ ì¤‘ìš”ë„ ì¡°ì •
                            adjusted_importance = quality_result["adjusted_importance"]
                            block_data = self._add_memory_direct(content, adjusted_importance)
                            duration_ms = int((time.time() - start_time) * 1000)
                            
                            # Analytics: ì„±ê³µì ì¸ ë©”ëª¨ë¦¬ ì €ì¥ ë¡œê¹…
                            self.usage_analytics.log_event(
                                "tool_usage", tool_name,
                                {
                                    "block_index": block_data['block_index'],
                                    "quality_score": quality_result['quality_score'],
                                    "quality_level": quality_result['quality_level'],
                                    "importance_adjusted": adjusted_importance != importance
                                },
                                duration_ms, True, session_id=self.server_session_id
                            )
                            self.usage_analytics.log_quality_metrics(
                                len(content), quality_result['quality_score'], quality_result['quality_level'],
                                importance, adjusted_importance, False, duplicate_check["similarity_score"], 
                                len(quality_result['suggestions'])
                            )
                            
                            # v2.0.5: í’ˆì§ˆ ë° ì¤‘ë³µ í”¼ë“œë°± í¬í•¨í•œ ì„±ê³µ ë©”ì‹œì§€
                            quality_feedback = f"""
**Quality Score**: {quality_result['quality_score']:.1%} ({quality_result['quality_level']})
**Adjusted Importance**: {adjusted_importance:.2f} (original: {importance:.2f})"""
                            
                            # ì¶”ê°€ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ë©´ í¬í•¨
                            suggestions_text = ""
                            if quality_result['suggestions']:
                                suggestions_text = f"\n\nğŸ’¡ **Quality Suggestions**:\n" + "\n".join(f"â€¢ {s}" for s in quality_result['suggestions'][:2])
                            
                            result_text = f"""âœ… **Memory Successfully Added!**

**Block Index**: #{block_data['block_index']}
**Storage**: Permanent (Long-term Memory)
**Duplicate Check**: âœ… Passed{quality_feedback}{suggestions_text}"""
                            
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "result": {
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": result_text
                                        }
                                    ]
                                }
                            }
                        except Exception as e:
                            logger.error(f"Enhanced memory add failed: {e}")
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {
                                    "code": -32603,
                                    "message": f"Failed to add memory: {str(e)}"
                                }
                            }
                    else:
                        # CLI fallback
                        command = ["memory", "add", content, "--importance", str(importance)]
                        result = self._run_cli_command(command)
                        
                        if result["success"]:
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "result": {
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": f"âœ… Memory added to PERMANENT storage: {result['output']}"
                                        }
                                    ]
                                }
                            }
                        else:
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {
                                    "code": -32603,
                                    "message": f"Failed to add memory: {result['error']}"
                                }
                            }
                
                # search_memory ë„êµ¬
                elif tool_name == 'search_memory':
                    query = arguments.get('query', '')
                    limit = arguments.get('limit', 5)
                    start_time = time.time()
                    
                    if self.direct_mode:
                        try:
                            # ì§ì ‘ ëª¨ë“ˆ ì‚¬ìš© - CLIì™€ ë™ì¼í•œ íŒ¨í„´
                            results = self._search_memory_direct(query, limit)
                            duration_ms = int((time.time() - start_time) * 1000)
                            
                            # Analytics: ê²€ìƒ‰ ì´ë²¤íŠ¸ ë¡œê¹…
                            self.usage_analytics.log_event(
                                "tool_usage", tool_name,
                                {
                                    "query_length": len(query),
                                    "results_found": len(results),
                                    "limit_requested": limit
                                },
                                duration_ms, True, session_id=self.server_session_id
                            )
                            
                            if results:
                                result_text = f"ğŸ” Found {len(results)} memories:\n"
                                for i, memory in enumerate(results, 1):
                                    timestamp = memory.get('timestamp', 'Unknown')
                                    content = memory.get('context', '')[:100] + ('...' if len(memory.get('context', '')) > 100 else '')
                                    result_text += f"{i}. [{timestamp}] {content}\n"
                            else:
                                result_text = "[ERROR] No memories found"
                            
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "result": {
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": result_text
                                        }
                                    ]
                                }
                            }
                        except Exception as e:
                            logger.error(f"Direct memory search failed: {e}")
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {
                                    "code": -32603,
                                    "message": f"Failed to search memory: {str(e)}"
                                }
                            }
                    else:
                        # CLI fallback
                        command = ["memory", "search", query, "--count", str(limit)]
                        result = self._run_cli_command(command)
                        
                        if result["success"]:
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "result": {
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": f"ğŸ” Search results:\n{result['output']}"
                                        }
                                    ]
                                }
                            }
                        else:
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {
                                    "code": -32603,
                                    "message": f"Failed to search memory: {result['error']}"
                                }
                            }
                
                # get_memory_stats ë„êµ¬
                elif tool_name == 'get_memory_stats':
                    try:
                        # ë©”ëª¨ë¦¬ í†µê³„ ì§ì ‘ ìˆ˜ì§‘
                        data_dir = Path.home() / ".greeum"
                        
                        stats = {
                            "data_directory": str(data_dir),
                            "exists": data_dir.exists(),
                            "files": []
                        }
                        
                        if data_dir.exists():
                            for file in data_dir.glob("*"):
                                if file.is_file():
                                    stats["files"].append({
                                        "name": file.name,
                                        "size": file.stat().st_size
                                    })
                        
                        return {
                            "jsonrpc": "2.0",
                            "id": request_id,
                            "result": {
                                "content": [
                                    {
                                        "type": "text",
                                        "text": f"ğŸ“Š Memory Statistics:\n{json.dumps(stats, indent=2)}"
                                    }
                                ]
                            }
                        }
                        
                    except Exception as e:
                        return {
                            "jsonrpc": "2.0",
                            "id": request_id,
                            "error": {
                                "code": -32603,
                                "message": f"Failed to get stats: {str(e)}"
                            }
                        }
                
                # usage_analytics ë„êµ¬ - v2.0.5 New Analytics Tool
                elif tool_name == 'usage_analytics':
                    days = arguments.get('days', 7)
                    report_type = arguments.get('report_type', 'usage')
                    start_time = time.time()
                    
                    if self.direct_mode and hasattr(self, 'usage_analytics'):
                        try:
                            if report_type == 'usage' or report_type == 'all':
                                usage_stats = self.usage_analytics.get_usage_statistics(days)
                            
                            if report_type == 'quality' or report_type == 'all':
                                quality_trends = self.usage_analytics.get_quality_trends(days)
                            
                            if report_type == 'performance' or report_type == 'all':
                                performance_insights = self.usage_analytics.get_performance_insights(days)
                            
                            duration_ms = int((time.time() - start_time) * 1000)
                            
                            # Analytics: analytics ìš”ì²­ ìì²´ë„ ë¡œê¹…
                            self.usage_analytics.log_event(
                                "tool_usage", tool_name,
                                {"report_type": report_type, "days": days},
                                duration_ms, True, session_id=self.server_session_id
                            )
                            
                            # ë³´ê³ ì„œ ìƒì„±
                            if report_type == 'usage':
                                report_text = f"""ğŸ“Š **Usage Analytics Report** ({days} days)

**Basic Statistics**:
â€¢ Total Events: {usage_stats['basic_stats']['total_events']}
â€¢ Unique Sessions: {usage_stats['basic_stats']['unique_sessions']}
â€¢ Success Rate: {usage_stats['basic_stats']['success_rate']:.1%}
â€¢ Avg Response Time: {usage_stats['basic_stats']['avg_duration_ms']:.0f}ms

**Top Tools Used**:
{chr(10).join(f"â€¢ {tool}: {count} times" for tool, count in list(usage_stats['tool_usage'].items())[:5])}

**Quality Statistics**:
â€¢ Average Quality Score: {usage_stats['quality_stats']['avg_quality_score']:.2f}
â€¢ Duplicate Rate: {usage_stats['quality_stats']['duplicate_rate']:.1%}
â€¢ Quality Checks: {usage_stats['quality_stats']['total_quality_checks']}"""
                            
                            elif report_type == 'quality':
                                report_text = f"""[IMPROVE] **Quality Trends Report** ({days} days)

**Quality Distribution**:
{chr(10).join(f"â€¢ {level}: {count}" for level, count in quality_trends['quality_distribution'].items())}

**Recent Trends**:
{chr(10).join(f"â€¢ {trend['date']}: {trend['avg_quality']:.2f} avg quality ({trend['count']} memories)" for trend in quality_trends['daily_trends'][-5:])}

**Duplicate Analysis**:
{chr(10).join(f"â€¢ {trend['date']}: {trend['duplicate_rate']:.1%} duplicate rate" for trend in quality_trends['duplicate_trends'][-3:])}"""
                            
                            elif report_type == 'performance':
                                report_text = f"""[FAST] **Performance Insights Report** ({days} days)

**Performance by Tool**:
{chr(10).join(f"â€¢ {perf['tool_name']}: {perf['avg_duration_ms']:.0f}ms avg ({perf['operation_count']} ops)" for perf in performance_insights['performance_by_tool'][:5])}

**Error Patterns**:
{chr(10).join(f"â€¢ {error['tool_name']}: {error['error_count']} errors" for error in performance_insights['error_patterns'][:3])}

**Recommendations**:
{chr(10).join(f"â€¢ {rec}" for rec in performance_insights['recommendations'])}"""
                            
                            else:  # 'all'
                                report_text = f"""ğŸ“Š **Complete Analytics Report** ({days} days)

**Usage Summary**:
â€¢ Total Events: {usage_stats['basic_stats']['total_events']}
â€¢ Success Rate: {usage_stats['basic_stats']['success_rate']:.1%}
â€¢ Avg Quality: {usage_stats['quality_stats']['avg_quality_score']:.2f}

**Top Issues**:
{chr(10).join(f"â€¢ {rec}" for rec in performance_insights['recommendations'][:3])}

ğŸ’¡ Use specific report types for detailed analysis: 'usage', 'quality', or 'performance'"""
                            
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "result": {
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": report_text
                                        }
                                    ]
                                }
                            }
                            
                        except Exception as e:
                            logger.error(f"Analytics report generation failed: {e}")
                            return {
                                "jsonrpc": "2.0",
                                "id": request_id,
                                "error": {
                                    "code": -32603,
                                    "message": f"Failed to generate analytics report: {str(e)}"
                                }
                            }
                    else:
                        return {
                            "jsonrpc": "2.0",
                            "id": request_id,
                            "error": {
                                "code": -32603,
                                "message": "Analytics not available in CLI mode"
                            }
                        }
                
                # ì œê±°ë¨: ltm_analyze, ltm_verify, ltm_export, stm_add, stm_promote, stm_cleanup
                # ì•ˆì „ì„±ê³¼ ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ìœ„í—˜í•œ 6ê°œ ë„êµ¬ëŠ” MCPì—ì„œ ì œê±°ë¨
                # ì´ ê¸°ëŠ¥ë“¤ì€ CLIë¥¼ í†µí•´ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
                
                # ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬
                else:
                    return {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "error": {
                            "code": -32601,
                            "message": f"Unknown tool: {tool_name}"
                        }
                    }
            
            # 4. Notifications (ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
            elif method == 'notifications/initialized':
                # ì•Œë¦¼ì€ ì‘ë‹µí•˜ì§€ ì•ŠìŒ
                return None
                
            # 5. ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì„œë“œ
            else:
                return {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {
                        "code": -32601,
                        "message": f"Method not found: {method}"
                    }
                }
                
        except Exception as e:
            logger.error(f"Request handling failed: {e}")
            return {
                "jsonrpc": "2.0",
                "id": request.get('id', 1),
                "error": {
                    "code": -32603,
                    "message": f"Internal error: {str(e)}"
                }
            }

async def main():
    """ë©”ì¸ ì„œë²„ ë£¨í”„"""
    try:
        server = ClaudeCodeMCPServer()
        logger.info("Claude Code compatible MCP server started")
        
        # STDIOë¡œ JSON-RPC ë©”ì‹œì§€ ì²˜ë¦¬
        while True:
            try:
                line = sys.stdin.readline()
                if not line:
                    break
                    
                line = line.strip()
                if not line:
                    continue
                    
                # JSON íŒŒì‹±
                request = json.loads(line)
                response = await server.handle_request(request)
                
                # ì‘ë‹µ ì „ì†¡ (Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
                if response is not None:
                    print(json.dumps(response), flush=True)
                
            except json.JSONDecodeError as e:
                logger.error(f"Invalid JSON: {e}")
                error_response = {
                    "jsonrpc": "2.0",
                    "id": None,
                    "error": {"code": -32700, "message": "Parse error"}
                }
                print(json.dumps(error_response), flush=True)
                
            except KeyboardInterrupt:
                logger.info("Server interrupted")
                break
                
            except Exception as e:
                logger.error(f"Unexpected error: {e}")
                
    except Exception as e:
        logger.error(f"Server startup failed: {e}")
        sys.exit(1)
    finally:
        logger.info("Claude Code MCP server stopped")

if __name__ == "__main__":
    # Python ë²„ì „ í™•ì¸
    if sys.version_info < (3, 6):
        print("Error: Python 3.6+ required", file=sys.stderr)
        sys.exit(1)
        
    # ë¹„ë™ê¸° ì‹¤í–‰
    try:
        asyncio.run(main())
    except AttributeError:
        # Python 3.6 í˜¸í™˜ì„±
        loop = asyncio.get_event_loop()
        loop.run_until_complete(main())