#!/usr/bin/env python3
"""
ê¸°ë³¸ MCP ì–´ëŒ‘í„° ì¸í„°í˜ì´ìŠ¤
- ëª¨ë“  í™˜ê²½ë³„ ì–´ëŒ‘í„°ì˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Greeum ì»´í¬ë„ŒíŠ¸ í†µí•© ì´ˆê¸°í™”
- ê¸°ì¡´ ë„êµ¬ API ì™„ì „ í˜¸í™˜ì„± ë³´ì¥
"""

import asyncio
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

# Greeum í•µì‹¬ ì»´í¬ë„ŒíŠ¸
try:
    from greeum.core.block_manager import BlockManager
    from greeum.core import DatabaseManager  # Thread-safe factory pattern  
    from greeum.core.stm_manager import STMManager
    from greeum.core.duplicate_detector import DuplicateDetector
    from greeum.core.quality_validator import QualityValidator
    from greeum.core.usage_analytics import UsageAnalytics
    from greeum.core.search_engine import SearchEngine
    GREEUM_AVAILABLE = True
except ImportError:
    GREEUM_AVAILABLE = False

logger = logging.getLogger(__name__)

class BaseAdapter(ABC):
    """ëª¨ë“  MCP ì–´ëŒ‘í„°ì˜ ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.components = None
        self.initialized = False
        
    def initialize_greeum_components(self) -> Optional[Dict[str, Any]]:
        """Greeum í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í†µí•© ì´ˆê¸°í™”"""
        if self.components is not None:
            return self.components
            
        if not GREEUM_AVAILABLE:
            logger.error("[ERROR] Greeum components not available")
            return None
            
        try:
            # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
            db_manager = DatabaseManager()
            block_manager = BlockManager(db_manager)
            stm_manager = STMManager(db_manager)
            duplicate_detector = DuplicateDetector(db_manager)
            quality_validator = QualityValidator()
            usage_analytics = UsageAnalytics(db_manager)
            search_engine = SearchEngine(block_manager)
            
            self.components = {
                'db_manager': db_manager,
                'block_manager': block_manager,
                'stm_manager': stm_manager,
                'duplicate_detector': duplicate_detector,
                'quality_validator': quality_validator,
                'usage_analytics': usage_analytics,
                'search_engine': search_engine
            }
            
            self.initialized = True
            logger.info("âœ… Greeum components initialized successfully")
            return self.components
            
        except Exception as e:
            logger.error(f"[ERROR] Failed to initialize Greeum components: {e}")
            return None
    
    # ê³µí†µ ë„êµ¬ êµ¬í˜„ (ëª¨ë“  ì–´ëŒ‘í„°ì—ì„œ ë™ì¼)
    def add_memory_tool(self, content: str, importance: float = 0.5) -> str:
        """ë©”ëª¨ë¦¬ ì¶”ê°€ ë„êµ¬ - ê¸°ì¡´ API ì™„ì „ í˜¸í™˜"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            # ì¤‘ë³µ ê²€ì‚¬
            duplicate_check = self.components['duplicate_detector'].check_duplicate(content)
            if duplicate_check["is_duplicate"]:
                similarity = duplicate_check["similarity_score"]
                return f"""âš ï¸  **Potential Duplicate Memory Detected**

**Similarity**: {similarity:.1%} with existing memory
**Similar Memory**: Block #{duplicate_check['similar_block_index']}

Please search existing memories first or provide more specific content."""
            
            # í’ˆì§ˆ ê²€ì¦
            quality_result = self.components['quality_validator'].validate_memory_quality(content, importance)
            
            # ë©”ëª¨ë¦¬ ì¶”ê°€ - ì§ì ‘ êµ¬í˜„ (legacy ì˜ì¡´ì„± ì œê±°)
            block_data = self._add_memory_direct(content, importance)
            
            # ì‚¬ìš© í†µê³„ ë¡œê¹…
            self.components['usage_analytics'].log_quality_metrics(
                len(content), quality_result['quality_score'], quality_result['quality_level'],
                importance, importance, False, duplicate_check["similarity_score"], 
                len(quality_result.get('suggestions', []))
            )
            
            # ì„±ê³µ ì‘ë‹µ
            quality_feedback = f"""
**Quality Score**: {quality_result['quality_score']:.1%} ({quality_result['quality_level']})
**Adjusted Importance**: {importance:.2f} (original: {importance:.2f})"""
            
            suggestions_text = ""
            if quality_result.get('suggestions'):
                suggestions_text = f"\n\nğŸ’¡ **Quality Suggestions**:\n" + "\n".join(f"â€¢ {s}" for s in quality_result['suggestions'][:2])
            
            return f"""âœ… **Memory Successfully Added!**

**Block Index**: #{block_data['block_index']}
**Storage**: Permanent (Long-term Memory)
**Duplicate Check**: âœ… Passed{quality_feedback}{suggestions_text}"""
            
        except Exception as e:
            logger.error(f"add_memory failed: {e}")
            return f"[ERROR] Failed to add memory: {str(e)}"
    
    def search_memory_tool(self, query: str, limit: int = 5, depth: int = 0, tolerance: float = 0.5) -> str:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ - ì—°ê´€ê´€ê³„ í™•ì¥ íƒìƒ‰ ê¸°ëŠ¥ ì¶”ê°€"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ê²€ìƒ‰
            results = self._search_memory_direct(query, limit)
            
            # ì—°ê´€ê´€ê³„ í™•ì¥ íƒìƒ‰ (depth > 0ì¸ ê²½ìš°)
            if depth > 0 and results:
                results = self._expand_search_with_associations(results, depth, tolerance, limit)
            
            # ì‚¬ìš© í†µê³„ ë¡œê¹… (í™•ì¥ëœ íŒŒë¼ë¯¸í„° í¬í•¨)
            self.components['usage_analytics'].log_event(
                "tool_usage", "search_memory",
                {
                    "query_length": len(query), 
                    "results_found": len(results), 
                    "limit_requested": limit,
                    "depth": depth,
                    "tolerance": tolerance
                },
                0, True
            )
            
            if results:
                result_text = f"ğŸ” Found {len(results)} memories"
                if depth > 0:
                    result_text += f" (depth {depth}, tolerance {tolerance:.1f})"
                result_text += ":\n"
                
                for i, memory in enumerate(results, 1):
                    timestamp = memory.get('timestamp', 'Unknown')
                    content = memory.get('context', '')[:100] + ('...' if len(memory.get('context', '')) > 100 else '')
                    
                    # ì—°ê´€ê´€ê³„ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                    relation_info = ""
                    if memory.get('relation_type'):
                        if memory['relation_type'] == 'direct_match':
                            relation_info = " [ğŸ¯]"
                        elif 'depth_1' in memory['relation_type']:
                            relation_info = " [[LINK]]"
                        elif 'depth_2' in memory['relation_type']:
                            relation_info = " [[LINK][LINK]]"
                        elif 'depth_3' in memory['relation_type']:
                            relation_info = " [[LINK][LINK][LINK]]"
                    
                    result_text += f"{i}. [{timestamp}]{relation_info} {content}\n"
                return result_text
            else:
                return f"ğŸ” No memories found for query: '{query}'"
                
        except Exception as e:
            logger.error(f"search_memory failed: {e}")
            return f"[ERROR] Search failed: {str(e)}"
    
    def get_memory_stats_tool(self) -> str:
        """ë©”ëª¨ë¦¬ í†µê³„ ë„êµ¬ - ë¡œì»¬ DB ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•œ í†µê³„ ì œê³µ"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            db_manager = self.components['db_manager']
            stm_manager = self.components['stm_manager']
            
            # ì§ì ‘ SQLì„ ì‚¬ìš©í•œ ì •í™•í•œ í†µê³„ ê³„ì‚°
            stats = self._get_detailed_memory_stats(db_manager)
            
            # STM í†µê³„
            stm_stats = {}
            try:
                if hasattr(stm_manager, 'get_stats'):
                    stm_stats = stm_manager.get_stats()
                elif hasattr(stm_manager, 'cache'):
                    # STM ìºì‹œ ì§ì ‘ í™•ì¸
                    cache_data = stm_manager.cache
                    stm_stats = {
                        'active_count': len(cache_data) if isinstance(cache_data, dict) else 0,
                        'available_slots': max(0, 100 - len(cache_data)) if isinstance(cache_data, dict) else 100
                    }
            except:
                stm_stats = {'active_count': 0, 'available_slots': 100}
            
            return f"""ğŸ“Š **Greeum Memory Statistics**

**Long-term Memory (Local DB)**:
â€¢ Total Blocks: {stats['total_blocks']}
â€¢ This Week: {stats['week_count']}
â€¢ This Month: {stats['month_count']}
â€¢ Average Importance: {stats['avg_importance']:.2f}

**Short-term Memory**:
â€¢ Active Slots: {stm_stats.get('active_count', 0)}
â€¢ Available Slots: {stm_stats.get('available_slots', 100)}

**Database Info**:
â€¢ Database Path: {stats['db_path']}
â€¢ Last Updated: {stats['last_updated']}

**System Status**: âœ… Operational
**Version**: 2.3.0 (Local DB Optimized)"""
            
        except Exception as e:
            logger.error(f"get_memory_stats failed: {e}")
            return f"[ERROR] Stats retrieval failed: {str(e)}"
    
    def usage_analytics_tool(self, days: int = 7, report_type: str = "usage") -> str:
        """ì‚¬ìš© ë¶„ì„ ë„êµ¬ - ê¸°ì¡´ API ì™„ì „ í˜¸í™˜"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            # UsageAnalytics ì‹¤ì œ ë©”ì„œë“œ ì‚¬ìš©
            analytics_component = self.components['usage_analytics']
            if hasattr(analytics_component, 'get_usage_report'):
                analytics = analytics_component.get_usage_report(days=days, report_type=report_type)
            else:
                # fallback - ê¸°ë³¸ ë°ì´í„° ìƒì„±
                analytics = {
                    'total_operations': 'N/A',
                    'add_operations': 'N/A', 
                    'search_operations': 'N/A',
                    'avg_quality_score': 0.0,
                    'high_quality_rate': 0.0,
                    'avg_response_time': 0.0,
                    'success_rate': 1.0
                }
            
            return f"""[IMPROVE] **Usage Analytics Report** ({days} days)

**Activity Summary**:
â€¢ Total Operations: {analytics.get('total_operations', 0)}
â€¢ Memory Additions: {analytics.get('add_operations', 0)}
â€¢ Search Operations: {analytics.get('search_operations', 0)}

**Quality Metrics**:
â€¢ Average Quality Score: {analytics.get('avg_quality_score', 0):.1%}
â€¢ High Quality Rate: {analytics.get('high_quality_rate', 0):.1%}

**Performance**:
â€¢ Average Response Time: {analytics.get('avg_response_time', 0):.1f}ms
â€¢ Success Rate: {analytics.get('success_rate', 0):.1%}

**Report Type**: {report_type.title()}
**Generated**: Unified MCP v2.2.7"""
            
        except Exception as e:
            logger.error(f"usage_analytics failed: {e}")
            return f"[ERROR] Analytics failed: {str(e)}"
    
    def _add_memory_direct(self, content: str, importance: float = 0.5) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì§ì ‘ ì¶”ê°€ - legacy ì˜ì¡´ì„± ì™„ì „ ì œê±°"""
        from greeum.text_utils import process_user_input
        from datetime import datetime
        import json
        import hashlib
        
        if not self.components:
            raise Exception("Greeum components not available")
        
        db_manager = self.components['db_manager']
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
        result = process_user_input(content)
        result["importance"] = importance
        
        timestamp = datetime.now().isoformat()
        result["timestamp"] = timestamp
        
        # ë¸”ë¡ ì¸ë±ìŠ¤ ìƒì„±
        last_block_info = db_manager.get_last_block_info()
        if last_block_info is None:
            last_block_info = {"block_index": -1}
        block_index = last_block_info.get("block_index", -1) + 1
        
        # ì´ì „ í•´ì‹œ
        prev_hash = ""
        if block_index > 0:
            prev_block = db_manager.get_block(block_index - 1)
            if prev_block:
                prev_hash = prev_block.get("hash", "")
        
        # í•´ì‹œ ê³„ì‚°
        hash_data = {
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "prev_hash": prev_hash
        }
        hash_str = json.dumps(hash_data, sort_keys=True)
        hash_value = hashlib.sha256(hash_str.encode()).hexdigest()
        
        # ìµœì¢… ë¸”ë¡ ë°ì´í„°
        block_data = {
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "keywords": result.get("keywords", []),
            "tags": result.get("tags", []),
            "embedding": result.get("embedding", []),
            "importance": result.get("importance", 0.5),
            "hash": hash_value,
            "prev_hash": prev_hash
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        db_manager.add_block(block_data)
        
        return block_data
        
    def _search_memory_direct(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """ë©”ëª¨ë¦¬ ì§ì ‘ ê²€ìƒ‰ - legacy ì˜ì¡´ì„± ì™„ì „ ì œê±°"""
        from greeum.embedding_models import get_embedding
        
        if not self.components:
            raise Exception("Greeum components not available")
            
        db_manager = self.components['db_manager'] 
        search_engine = self.components['search_engine']
        
        # SearchEngine.search ë©”ì„œë“œ ì‚¬ìš© (search_memories ì•„ë‹˜)
        search_result = search_engine.search(query, top_k=limit)
        results = search_result.get('blocks', [])
        
        # ê²°ê³¼ë¥¼ legacy í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_results = []
        for result in results:
            formatted_results.append({
                "block_index": result.get("block_index"),
                "context": result.get("context"), 
                "timestamp": result.get("timestamp"),
                "relevance_score": result.get("relevance_score", 0.0),
                "keywords": result.get("keywords", []),
                "tags": result.get("tags", [])
            })
            
        return formatted_results
    
    def _expand_search_with_associations(self, base_results: List[Dict], depth: int, tolerance: float, max_results: int) -> List[Dict]:
        """
        ì—°ê´€ê´€ê³„ë¥¼ í™œìš©í•œ í™•ì¥ ê²€ìƒ‰
        
        Args:
            base_results: ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼
            depth: íƒìƒ‰ ê¹Šì´ (1-3)
            tolerance: ì—°ê´€ê´€ê³„ í—ˆìš© ì˜¤ì°¨ (0.0-1.0)
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            í™•ì¥ëœ ê²€ìƒ‰ ê²°ê³¼ (ì—°ê´€ê´€ê³„ ì •ë³´ í¬í•¨)
        """
        try:
            if not base_results or depth == 0:
                return base_results
            
            # AssociationSystem ì´ˆê¸°í™”
            from greeum.core.association_detector import AssociationSystem
            association_system = AssociationSystem()
            
            db_manager = self.components['db_manager']
            expanded_results = []
            processed_indices = set()
            
            # ê¸°ë³¸ ê²°ê³¼ë“¤ì„ ë¨¼ì € ì¶”ê°€ (ì›ë³¸ í‘œì‹œ)
            for memory in base_results:
                memory['relation_type'] = 'direct_match'
                expanded_results.append(memory)
                processed_indices.add(memory.get('block_index'))
            
            current_level_memories = base_results.copy()
            
            # ê° depth ë‹¨ê³„ë³„ë¡œ ì—°ê´€ ë©”ëª¨ë¦¬ íƒìƒ‰
            for current_depth in range(1, depth + 1):
                if len(expanded_results) >= max_results:
                    break
                    
                next_level_memories = []
                
                for memory in current_level_memories:
                    if len(expanded_results) >= max_results:
                        break
                    
                    # í˜„ì¬ ë©”ëª¨ë¦¬ì™€ ì—°ê´€ëœ ë©”ëª¨ë¦¬ë“¤ ì°¾ê¸°
                    associated_memories = self._find_associated_memories(
                        memory, association_system, tolerance, current_depth
                    )
                    
                    for assoc_memory in associated_memories:
                        if len(expanded_results) >= max_results:
                            break
                            
                        assoc_index = assoc_memory.get('block_index')
                        if assoc_index not in processed_indices:
                            assoc_memory['relation_type'] = f'depth_{current_depth}_association'
                            expanded_results.append(assoc_memory)
                            processed_indices.add(assoc_index)
                            next_level_memories.append(assoc_memory)
                
                current_level_memories = next_level_memories
                
                # ë” ì´ìƒ ìƒˆë¡œìš´ ì—°ê´€ ë©”ëª¨ë¦¬ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if not next_level_memories:
                    break
            
            return expanded_results[:max_results]
            
        except Exception as e:
            logger.error(f"Association expansion failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return base_results
    
    def _find_associated_memories(self, memory: Dict, association_system, tolerance: float, depth: int) -> List[Dict]:
        """
        íŠ¹ì • ë©”ëª¨ë¦¬ì™€ ì—°ê´€ëœ ë©”ëª¨ë¦¬ë“¤ ì°¾ê¸°
        
        Args:
            memory: ê¸°ì¤€ ë©”ëª¨ë¦¬
            association_system: ì—°ê´€ê´€ê³„ ì‹œìŠ¤í…œ
            tolerance: í—ˆìš© ì˜¤ì°¨
            depth: í˜„ì¬ íƒìƒ‰ ê¹Šì´
            
        Returns:
            ì—°ê´€ëœ ë©”ëª¨ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            db_manager = self.components['db_manager']
            
            # ì—°ê´€ë„ ì„ê³„ê°’ ê³„ì‚° (tolerance ê¸°ë°˜)
            base_threshold = 0.1  # ê¸°ë³¸ ì„ê³„ê°’
            adjusted_threshold = base_threshold * (1.0 - tolerance)  # tolerance ë†’ì„ìˆ˜ë¡ ë‚®ì€ ì„ê³„ê°’
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ ì—°ê´€ ë©”ëª¨ë¦¬ ê²€ìƒ‰
            if memory.get('embedding'):
                similar_memories = db_manager.search_blocks_by_embedding(
                    memory['embedding'], 
                    top_k=20,  # í›„ë³´êµ°ì„ ë„‰ë„‰íˆ
                    threshold=adjusted_threshold
                )
                
                # í˜„ì¬ ë©”ëª¨ë¦¬ ì œì™¸
                current_index = memory.get('block_index')
                filtered_memories = [m for m in similar_memories if m.get('block_index') != current_index]
                
                # tolerance ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ í•„í„°ë§
                final_memories = []
                for candidate in filtered_memories[:10]:  # ìƒìœ„ 10ê°œë§Œ ê³ ë ¤
                    # toleranceê°€ ë†’ì„ìˆ˜ë¡ ë” ë§ì€ ë©”ëª¨ë¦¬ í¬í•¨
                    similarity_score = self._calculate_similarity(memory, candidate)
                    if similarity_score >= adjusted_threshold:
                        final_memories.append(candidate)
                
                return final_memories
            
            return []
            
        except Exception as e:
            logger.error(f"Finding associated memories failed: {e}")
            return []
    
    def _calculate_similarity(self, memory1: Dict, memory2: Dict) -> float:
        """
        ë‘ ë©”ëª¨ë¦¬ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
        
        ì‹¤ì œë¡œëŠ” ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„, í‚¤ì›Œë“œ ê²¹ì¹¨ ë“±ì„ ì¢…í•©
        """
        try:
            import numpy as np
            
            # ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
            emb1 = memory1.get('embedding', [])
            emb2 = memory2.get('embedding', [])
            
            if emb1 and emb2 and len(emb1) == len(emb2):
                emb1_np = np.array(emb1)
                emb2_np = np.array(emb2)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                dot_product = np.dot(emb1_np, emb2_np)
                norm1 = np.linalg.norm(emb1_np)
                norm2 = np.linalg.norm(emb2_np)
                
                if norm1 > 0 and norm2 > 0:
                    return dot_product / (norm1 * norm2)
            
            # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
            keywords1 = set(memory1.get('keywords', []))
            keywords2 = set(memory2.get('keywords', []))
            
            if keywords1 and keywords2:
                intersection = keywords1.intersection(keywords2)
                union = keywords1.union(keywords2)
                return len(intersection) / len(union) if union else 0.0
            
            return 0.0
            
        except Exception as e:
            logger.error(f"Similarity calculation failed: {e}")
            return 0.0
    
    def _get_detailed_memory_stats(self, db_manager) -> Dict[str, Any]:
        """ë¡œì»¬ DBì—ì„œ ìƒì„¸í•œ ë©”ëª¨ë¦¬ í†µê³„ ì§ì ‘ ê³„ì‚°"""
        try:
            from datetime import datetime, timedelta
            import sqlite3
            
            # DB ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            db_path = getattr(db_manager, 'db_path', 'Unknown')
            
            # ì§ì ‘ SQL ì¿¼ë¦¬ ì‹¤í–‰ - ë¡œì»¬ DB ìš°ì„ 
            if hasattr(db_manager, 'conn') and db_manager.conn:
                conn = db_manager.conn
            elif hasattr(db_manager, 'db_path'):
                conn = sqlite3.connect(db_manager.db_path)
            else:
                # ë¡œì»¬ ë””ë ‰í† ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í™•ì¸
                import os
                local_db_path = './data/memory.db'
                if os.path.exists(local_db_path):
                    conn = sqlite3.connect(local_db_path)
                else:
                    # ëŒ€ì²´ ë¡œì»¬ ê²½ë¡œë“¤ ì‹œë„
                    alternative_paths = [
                        './memory.db',
                        './greeum_memory.db',
                        os.path.expanduser('~/greeum_local/memory.db')
                    ]
                    conn = None
                    for path in alternative_paths:
                        if os.path.exists(path):
                            conn = sqlite3.connect(path)
                            break
                    
                    if not conn:
                        raise FileNotFoundError("No local memory database found. Please ensure memory.db exists in current directory.")
            
            cursor = conn.cursor()
            
            # ì „ì²´ ë¸”ë¡ ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM blocks")
            total_blocks = cursor.fetchone()[0]
            
            # ì´ë²ˆ ì£¼ ë¸”ë¡ ìˆ˜
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            cursor.execute("SELECT COUNT(*) FROM blocks WHERE timestamp > ?", (week_ago,))
            week_count = cursor.fetchone()[0]
            
            # ì´ë²ˆ ë‹¬ ë¸”ë¡ ìˆ˜  
            month_ago = (datetime.now() - timedelta(days=30)).isoformat()
            cursor.execute("SELECT COUNT(*) FROM blocks WHERE timestamp > ?", (month_ago,))
            month_count = cursor.fetchone()[0]
            
            # í‰ê·  ì¤‘ìš”ë„
            cursor.execute("SELECT AVG(importance) FROM blocks WHERE importance IS NOT NULL")
            avg_importance_result = cursor.fetchone()[0]
            avg_importance = avg_importance_result if avg_importance_result else 0.5
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸
            cursor.execute("SELECT timestamp FROM blocks ORDER BY block_index DESC LIMIT 1")
            last_entry = cursor.fetchone()
            last_updated = last_entry[0] if last_entry else "Never"
            
            # ì—°ê²°ì´ ì„ì‹œë¡œ ìƒì„±ëœ ê²½ìš° ë‹«ê¸°
            if not (hasattr(db_manager, 'conn') and db_manager.conn):
                conn.close()
            
            return {
                'total_blocks': total_blocks,
                'week_count': week_count,
                'month_count': month_count,
                'avg_importance': avg_importance,
                'db_path': db_path,
                'last_updated': last_updated
            }
            
        except Exception as e:
            logger.error(f"Failed to get detailed stats: {e}")
            return {
                'total_blocks': 0,
                'week_count': 0,
                'month_count': 0,
                'avg_importance': 0.5,
                'db_path': 'Unknown',
                'last_updated': 'Error'
            }
    
    @abstractmethod
    async def run(self):
        """ì„œë²„ ì‹¤í–‰ (ê° ì–´ëŒ‘í„°ì—ì„œ êµ¬í˜„)"""
        pass