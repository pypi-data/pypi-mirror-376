Metadata-Version: 2.4
Name: MultiLayerPerceptron
Version: 0.1.0
Summary: ImplementaciÃ³n desde cero de un PerceptrÃ³n Multicapa en Python, sin librerÃ­as externas, con backpropagation y soporte para mÃºltiples capas.
Project-URL: Homepage, https://github.com/AsherGarciaO/MultiLayerPerceptron/
Author-email: Asher <ashergarciaortiz@gmail.com>
License-Expression: MIT
License-File: LICENSE
Requires-Python: >=3.8
Description-Content-Type: text/markdown

ğŸ§  Proyecto: PerceptrÃ³n Y PerceptrÃ³n Multicapa desde Cero

Este proyecto implementa un PerceptrÃ³n Multicapa (MLP) en Python, desarrollado sin librerÃ­as externas, Ãºnicamente con la biblioteca estÃ¡ndar.

El objetivo es mostrar cÃ³mo funcionan las redes neuronales artificiales desde sus fundamentos matemÃ¡ticos, sin depender de frameworks como TensorFlow o PyTorch, NumPy, etc.

âœ¨ CaracterÃ­sticas

-> ImplementaciÃ³n desde cero de un MLP (Multi-Layer Perceptron).

-> Funciones de activaciÃ³n clÃ¡sicas (Sigmoide, ReLU, Leaky ReLU y tanh).

-> Entrenamiento con backpropagation y gradiente descendente.

-> Soporte para mÃºltiples capas ocultas y diferentes cantidades de neuronas por capa.

Ejemplos de entrenamiento con problemas simples (ej. compuertas lÃ³gicas).

ğŸ¯ Objetivo

Este proyecto estÃ¡ pensado como material educativo para quienes quieran entender a detalle el funcionamiento interno de las redes neuronales y el algoritmo de retropropagaciÃ³n, sin â€œcaja negraâ€.