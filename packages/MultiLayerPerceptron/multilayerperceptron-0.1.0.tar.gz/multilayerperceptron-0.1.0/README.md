ğŸ§  Proyecto: PerceptrÃ³n Y PerceptrÃ³n Multicapa desde Cero

Este proyecto implementa un PerceptrÃ³n Multicapa (MLP) en Python, desarrollado sin librerÃ­as externas, Ãºnicamente con la biblioteca estÃ¡ndar.

El objetivo es mostrar cÃ³mo funcionan las redes neuronales artificiales desde sus fundamentos matemÃ¡ticos, sin depender de frameworks como TensorFlow o PyTorch, NumPy, etc.

âœ¨ CaracterÃ­sticas

-> ImplementaciÃ³n desde cero de un MLP (Multi-Layer Perceptron).

-> Funciones de activaciÃ³n clÃ¡sicas (Sigmoide, ReLU, Leaky ReLU y tanh).

-> Entrenamiento con backpropagation y gradiente descendente.

-> Soporte para mÃºltiples capas ocultas y diferentes cantidades de neuronas por capa.

Ejemplos de entrenamiento con problemas simples (ej. compuertas lÃ³gicas).

ğŸ¯ Objetivo

Este proyecto estÃ¡ pensado como material educativo para quienes quieran entender a detalle el funcionamiento interno de las redes neuronales y el algoritmo de retropropagaciÃ³n, sin â€œcaja negraâ€.