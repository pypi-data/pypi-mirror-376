from collections import OrderedDict
from pathlib import Path
from typing import Callable, overload, Self, Mapping, Any, Optional, Generator, Union, Sequence, MutableMapping

import torch.utils.data
from torch import Tensor

from safetensors_dataset.utils import TensorLayout

pack_tensor_t = dict[str, torch.Tensor]
pack_metadata_t = dict[str, Any] | None
pack_return_t = tuple[pack_tensor_t, pack_metadata_t]

class SafetensorsDataset(torch.utils.data.Dataset):
    dataset: dict[str, list[Any] | torch.Tensor]

    def __init__(self, dataset: MutableMapping[str, list[Any] | torch.Tensor] = None, preprocess: bool=False):
        pass

    def __contains__(self, item: str):
        return item in self.dataset

    def pack(self) -> Self: ...

    def shard(
        self,
        chunk_size: int = 5000,
        preprocess_if_unprocessed: bool = True,
    ) -> ShardedSafetensorsDataset | SafetensorsDataset: ...

    def filter(self, filter_fn: Callable[[dict[str, Tensor]], bool], tqdm: bool = True) -> SafetensorsDataset: ...

    def keys(self) -> set[str]: ...

    @overload
    def __getitem__(self, item: str) -> Tensor | list[Tensor]: ...
    @overload
    def __getitem__(self, item: int) -> dict[str, Tensor]: ...

    def __getitems__(self, items: list[int]) -> list[dict[str, Tensor]]: ...

    def __len__(self) -> int: ...

    @property
    def device(self) -> torch.device: ...

    def to(self, device: torch.device | int | str) -> SafetensorsDataset: ...

    def map(
        self,
        func: Callable[[dict[str, torch.Tensor]], dict[str, torch.Tensor]],
        info: Optional[Mapping[str, TensorLayout]] = None,
        use_tqdm: bool = True,
        batched: bool = False,
        batch_size: int = 1,
    ) -> "SafetensorsDataset": ...

    def select(self, indices: list[int], use_tqdm: bool = False) -> "SafetensorsDataset": ...

    def rename(self, key: str, new_key: str): ...

    def __add__(self, other: SafetensorsDataset) -> SafetensorsDataset: ...
    def __iadd__(self, other: SafetensorsDataset): ...

    def _transpose(self, batched=False, batch_size=0) -> Generator[Mapping[str, torch.Tensor], None, None]: ...

    def info(self) -> Mapping[str, TensorLayout]: ...

    def _save_to_dict(self) -> tuple[OrderedDict[str, Tensor], dict[str, Any]]: ...

    def save_to_file(self, path: Union[str, Path]): ...

    @classmethod
    def _load_from_dict(cls, tensors: dict[str, torch.Tensor], metadata: dict[str, Any]) -> SafetensorsDataset: ...

    @classmethod
    def load_from_file(cls, path: Path) -> SafetensorsDataset: ...

    @classmethod
    def from_dict(cls, x: dict[str, Tensor | list[Tensor]], *, preprocess: bool=False) -> SafetensorsDataset: ...

    @classmethod
    def from_list(cls, x: list[dict[str, Tensor]], *, preprocess: bool=False) -> SafetensorsDataset: ...

    @staticmethod
    def unpack_list_tensor(key: str, metadata: Mapping[str, Any], meta: Mapping[str, Any], storage: Mapping[str, torch.Tensor]): ...

    @staticmethod
    def unpack_nested_tensor(key: str, metadata: Mapping[str, Any], meta: Mapping[str, Any], storage: Mapping[str, torch.Tensor]): ...

    @staticmethod
    def unpack_sparse_tensor(key: str, metadata: Mapping[str, Any], meta: Mapping[str, Any], storage: Mapping[str, torch.Tensor]): ...

    @staticmethod
    def pack_single_tensor(key: str, tensor: torch.Tensor) -> pack_return_t: ...

    def pack_tensor_list(self, key: str, tensors: Sequence[torch.Tensor]) -> pack_return_t: ...

class ShardedSafetensorsDataset(torch.utils.data.Dataset):
    shards: tuple[SafetensorsDataset, ...]
    shard_size: int

    def __init__(self, shards: tuple[SafetensorsDataset, ...]): ...

    def __contains__(self, item) -> bool: ...

    def __len__(self) -> int: ...

    def __getitem__(self, item: int | str) -> dict[str, torch.Tensor] | torch.Tensor: ...

    def get_shard(self, pos: Optional[int] = None) -> SafetensorsDataset: ...

    def __getitems__(self, indices: list[int]) -> list[dict[str, torch.Tensor]]: ...

    def save_to_file(self, path: Union[str, Path]): ...

    @classmethod
    def _load_from_dict(cls, tensors: dict[str, Tensor], metadata: dict[str, Any]) -> ShardedSafetensorsDataset: ...

    @classmethod
    def load_from_file(cls, path: Union[str, Path]) -> ShardedSafetensorsDataset: ...