{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Flows distribution on a road network",
   "id": "16ec1d296a48d84f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialize the Sedona context passing Spark options to set the maximum memory for the Spark driver to 20GB, which is useful for handling large datasets.",
   "id": "89752b03aad404c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T12:50:36.606903Z",
     "start_time": "2025-08-30T12:50:30.448865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libadalina_core.sedona_configuration import init_sedona_context\n",
    "\n",
    "init_sedona_context(spark_configs={\n",
    "    \"spark.driver.memory\": \"20g\"\n",
    "})"
   ],
   "id": "c98f52174ce959e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://artifacts.unidata.ucar.edu/repository/unidata-all added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/marco/.ivy2/cache\n",
      "The jars for the packages stored in: /home/marco/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-3.3_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2d3b137d-a07e-4553-b23f-64fb31fc839e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-spark-3.3_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#sedona-common;1.7.1 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound org.locationtech.jts#jts-core;1.20.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/marco/Workspace/miniconda/v3/envs/adalina-analytics/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.locationtech.spatial4j#spatial4j;0.8 in central\n",
      "\tfound com.google.geometry#s2-geometry;2.0.0 in central\n",
      "\tfound com.google.guava#guava;25.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.uber#h3;4.1.1 in central\n",
      "\tfound net.sf.geographiclib#GeographicLib-Java;1.52 in central\n",
      "\tfound com.github.ben-manes.caffeine#caffeine;2.9.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.10.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-spark-common-3.3_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#shade-proto;1.7.1 in central\n",
      "\tfound org.xerial#sqlite-jdbc;3.41.2.2 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound graphframes#graphframes;0.8.3-spark3.4-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.beryx#awt-color-factory;1.0.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.7.1-28.5 in central\n",
      ":: resolution report :: resolve 361ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.5.1 from central in [default]\n",
      "\tcom.google.geometry#s2-geometry;2.0.0 from central in [default]\n",
      "\tcom.google.guava#guava;25.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.uber#h3;4.1.1 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tgraphframes#graphframes;0.8.3-spark3.4-s_2.12 from spark-packages in [default]\n",
      "\tnet.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-common;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-3.3_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-common-3.3_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#shade-proto;1.7.1 from central in [default]\n",
      "\torg.beryx#awt-color-factory;1.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.7.1-28.5 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.20.0 from central in [default]\n",
      "\torg.locationtech.spatial4j#spatial4j;0.8 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\torg.xerial#sqlite-jdbc;3.41.2.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.checkerframework#checker-qual;2.0.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   27  |   0   |   0   |   2   ||   25  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2d3b137d-a07e-4553-b23f-64fb31fc839e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 25 already retrieved (0kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:50:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the packages necessary to read the datasets from disk and set the base path of the datasets\n",
   "id": "80f50083eb87303f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T12:50:36.645660Z",
     "start_time": "2025-08-30T12:50:36.635180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "from libadalina_core.readers import geopackage_to_dataframe\n",
    "from libadalina_core.graph_extraction.readers import OpenStreetMapReader, RoadTypes\n",
    "import pandas as pd\n",
    "\n",
    "base_path = pathlib.Path(os.environ.get(\"SAMPLES_DIR\", \"\"))"
   ],
   "id": "326cd3e52d10fc80",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We also import `Timing` utility to monitor the computing time of the steps and the garbace collector module `gc` to force garbage collection since the following operations are memory intensive.\n",
   "id": "8f41c294c0e1ab2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T12:50:36.843335Z",
     "start_time": "2025-08-30T12:50:36.841149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libadalina_analytics.utils import Timing\n",
    "import gc"
   ],
   "id": "42e2375f201f763d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this step, we read two datasets:\n",
    "1. The OpenStreetMap roadmap of Lombardia region\n",
    "2. The GeoPackage containing population grid data of Lombardia\n",
    "\n",
    "The population dataset is optional for graph building. However, in this example, it is joined with the roadmap to enrich the graph edges by adding population data, specifically the number of people living within a 5 kilometers radius of each edge.\n",
    "\n",
    "Additionally, the graph is automatically enriched with distance information for each edge."
   ],
   "id": "f51cd86bfa14fef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T12:55:15.686714Z",
     "start_time": "2025-08-30T12:50:36.888966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libadalina_core.graph_extraction.builders import build_graph\n",
    "from libadalina_core.spatial_operators import AggregationFunction, AggregationType\n",
    "\n",
    "with Timing('Building graph: {}'):\n",
    "    osm_df = OpenStreetMapReader(RoadTypes.MAIN_ROADS).read(str(base_path / 'road_maps' / 'Lombardia.gpkg'))\n",
    "    population = geopackage_to_dataframe(\n",
    "        str(base_path / \"population-north-italy\" / \"Lombardia.gpkg\"),\n",
    "        \"dataframe\"\n",
    "    )[['T', 'geometry']]\n",
    "\n",
    "    graph = build_graph(osm_df,\n",
    "                        name='milan_road',\n",
    "                        joined_df=population,\n",
    "                        buffer_radius_meters=5000, # 5km buffer around the roads to consider population\n",
    "                        aggregate_functions=[\n",
    "                            AggregationFunction(\"T\", AggregationType.SUM, 'population', proportional='geometry_right')\n",
    "                        ]\n",
    "                        )\n",
    "\n",
    "    del osm_df\n",
    "    del population\n",
    "    gc.collect()\n",
    "    print(\"Created graph with\", graph.number_of_nodes(), \"nodes and\", graph.number_of_edges(), \"edges\")\n"
   ],
   "id": "54c418d704f98ae6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/Workspace/miniconda/v3/envs/adalina-analytics/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:50:46 WARN TaskSetManager: Stage 3 contains a task of very large size (1738 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:51:00 WARN TaskSetManager: Stage 4 contains a task of very large size (1738 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:51:08 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>  (0 + 16) / 16][Stage 6:>   (0 + 0) / 16][Stage 8:>   (0 + 0) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:51:08 WARN TaskSetManager: Stage 6 contains a task of very large size (1738 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                (0 + 16) / 16][Stage 8:>                 (0 + 0) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:51:14 WARN TaskSetManager: Stage 8 contains a task of very large size (1738 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:54:12 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created graph with 977287 nodes and 1749309 edges\n",
      "Building graph: 278.51437854766846\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We read two datasets for the flow distribution analysis:\n",
    "\n",
    "1. **Transportation Flows Dataset**:\n",
    "   - CSV file containing flow data between different regions of Lombardia\n",
    "   - Contains information about transportation demand between origin-destination pairs\n",
    "\n",
    "2. **Regional Shapes Dataset**:\n",
    "   - GeoPackage file containing geometric shapes of Lombardia regions\n",
    "   - Used to map flows between specific geographic areas\n",
    "\n",
    "In this example, we analyze flows between Milano's regions and Bergamo's regions.\n",
    "\n",
    "The `flows_distribution_algorithm` is then applied with:\n",
    "- Population-based cost weight: 0.7\n",
    "- Distance-based cost weight: 0.3\n",
    "\n",
    "The output is the `flows` DataFrame enriched with the paths going from each pair of source-destination regions.\n",
    "For each path we report the nodes traversed, the geometry of the path, the cost of the path, the distance and the amount of population involved.\n"
   ],
   "id": "13f223e00aac2d1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T13:00:01.338232Z",
     "start_time": "2025-08-30T12:58:12.060684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libadalina_analytics.flows_distribution.algorithms.flows_distribution_algorithm import flows_distribution_algorithm, GraphCost\n",
    "\n",
    "with Timing('Computing flows distribution: {}'):\n",
    "    flows = pd.read_csv(base_path / \"flows\" / \"matrice_od_2016_merci.csv\", sep=',')\n",
    "    flows['demand'] = flows.apply(lambda row: row['N1'] + row['N2'] + row['N3'], axis=1)\n",
    "\n",
    "    shapes = geopackage_to_dataframe(\n",
    "        str(base_path / \"flows\" / \"Shape_Matrice_OD2016_-_Veicoli_commerciali_e_pesanti_-_Zone_interne_20250816.gpkg\"),\n",
    "        'dataframe'\n",
    "    )\n",
    "\n",
    "    source_node_ids = [215, 218, 219, 220, 221, 222] # shape ID area of Milano\n",
    "    destination_node_ids = [10, 11, 12]  # shape ID area of Bergamo\n",
    "\n",
    "    result = flows_distribution_algorithm(graph, shapes, flows,\n",
    "                                 graph_costs=[\n",
    "                                     GraphCost(name='population', cost_per_unit=1, weight=.7),\n",
    "                                     GraphCost(name='distance', cost_per_unit=1, weight=.3),\n",
    "                                 ],\n",
    "                                 shapes_id_column='ID_Z_IIL',\n",
    "                                 flows_origin_id_column='Z_IIL_O',\n",
    "                                 flows_destination_id_column='Z_IIL_D',\n",
    "                                 flows_demand_column='demand',\n",
    "                                 sources=source_node_ids,\n",
    "                                 destinations=destination_node_ids,\n",
    "                             )\n",
    "    print(result.columns)\n",
    "    print(result.head())"
   ],
   "id": "1270f4b205ff6112",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:58:47 WARN RangeJoinExec: [SedonaSQL] Join dominant side partition number 16 is larger than 1/2 of the dominant side count 6\n",
      "25/08/30 14:58:47 WARN RangeJoinExec: [SedonaSQL] Try to use follower side partition number 16\n",
      "25/08/30 14:58:47 WARN RangeJoinExec: [SedonaSQL] Join follower side partition number is also larger than 1/2 of the dominant side count 6\n",
      "25/08/30 14:58:47 WARN RangeJoinExec: [SedonaSQL] Try to use 1/2 of the dominant side count 3 as the partition number of both sides\n",
      "25/08/30 14:58:47 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "25/08/30 14:58:47 WARN TaskSetManager: Stage 74 contains a task of very large size (7198 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/30 14:58:49 WARN RangeJoinExec: [SedonaSQL] Join dominant side partition number 16 is larger than 1/2 of the dominant side count 3\n",
      "25/08/30 14:58:49 WARN RangeJoinExec: [SedonaSQL] Try to use follower side partition number 16\n",
      "25/08/30 14:58:49 WARN RangeJoinExec: [SedonaSQL] Join follower side partition number is also larger than 1/2 of the dominant side count 3\n",
      "25/08/30 14:58:49 WARN RangeJoinExec: [SedonaSQL] Try to use 1/2 of the dominant side count 1 as the partition number of both sides\n",
      "25/08/30 14:58:49 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n",
      "25/08/30 14:58:49 WARN TaskSetManager: Stage 78 contains a task of very large size (7198 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Z_IIL_O', 'Z_IIL_D', 'Z_IIL_O_NOME', 'Z_IIL_D_NOME', 'N1', 'N2', 'N3',\n",
      "       'demand', 'path', 'geometry', 'path_cost', 'population', 'distance'],\n",
      "      dtype='object')\n",
      "   Z_IIL_O  Z_IIL_D        Z_IIL_O_NOME                   Z_IIL_D_NOME     N1  \\\n",
      "0      219       10  MILANO 5-MILANO 16            BERGAMO 1-BERGAMO 7  21.20   \n",
      "1      219       12  MILANO 5-MILANO 16  BERGAMO 2-BERGAMO 3-BERGAMO 4  20.15   \n",
      "2      220       11   MILANO 6-MILANO 8            BERGAMO 5-BERGAMO 6  20.71   \n",
      "3      220       12   MILANO 6-MILANO 8  BERGAMO 2-BERGAMO 3-BERGAMO 4   0.00   \n",
      "4      221       10  MILANO 9-MILANO 10            BERGAMO 1-BERGAMO 7   0.00   \n",
      "\n",
      "     N2    N3  demand                                               path  \\\n",
      "0  2.72  3.71   27.63  [60129574356, 120259116670, 42949705128, 34359...   \n",
      "1  2.84  3.64   26.63  [60129574356, 120259116670, 42949705128, 34359...   \n",
      "2  3.14  5.04   28.89  [8589936430, 42949674304, 42949676808, 3435974...   \n",
      "3  3.18  4.44    7.62  [8589936430, 42949674304, 42949676808, 3435974...   \n",
      "4  1.99  0.95    2.94  [17179890910, 68719497349, 77309430582, 687194...   \n",
      "\n",
      "                                            geometry     path_cost  \\\n",
      "0  MULTILINESTRING ((9.2002 45.51078, 9.20059 45....  2.574238e+07   \n",
      "1  MULTILINESTRING ((9.2002 45.51078, 9.20059 45....  2.438661e+07   \n",
      "2  MULTILINESTRING ((9.24599 45.47091, 9.24603 45...  1.176192e+07   \n",
      "3  MULTILINESTRING ((9.24599 45.47091, 9.24603 45...  3.720047e+06   \n",
      "4  MULTILINESTRING ((9.20449 45.42102, 9.20453 45...  1.541527e+06   \n",
      "\n",
      "     population      distance  \n",
      "0  1.310490e+06  47796.333286  \n",
      "1  1.282591e+06  59810.338307  \n",
      "2  5.505338e+05  72513.981040  \n",
      "3  6.649290e+05  75816.207231  \n",
      "4  7.116235e+05  87308.202540  \n",
      "Computing flows distribution: 109.27334570884705\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
