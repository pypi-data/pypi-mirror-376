{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation (arXiv:1505.04597). arXiv. https://doi.org/10.48550/arXiv.1505.04597\n",
    "\n",
    "ISBI-2012 electron microscopy data: https://downloads.imagej.net/ISBI-2012-challenge.zip\n",
    "\n",
    "https://github.com/alexklibisz/isbi-2012/blob/master/notebooks/data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing as T\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tifffile as tiff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.modules.loss as torch_loss\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as vision_trafos_v2\n",
    "from einops import rearrange\n",
    "from tensordict import tensorclass\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "from torchvision import tv_tensors\n",
    "\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_em_data = Path(\"../data/ISBI-2012-challenge\")\n",
    "path_em_data, path_em_data.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tiff.imread(path_em_data / \"train-volume.tif\")\n",
    "Y = tiff.imread(path_em_data / \"train-labels.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_x, _y) in enumerate(zip(X, Y)):\n",
    "\n",
    "    if i > 3:\n",
    "        break\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=2)\n",
    "    axs[0].imshow(_x)\n",
    "    axs[1].imshow(_y)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.mean(), _x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(_y.ravel()), Counter(_x.ravel()).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISBIDatasetWithLabels(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        transform: nn.Module = None,  # https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py\n",
    "        add_channel: bool = True,\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n = len(X)\n",
    "        if X.shape != Y.shape:\n",
    "            raise ValueError(\n",
    "                f\"X and y must have same length, got {X.shape=} and {Y.shape=}\"\n",
    "            )\n",
    "\n",
    "        self.transform = transform\n",
    "        self.add_channel = add_channel\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx: int) -> T.Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        img = tv_tensors.Image(self.X[idx])\n",
    "        labels = tv_tensors.Mask(self.Y[idx] == 255)\n",
    "\n",
    "        if self.transform:\n",
    "            img, labels = self.transform(img, labels)\n",
    "\n",
    "        return img, labels\n",
    "\n",
    "\n",
    "class ISBIDatasetWithLabelsIterable(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        transform: nn.Module = None,  # https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py\n",
    "        add_channel: bool = True,\n",
    "        n_repetitions: int = 1,\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n_repetitions = n_repetitions\n",
    "        self.n = len(X)\n",
    "        if X.shape != Y.shape:\n",
    "            raise ValueError(\n",
    "                f\"X and y must have same length, got {X.shape=} and {Y.shape=}\"\n",
    "            )\n",
    "\n",
    "        self.transform = transform\n",
    "        self.add_channel = add_channel\n",
    "\n",
    "    def generate(self) -> T.Iterator[T.Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        for _ in range(self.n_repetitions):\n",
    "            for idx in range(self.n):\n",
    "                img = tv_tensors.Image(self.X[idx])\n",
    "                labels = tv_tensors.Mask(self.Y[idx] == 255)\n",
    "\n",
    "                if self.transform:\n",
    "                    img, labels = self.transform(img, labels)\n",
    "\n",
    "                yield img, labels\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        return iter(self.generate())\n",
    "\n",
    "\n",
    "@tensorclass\n",
    "class ISBIBlockWithLabels:\n",
    "    image: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "\n",
    "\n",
    "def collate_isbi_dataset_to_block_with_labels(\n",
    "    input: T.List[T.Tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> ISBIBlockWithLabels:\n",
    "\n",
    "    images = torch.stack([v[0] for v in input])\n",
    "    labels = torch.stack([v[1] for v in input])\n",
    "    return ISBIBlockWithLabels(\n",
    "        image=images, labels=labels, batch_size=[images.shape[0]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafos = vision_trafos_v2.Compose(\n",
    "    [\n",
    "        vision_trafos_v2.RandomAffine(degrees=0, shear=5),\n",
    "        vision_trafos_v2.RandomCrop(size=(64, 64)),\n",
    "        vision_trafos_v2.RandomVerticalFlip(),\n",
    "        vision_trafos_v2.RandomHorizontalFlip(),\n",
    "        vision_trafos_v2.ToDtype(torch.float32),\n",
    "        vision_trafos_v2.Normalize(mean=[0.0], std=[255.0]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train = ISBIDatasetWithLabels(X1, Y1, transform=trafos)\n",
    "# ds_valid = ISBIDatasetWithLabels(X[-5:], Y[-5:], transform=trafos)\n",
    "n_repetitiopns = 5\n",
    "X0, X1, Y0, Y1 = X[:-5], X[-5:], Y[:-5], Y[-5:]\n",
    "ds_train = ISBIDatasetWithLabelsIterable(\n",
    "    X0, Y0, transform=trafos, n_repetitions=n_repetitiopns\n",
    ")\n",
    "ds_valid = ISBIDatasetWithLabelsIterable(\n",
    "    X1, Y1, transform=trafos, n_repetitions=n_repetitiopns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_labels(image: torch.Tensor, labels: torch.Tensor):\n",
    "    fig, axs = plt.subplots(ncols=2, nrows=2)\n",
    "\n",
    "    axs[0, 0].imshow(image[0])\n",
    "    axs[0, 1].imshow(labels)\n",
    "\n",
    "    sns.histplot(x=image[0].ravel(), ax=axs[1, 0])\n",
    "    sns.histplot(x=labels.ravel(), ax=axs[1, 1])\n",
    "\n",
    "    print(image[0].ravel().mean(), image[0].ravel().std())\n",
    "    print(image[0].ravel().min(), image[0].ravel().max())\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# img, labels = ds_train[0]\n",
    "img, labels = next(iter(ds_train.generate()))\n",
    "\n",
    "show_image_and_labels(img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # *n_repetitiopns\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_isbi_dataset_to_block_with_labels,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_isbi_dataset_to_block_with_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        self.act_conv1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "        self.act_conv2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, nonlinearity=\"relu\")\n",
    "        self.act_conv3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv4.weight, nonlinearity=\"relu\")\n",
    "        self.act_conv4 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=1,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv5.weight, nonlinearity=\"relu\")\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.act_conv1,\n",
    "            self.conv2,\n",
    "            self.act_conv2,\n",
    "            self.conv3,\n",
    "            self.act_conv3,\n",
    "            self.conv4,\n",
    "            self.act_conv4,\n",
    "            self.conv5,\n",
    "        )\n",
    "\n",
    "    def forward(self, input: ISBIBlockWithLabels) -> torch.Tensor:\n",
    "        x = input.image.float()\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEISBI(torch_loss.BCEWithLogitsLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(\n",
    "        self, inference: torch.Tensor, input: ISBIBlockWithLabels\n",
    "    ) -> torch.Tensor:\n",
    "        return super().forward(inference.ravel(), input.labels.ravel().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = BCEISBI()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\n",
    "    \"./models\"\n",
    ")  # location used by learner.find_learning_rate to store the model before the search\n",
    "\n",
    "# the name_patterns used below work only because of how DenseNet and Layer are defined, you may have to use different patterns\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*act.*\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*conv.*\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*conv.*\",)\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=50, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\", ylim=(1e-1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_steps_per_epoch(\n",
    "    ds_train: T.Union[Dataset, IterableDataset],\n",
    "    dl_train: DataLoader,\n",
    "    X0: np.ndarray,\n",
    "    n_repetitiopns: int,\n",
    "    batch_size: int,\n",
    ") -> int:\n",
    "    if hasattr(ds_train, \"__len__\"):\n",
    "        steps_per_epoch = len(dl_train)\n",
    "    else:\n",
    "        steps_per_epoch = math.ceil(len(X0) * n_repetitiopns / batch_size)\n",
    "    return steps_per_epoch\n",
    "\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(\n",
    "    ds_train, dl_train, X0, n_repetitiopns, batch_size\n",
    ")\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 4e-4\n",
    "n_epochs = 50\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot(yscale=\"log\", window=20, window_valid=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits, inputs = learner.predict(dl_valid, return_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = y_logits.detach().sigmoid().numpy()\n",
    "y_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_simple = loss_callback.get_losses_valid()\n",
    "\n",
    "losses_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inputs_labels_and_predictions(\n",
    "    ix: int, inputs: ISBIBlockWithLabels, y_prob: np.ndarray\n",
    "):\n",
    "    fig, axs = plt.subplots(ncols=3)\n",
    "\n",
    "    axs[0].imshow(inputs.image[ix, 0])\n",
    "    axs[1].imshow(inputs.labels[ix])\n",
    "    axs[2].imshow(y_prob[ix, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(y_logits.shape[0]):\n",
    "    show_inputs_labels_and_predictions(ix, inputs, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(shallow) u-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in: int, n_out: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=n_in,\n",
    "            out_channels=n_out,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=n_out,\n",
    "            out_channels=n_out,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.act1, self.conv2, self.act2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ResConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in: int, n_out: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=n_in,\n",
    "            out_channels=n_out,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=n_out,\n",
    "            out_channels=n_out,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x0 = self.act1(self.conv1(x))\n",
    "        x1 = self.act2(self.conv2(x0))\n",
    "        return x0 + x1\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in: int, n_out: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up_nn = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.up_conv = nn.Conv2d(n_in, n_out, kernel_size=3, padding=\"same\")\n",
    "        nn.init.kaiming_normal_(self.up_conv.weight, nonlinearity=\"relu\")\n",
    "        self.up_act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.up_nn(x)\n",
    "        return self.up_act(self.up_conv(x))\n",
    "\n",
    "\n",
    "def get_conv_block(\n",
    "    n_in: int, n_out: int, res: bool\n",
    ") -> T.Union[ConvBlock, ResConvBlock]:\n",
    "    if res:\n",
    "        return ResConvBlock(n_in=n_in, n_out=n_out)\n",
    "    else:\n",
    "        return ConvBlock(n_in=n_in, n_out=n_out)\n",
    "\n",
    "\n",
    "class Model2Layers(nn.Module):\n",
    "\n",
    "    def __init__(self, res: bool = False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.net_in = get_conv_block(n_in=1, n_out=64, res=res)  # h/w 64\n",
    "\n",
    "        self.sample_down = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  # h/w 32\n",
    "\n",
    "        self.mid_conv = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )  # h/w 32\n",
    "        nn.init.kaiming_normal_(self.mid_conv.weight, nonlinearity=\"relu\")\n",
    "        self.mid_act_conv = nn.ReLU()\n",
    "\n",
    "        self.sample_up = Up(n_in=128, n_out=64)  # h/w 64\n",
    "\n",
    "        self.net_out = get_conv_block(n_in=128, n_out=64, res=res)  # h/w 64\n",
    "\n",
    "        self.net_final = nn.Conv2d(\n",
    "            in_channels=64, out_channels=1, kernel_size=(1, 1), padding=\"same\"\n",
    "        )  # h/w 64\n",
    "\n",
    "    def forward(self, input: ISBIBlockWithLabels) -> torch.Tensor:\n",
    "        x = input.image.float()\n",
    "        x = self.net_in(x)\n",
    "\n",
    "        y = self.sample_down(x)\n",
    "        y = self.mid_act_conv(self.mid_conv(y))\n",
    "\n",
    "        y = self.sample_up(y)\n",
    "\n",
    "        z = torch.cat((x, y), dim=1)\n",
    "\n",
    "        z = self.net_out(z)\n",
    "        z = self.net_final(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class Model3Layers(nn.Module):\n",
    "\n",
    "    def __init__(self, res: bool):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.net_in = get_conv_block(n_in=1, n_out=64, res=res)  # h/w 64\n",
    "\n",
    "        self.sample_down1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  # h/w 32\n",
    "\n",
    "        self.net_down_layer1 = get_conv_block(\n",
    "            n_in=64, n_out=128, res=res\n",
    "        )  # h/w 32\n",
    "\n",
    "        self.sample_down2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  # h/w 16\n",
    "\n",
    "        self.mid_conv = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=256,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "        )  # h/w 16\n",
    "        nn.init.kaiming_normal_(self.mid_conv.weight, nonlinearity=\"relu\")\n",
    "        self.mid_act_conv = nn.ReLU()\n",
    "\n",
    "        self.sample_up1 = Up(n_in=256, n_out=128)  # h/w 32\n",
    "\n",
    "        self.net_up_layer1 = get_conv_block(\n",
    "            n_in=256, n_out=128, res=res\n",
    "        )  # h/w 32\n",
    "\n",
    "        self.sample_up2 = Up(n_in=128, n_out=64)  # h/w 64\n",
    "\n",
    "        self.net_out = get_conv_block(n_in=128, n_out=64, res=res)  # h/w 64\n",
    "\n",
    "        self.net_final = nn.Conv2d(\n",
    "            in_channels=64, out_channels=1, kernel_size=(1, 1), padding=\"same\"\n",
    "        )  # h/w 64\n",
    "\n",
    "    def forward(self, input: ISBIBlockWithLabels) -> torch.Tensor:\n",
    "\n",
    "        x0 = input.image.float()\n",
    "        x0 = self.net_in(x0)\n",
    "\n",
    "        x1 = self.sample_down1(x0)\n",
    "        x1 = self.net_down_layer1(x1)\n",
    "\n",
    "        z = self.sample_down2(x1)\n",
    "        z = self.mid_act_conv(self.mid_conv(z))\n",
    "\n",
    "        x4 = self.sample_up1(z)\n",
    "        x4 = torch.cat((x1, x4), dim=1)\n",
    "        x4 = self.net_up_layer1(x4)\n",
    "\n",
    "        x5 = self.sample_up2(x4)\n",
    "        x5 = torch.cat((x0, x5), dim=1)\n",
    "        x5 = self.net_out(x5)\n",
    "\n",
    "        y = self.net_final(x5)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model3Layers(res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = BCEISBI()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\n",
    "    \"./models\"\n",
    ")  # location used by learner.find_learning_rate to store the model before the search\n",
    "\n",
    "# the name_patterns used below work only because of how DenseNet and Layer are defined, you may have to use different patterns\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*act.*\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*conv.*\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*conv.*\",)\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=50, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"linear\", ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = calc_steps_per_epoch(\n",
    "    ds_train, dl_train, X0, n_repetitiopns, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "n_epochs = 50\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits, inputs = learner.predict(dl_valid, return_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = y_logits.detach().sigmoid().numpy()\n",
    "y_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_shallow = loss_callback.get_losses_valid()\n",
    "display(losses_simple.tail(), losses_shallow.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=losses_simple, x=\"iteration\", y=\"loss_valid\", label=\"simple\", ax=ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=losses_shallow, x=\"iteration\", y=\"loss_valid\", label=\"u-net\", ax=ax\n",
    ")\n",
    "\n",
    "ax.legend(title=\"model\")\n",
    "ax.set(yscale=\"log\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(y_logits.shape[0]):\n",
    "    show_inputs_labels_and_predictions(ix, inputs, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
