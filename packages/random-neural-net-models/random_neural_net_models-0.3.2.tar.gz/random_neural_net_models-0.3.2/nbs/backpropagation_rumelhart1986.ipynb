{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* _Rumelhart et al. 1986, Learning representations by back-propagating errors_, [nature](https://www.nature.com/articles/323533a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.datasets as sk_datasets\n",
    "import sklearn.model_selection as model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random_neural_net_models.backprop_rumelhart as backprop_rumelhart\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_datasets.make_regression(\n",
    "    n_samples=100, n_features=1, noise=20, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1, y0, y1 = model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X0[:, 0], y=y0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_datasets.make_blobs(\n",
    "    n_samples=1_000,\n",
    "    n_features=2,\n",
    "    centers=2,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_train[:, 0], y=X_train[:, 1], hue=y_train, alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumelhart et al. 1986, \"Learning representations by back-propagating errors\"\n",
    "> The following is in the spirit of the paper, *cough*. Found the presentation in the paper somewhat hard to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With input $x$ we predict $y$ using a function $f$ like\n",
    "\n",
    "$$\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$ uses weight $w$ and some non-linearity $g$ like\n",
    "\n",
    "$$\n",
    "z =  x \\cdot w^T \\\\\n",
    "f(x) = g(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper they use the sigmoid\n",
    "$$\n",
    "g(z) = \\frac{1}{1+\\exp(-z)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicating repeating weight multiplication and non-linearity with index $i$ (layer), we can write\n",
    "\n",
    "$$\n",
    "\n",
    "z_1 =  x \\cdot w_1 ^ T \\\\\n",
    "a_1 = g_1(z_1) \\\\\n",
    "\n",
    "...\\\\\n",
    "\n",
    "z_{i} = a_{i-1} \\cdot w_{i}^T \\\\\n",
    "a_{i} = g_{i}(z_{i}) \\\\\n",
    "\n",
    "...\\\\\n",
    "\n",
    "z_N = a_{N-1} \\cdot w_N^T \\\\\n",
    "a_N = g_N(z_N) \\\\\n",
    "\n",
    "f(x) = a_N\n",
    "\n",
    "$$\n",
    "\n",
    "where $a_i$ is \"activation\" of layer $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing predictions to desired valued $d$ we denote deviations / the loss as $l(d,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can identify how to change $w_i$ by how much lead to the strongest improvement of $l(d,y)$ for any $x$, $y$, $d$ by differentiating $l$. A straightforward way is scaling that gradient and applying it like\n",
    "\n",
    "$$\n",
    "\n",
    "w_{i,\\text{new}} = w_{i,\\text{old}} + \\epsilon \\frac{d}{dw_i}l(d,y)\n",
    "\n",
    "$$\n",
    "\n",
    "with some factor $\\epsilon \\in [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{d}{dw_i}l(d,y)$ can analytically be derived using the chain rule as \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{d}{dw_i}l(d,y) = l^\\prime(d,y) \\cdot g_N^\\prime(z_N) \\cdot z_N^\\prime \\cdot g_{N-1}^\\prime(z_{N-1}) \\cdot z_{N-1}^\\prime \\cdot \\space ... \\space \\cdot g_{i}^\\prime(z_{i}) \\cdot a_{i-1}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing $z^\\prime = \\frac{\\partial}{\\partial a}z = w ^ T$\n",
    "$$\n",
    "\n",
    "\\frac{d}{dw_i}l(d,y) = l^\\prime(d,y) \\cdot g_N^\\prime(z_N) \\cdot w_N ^ T \\cdot g_{N-1}^\\prime(z_{N-1}) \\cdot w_{N-1} ^ T \\cdot \\space ... \\space \\cdot g_{i}^\\prime(z_{i}) \\cdot a_{i-1}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another version proposed in Rumelhart et al. is\n",
    "$$\n",
    "\n",
    "w_{i,\\text{new}} = w_{i,\\text{old}} + \\epsilon \\frac{d}{dw_i}l(d,y) + \\alpha \\left( \\frac{d}{dw_i}l(d,y) \\right)_\\text{old}\n",
    "\n",
    "$$\n",
    "\n",
    "with some factor $\\alpha \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-10, 10, 100)\n",
    "a = backprop_rumelhart.sigmoid(x)\n",
    "a_prime = backprop_rumelhart.sigmoid_derivative(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=x, y=a, label=\"g(z): sigmoid\")\n",
    "sns.lineplot(x=x, y=a_prime, label=\"dg(z)/dz: sigmoid derivative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backprop_rumelhart.Rumelhart1986PerceptronClassifier(\n",
    "    n_hidden=(10, 5), epochs=10, verbose=True, eps=1e-3, alpha=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T\n",
    "X_plot[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_prob.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and now with `Learner` & pytorch tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.NumpyTrainingDataset(X_train, y_train)\n",
    "ds_val = rnnm_data.NumpyTrainingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=10,\n",
    "    collate_fn=rnnm_data.collate_numpy_dataset_to_xyblock,\n",
    "    shuffle=True,\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "    ds_val,\n",
    "    batch_size=10,\n",
    "    collate_fn=rnnm_data.collate_numpy_dataset_to_xyblock,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backprop_rumelhart.Rumelhart1986PytorchPerceptron(\n",
    "    n_hidden=(2, 10, 5, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "optimizer = optim.SGD(model.parameters(), lr=10, momentum=1e-3)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=10,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "loss = backprop_rumelhart.BCELoss()\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*act\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*lin\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*lin\",)\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "    scheduler_callback,\n",
    "]\n",
    "\n",
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=2, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T\n",
    "X_plot[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_plot = rnnm_data.NumpyInferenceDataset(X_plot)\n",
    "dl_plot = DataLoader(\n",
    "    ds_plot, batch_size=5, collate_fn=rnnm_data.collate_numpy_dataset_to_xblock\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = learner.predict(dl_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = y_prob.detach().numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_prob.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
