{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random_neural_net_models.mingpt.char as char\n",
    "import random_neural_net_models.mingpt.model as gpt_model\n",
    "import random_neural_net_models.mingpt.trainer as gpt_trainer\n",
    "import random_neural_net_models.mingpt.utils as gpt_utils\n",
    "import random_neural_net_models.utils as utils\n",
    "\n",
    "logger = utils.get_logger(\"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = char.DataConfig(block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O ../data/tiny-shakespear.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training dataset\n",
    "text = open(\"../data/tiny-shakespear.txt\", \"r\").read()\n",
    "train_dataset = char.CharDataset(data_config, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get default config and overrides from the command line, if any\n",
    "config = char.get_config(\n",
    "    max_iters=10,\n",
    "    vocab_size=train_dataset.get_vocab_size(),\n",
    "    block_size=train_dataset.get_block_size(),\n",
    ")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_utils.set_seed(config.system.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpt_model.GPT(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the trainer object\n",
    "trainer = gpt_trainer.Trainer(config.trainer, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration callback\n",
    "\n",
    "\n",
    "def batch_end_callback(trainer: gpt_trainer.Trainer):\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        logger.info(\n",
    "            f\"iter_dt {trainer.iter_dt * 1000:.2f} ms; iter {trainer.iter_num:_d}: train loss {trainer.loss.item():.5f}\"\n",
    "        )\n",
    "\n",
    "    if trainer.iter_num % 500 == 0:\n",
    "        # evaluate both the train and test score\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # sample from the model...\n",
    "            context = \"O God, O God!\"\n",
    "            x = torch.tensor(\n",
    "                [train_dataset.stoi[s] for s in context], dtype=torch.long\n",
    "            )[None, ...].to(trainer.device)\n",
    "            y = model.generate(\n",
    "                x, 500, temperature=1.0, do_sample=True, top_k=10\n",
    "            )[0]\n",
    "            completion = \"\".join([train_dataset.itos[int(i)] for i in y])\n",
    "            logger.info(completion)\n",
    "\n",
    "        # revert model to training mode\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_callback(\"on_batch_end\", batch_end_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the optimization\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_str(x: int) -> str:\n",
    "    return train_dataset.itos[int(x)]\n",
    "\n",
    "\n",
    "def tensor_int_to_str(x: torch.Tensor) -> str:\n",
    "    return \"\".join([int_to_str(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_int, y_int in train_dataset:\n",
    "    pred_int = model.generate(x_int.unsqueeze(0), 30, do_sample=False)\n",
    "\n",
    "    print(f\">>> x: \\n{tensor_int_to_str(x_int)}\\n\")\n",
    "    print(f\">>> y: \\n{tensor_int_to_str(y_int)}\\n\")\n",
    "    print(f\">>> pred: \\n{tensor_int_to_str(pred_int[0])}\\n\\n\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
