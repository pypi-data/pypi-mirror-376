{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion on MNIST: predicting the noise\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Train UNet to predict noise given noisified image\n",
    "2. Train UNet to predict noise given noisified image AND the noise level used\n",
    "\n",
    "Sampling is so finnicky!!11!!!1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* fastai 2022 / 2023 course part II:\n",
    "    * [notebook 26](https://github.com/fastai/course22p2/blob/master/nbs/26_diffusion_unet.ipynb)\n",
    "    * [lesson 19](https://course.fast.ai/Lessons/lesson19.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include all digits\n",
    "# TODO: include the digit itself (beyond the image) as information to pass to the model (especially for sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random_neural_net_models.convolution_lecun1990 as conv_lecun1990\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.losses as rnnm_losses\n",
    "import random_neural_net_models.telemetry as telemetry\n",
    "import random_neural_net_models.unet as unet\n",
    "import random_neural_net_models.unet_with_noise as unet_with_noise\n",
    "import random_neural_net_models.utils as utils\n",
    "\n",
    "logger = utils.get_logger(\"nb\")\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_OVERFITTING_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a few images to overfit on (limiting to the number 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 32\n",
    "n1 = 1_000\n",
    "is_5 = y == \"5\"\n",
    "X0, y0 = X.loc[is_5].iloc[:n0], y.loc[is_5].iloc[:n0]\n",
    "X1, y1 = X.loc[is_5].iloc[n0 : n1 + n0], y.loc[is_5].iloc[n0 : n0 + n1]\n",
    "X0.shape, X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.MNISTDatasetWithLabels(\n",
    "    X0, y0, one_hot=False, add_channel=False\n",
    ")\n",
    "ds_valid = rnnm_data.MNISTDatasetWithLabels(\n",
    "    X1, y1, one_hot=False, add_channel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = ds_train[0]\n",
    "plt.imshow(img, cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = ds_valid[0]\n",
    "plt.imshow(img, cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying noise based on \n",
    "```python\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    sig = (torch.randn([len(x0)])*1.2-1.2).exp().to(x0).reshape(-1,1,1,1)\n",
    "    noise = torch.randn_like(x0, device=device)\n",
    "    c_skip,c_out,c_in = scalings(sig)\n",
    "    noised_input = x0 + noise*sig\n",
    "    target = (x0-c_skip*noised_input)/c_out\n",
    "    return (noised_input*c_in,sig.squeeze()),target\n",
    "```\n",
    "from https://github.com/fastai/course22p2/blob/master/nbs/26_diffusion_unet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = n0\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=unet_with_noise.mnist_noisy_collate_train,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=500,\n",
    "    shuffle=False,\n",
    "    collate_fn=unet_with_noise.mnist_noisy_collate_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = []\n",
    "for _ in range(10):\n",
    "    for b in dl_train:\n",
    "        noise_levels.append(b.noise_level.detach())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "sns.histplot(torch.concat(noise_levels).numpy(), ax=ax)\n",
    "ax.set(xlabel=\"Noise level\", ylabel=\"Count\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting the noisified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b: unet_with_noise.MNISTNoisyDataTrain = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 0\n",
    "noisy_input_image = b.noisy_image[ix_img].cpu()\n",
    "target_noise = b.target_noise[ix_img].cpu()\n",
    "noise_level = b.noise_level[ix_img].cpu()\n",
    "noisy_input_image.shape, target_noise.shape, noise_level.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_skip, c_out, c_in = unet_with_noise.get_cs(noise_level)\n",
    "denoised_image = unet_with_noise.get_denoised_images(\n",
    "    noisy_input_image, target_noise, noise_level\n",
    ")\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 7))\n",
    "ax = axs[0]\n",
    "ax.imshow(noisy_input_image, cmap=\"gray\")\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(target_noise, cmap=\"gray\")\n",
    "ax.set_title(\"Target noise\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[2]\n",
    "ax.imshow(denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Denoised image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "    noisy_input_image, target_noise, denoised_image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting digit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_with_noise.UNetModelTensordict(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    list_num_features=(\n",
    "        8,\n",
    "        16,\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10_000\n",
    "lr = 1e-1\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss = unet_with_noise.MSELossMNISTNoisy()\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(\".*act.*\",),\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]\n",
    "\n",
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 10, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=200, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=lr,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(\n",
    "    dl_train,\n",
    "    n_epochs=n_epochs,\n",
    "    # dataloader_valid=dl_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learner.predict(dl_train)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().cpu()  # .numpy()\n",
    "preds[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images, target_noises, noise_levels = [], [], []\n",
    "\n",
    "for b in dl_train:\n",
    "    input_images.append(b.noisy_image)\n",
    "    target_noises.append(b.target_noise)\n",
    "    noise_levels.append(b.noise_level)\n",
    "\n",
    "input_images = torch.cat(input_images)\n",
    "target_noises = torch.cat(target_noises)\n",
    "noise_levels = torch.cat(noise_levels)\n",
    "input_images.shape, target_noises.shape, noise_levels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 1\n",
    "noisy_input_image = input_images[ix_img].cpu()\n",
    "pred_noise = preds[ix_img]\n",
    "target_noise = target_noises[ix_img].cpu()\n",
    "noise_level = noise_levels[ix_img].cpu()\n",
    "\n",
    "denoised_image = unet_with_noise.get_denoised_images(\n",
    "    noisy_input_image, target_noise, noise_level\n",
    ")\n",
    "pred_denoised_image = unet_with_noise.get_denoised_images(\n",
    "    noisy_input_image, pred_noise, noise_level\n",
    ")\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "\n",
    "unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "    noisy_input_image,\n",
    "    target_noise,\n",
    "    denoised_image,\n",
    "    title=f\"Target noise (noise level: {noise_levels[ix_img]:.4f})\",\n",
    ")\n",
    "unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "    noisy_input_image,\n",
    "    pred_noise,\n",
    "    pred_denoised_image,\n",
    "    title=f\"Predicted noise (noise level: {noise_levels[ix_img]:.4f})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting digit 5 - including the noise level as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing the noise embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.linspace(-10, 10, 100)\n",
    "emb = unet_with_noise.get_noise_level_embedding(noise, 8 * 4, max_period=1000)\n",
    "print(emb.T.shape)\n",
    "plt.imshow(emb.T)\n",
    "plt.xlabel(\"Noise level\")\n",
    "plt.ylabel(\"Embedding\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_with_noise.NoisyUNetModelTensordict(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    list_num_features=(\n",
    "        8,\n",
    "        16,\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2_000\n",
    "lr = 1e-1\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)  # , momentum=1e-3\n",
    "\n",
    "loss = unet_with_noise.MSELossMNISTNoisy()\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(\".*act.*\",),\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=100,\n",
    "    max_depth_search=4,\n",
    "    name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]\n",
    "\n",
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 10, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=200, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=lr,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learner.predict(dl_train)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().cpu()  # .numpy()\n",
    "preds[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images, target_noises, noise_levels = [], [], []\n",
    "\n",
    "for b in dl_train:\n",
    "    input_images.append(b.noisy_image)\n",
    "    target_noises.append(b.target_noise)\n",
    "    noise_levels.append(b.noise_level)\n",
    "\n",
    "input_images = torch.cat(input_images)\n",
    "target_noises = torch.cat(target_noises)\n",
    "noise_levels = torch.cat(noise_levels)\n",
    "input_images.shape, target_noises.shape, noise_levels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 1\n",
    "noisy_input_image = input_images[ix_img].cpu()\n",
    "pred_noise = preds[ix_img]\n",
    "target_noise = target_noises[ix_img].cpu()\n",
    "noise_level = noise_levels[ix_img].cpu()\n",
    "\n",
    "denoised_image = unet_with_noise.get_denoised_images(\n",
    "    noisy_input_image, target_noise, noise_level\n",
    ")\n",
    "pred_denoised_image = unet_with_noise.get_denoised_images(\n",
    "    noisy_input_image, pred_noise, noise_level\n",
    ")\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "\n",
    "unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "    noisy_input_image,\n",
    "    target_noise,\n",
    "    denoised_image,\n",
    "    title=f\"Target noise (noise level: {noise_levels[ix_img]:.4f})\",\n",
    ")\n",
    "unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "    noisy_input_image,\n",
    "    pred_noise,\n",
    "    pred_denoised_image,\n",
    "    title=f\"Predicted noise (noise level: {noise_levels[ix_img]:.4f})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noise levels based on\n",
    "```python\n",
    "def sigmas_karras(n, sigma_min=0.01, sigma_max=80., rho=7.):\n",
    "    ramp = torch.linspace(0, 1, n)\n",
    "    min_inv_rho = sigma_min**(1/rho)\n",
    "    max_inv_rho = sigma_max**(1/rho)\n",
    "    sigmas = (max_inv_rho + ramp * (min_inv_rho-max_inv_rho))**rho\n",
    "    return torch.cat([sigmas, tensor([0.])]).cuda()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_level(\n",
    "    n: int, max_noise_level: float = 15.0, d: float = 2.5\n",
    ") -> torch.Tensor:\n",
    "    return torch.tensor([max_noise_level / (d**i) for i in range(n)])\n",
    "\n",
    "\n",
    "max_noise_level = 2.0\n",
    "n_levels = 20\n",
    "rho = 7.0\n",
    "d = 3.0\n",
    "noise_levels = get_noise_level(n_levels, max_noise_level=max_noise_level, d=d)\n",
    "\n",
    "sns.scatterplot(x=range(len(noise_levels)), y=noise_levels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "generative_sig = torch.tensor([max_noise_level for _ in range(n_samples)])\n",
    "sampled_noise = unet_with_noise.draw_img_noise_given_noise_level(\n",
    "    generative_sig.reshape(-1, 1, 1),\n",
    "    images_shape=(generative_sig.shape[0], 28, 28),\n",
    ")\n",
    "_, _, c_in = unet_with_noise.get_cs(generative_sig.reshape(-1, 1, 1))\n",
    "sampled_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(7, 3), nrows=2)\n",
    "ax = axs[0]\n",
    "sns.histplot(x=sampled_noise.flatten(), ax=ax)\n",
    "ax.set(xlabel=\"unscaled Pixel value\", ylabel=\"Count\")\n",
    "ax = axs[1]\n",
    "sns.histplot(x=(sampled_noise * c_in).flatten(), ax=ax)\n",
    "ax.set(xlabel=\"scaled Pixel value\", ylabel=\"Count\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denoising based on \n",
    "```python\n",
    "def denoise(model, x, sig):\n",
    "    sig = sig[None]\n",
    "    c_skip,c_out,c_in = scalings(sig)\n",
    "    return model((x*c_in, sig))*c_out + x*c_skip\n",
    "    \n",
    "def sample_lms(model, steps=100, order=4, sigma_max=80.):\n",
    "    preds = []\n",
    "    x = torch.randn(sz).cuda()*sigma_max\n",
    "    sigs = sigmas_karras(steps, sigma_max=sigma_max)\n",
    "    ds = []\n",
    "    for i in progress_bar(range(len(sigs)-1)):\n",
    "        sig = sigs[i]\n",
    "        denoised = denoise(model, x, sig)\n",
    "        d = (x-denoised)/sig\n",
    "        ds.append(d)\n",
    "        if len(ds) > order: ds.pop(0)\n",
    "        cur_order = min(i+1, order)\n",
    "        coeffs = [linear_multistep_coeff(cur_order, sigs, i, j) for j in range(cur_order)]\n",
    "        x = x + sum(coeff*d for coeff, d in zip(coeffs, reversed(ds)))\n",
    "        preds.append(x)\n",
    "    return preds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_preds, denoised_preds = unet_with_noise.denoise_with_model(\n",
    "    learner, sampled_noise.float(), noise_levels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noise_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_denoise = 19\n",
    "\n",
    "for ix_img in range(n_samples):\n",
    "    if ix_denoise == 0:\n",
    "        noisy_input_image = sampled_noise[ix_img].cpu() * c_in[0]\n",
    "    else:\n",
    "        noisy_input_image = denoised_preds[ix_denoise - 1][ix_img].cpu()\n",
    "    predicted_noise = noise_preds[ix_denoise][ix_img].cpu()\n",
    "    denoised_image = denoised_preds[ix_denoise][ix_img].cpu()\n",
    "\n",
    "    noise_level = noise_levels[ix_denoise].cpu()\n",
    "    unet_with_noise.compare_input_noise_and_denoised_image(\n",
    "        noisy_input_image,\n",
    "        predicted_noise,\n",
    "        denoised_image,\n",
    "        title=f\"{ix_img=}: Predicted noise (noise level: {noise_level:.4f} (sigma_max: {max_noise_level:.4f}))\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement ResBlocks with attention as in https://github.com/fastai/course22p2/blob/master/nbs/28_diffusion-attn-cond.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
