{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Autoencoder on mnist\n",
    "\n",
    "The digits can be reconstructed to a pretty decent degree, with the same weird effect of overfitting a single image. The training seems to have phases where the model parameters / loss plateau before improving. Also the reconstructed images are a little bit blurry, but subjectively not as much as in the [fashion mnist example used in the lectures](https://github.com/fastai/course22p2/blob/master/nbs/08_autoencoder.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* fastai 2022 / 2023 course part II:\n",
    "    * [notebook 8](https://github.com/fastai/course22p2/blob/master/nbs/08_autoencoder.ipynb)\n",
    "    * [lesson 15](https://course.fast.ai/Lessons/lesson15.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import random_neural_net_models.autoencoder_fastai2022 as ae\n",
    "import random_neural_net_models.convolution_lecun1990 as conv_lecun1990\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.losses as rnnm_losses\n",
    "import random_neural_net_models.telemetry as telemetry\n",
    "import random_neural_net_models.utils as utils\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_OVERFITTING_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a few images to overfit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "X0, y0 = X.iloc[:n], y.iloc[:n]\n",
    "X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conv_lecun1990.DigitsDataset(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds[0]\n",
    "plt.imshow(item[0], cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {item[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.CNNAutoEncoder()\n",
    "model = telemetry.ModelTelemetry(\n",
    "    model,\n",
    "    loss_names=(\"total\",),\n",
    "    activations_name_patterns=(\".*act.*\",),\n",
    "    gradients_name_patterns=(\".*conv\\d$\",),\n",
    "    parameters_name_patterns=(\".*conv\\d$\",),\n",
    ")\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1_000\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, _) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb)\n",
    "\n",
    "        loss = loss_func(x_pred, xb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_gradient_stats(yscale=\"log\", figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_activation_stats(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawing histograms of the weights and biases across training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_parameter_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_loss_history_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference over samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.to(device)\n",
    "preds = model(train_features)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.detach().cpu().numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_features[0].cpu()\n",
    "img_pred = x_pred[0]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax = axs[0]\n",
    "ax.imshow(img, cmap=\"gray\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img_pred, cmap=\"gray\")\n",
    "ax.set_title(\"Reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clean_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting with `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.MNISTDatasetWithLabels(X0, y0)\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=1,\n",
    "    collate_fn=rnnm_data.collate_mnist_dataset_to_block_with_labels,\n",
    "    shuffle=True,\n",
    ")\n",
    "next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.CNNAutoEncoder2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1_000\n",
    "lr = 1e-2\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss = rnnm_losses.MSELossMNISTAutoencoder()\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*act.*\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*conv\\d$\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*conv\\d$\",)\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]\n",
    "\n",
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 10, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=200, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=lr,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = learner.predict(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(dl_train)).image[0]\n",
    "img_pred = x_pred[0]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax = axs[0]\n",
    "ax.imshow(img, cmap=\"gray\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img_pred, cmap=\"gray\")\n",
    "ax.set_title(\"Reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFITTING_ONLY:\n",
    "    raise SystemExit(\"Skipping training beyond overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing 10 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pair(img: torch.Tensor, img_pred: torch.Tensor):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    ax = axs[0]\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(\"Input image\")\n",
    "    ax.axis(\"off\")\n",
    "    ax = axs[1]\n",
    "    ax.imshow(img_pred, cmap=\"gray\")\n",
    "    ax.set_title(\"Reconstructed image\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_n_pairs(\n",
    "    input_features: torch.Tensor, x_pred: torch.Tensor, n: int = 5\n",
    "):\n",
    "    _n = min(n, len(input_features))\n",
    "    print(f\"Drawing {_n} pairs\")\n",
    "    for i in range(_n):\n",
    "        img = input_features[i].cpu()\n",
    "        img_pred = x_pred[i]\n",
    "        draw_pair(img, img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X2, y0, y2 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X0, X1, y0, y1 = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conv_lecun1990.DigitsDataset(X0, y0)\n",
    "ds_valid = conv_lecun1990.DigitsDataset(X1, y1)\n",
    "ds_test = conv_lecun1990.DigitsDataset(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(ds_valid, batch_size=500, shuffle=False)\n",
    "dataloader_test = DataLoader(ds_test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.CNNAutoEncoder()\n",
    "model = telemetry.ModelTelemetry(\n",
    "    model,\n",
    "    loss_names=(\"total\",),\n",
    "    gradients_every_n=100,\n",
    "    activations_every_n=100,\n",
    "    parameters_every_n=100,\n",
    "    activations_name_patterns=(\".*act.*\",),\n",
    "    gradients_name_patterns=(\".*conv\\d\",),\n",
    "    parameters_name_patterns=(\".*conv\\d\",),\n",
    ")\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, _) in tqdm.tqdm(\n",
    "        enumerate(dataloader), desc=\"Batches\", total=len(dataloader)\n",
    "    ):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb)\n",
    "\n",
    "        loss = loss_func(x_pred, xb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "    # compute validation loss\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        xs_pred, xs_true = [], []\n",
    "        for xb, _ in dataloader_test:\n",
    "            xb = xb.to(device)\n",
    "\n",
    "            x_pred = model(xb)\n",
    "            xs_pred.append(x_pred)\n",
    "            xs_true.append(xb)\n",
    "\n",
    "        x_pred = torch.cat(xs_pred, dim=0)\n",
    "        x_true = torch.cat(xs_true, dim=0)\n",
    "        loss_test = loss_func(x_pred, x_true)\n",
    "        model.loss_history_test(loss_test, _iter)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_gradient_stats(yscale=\"log\", figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_activation_stats(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawing histograms of the weights and biases across training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_parameter_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_loss_history_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_loss_history_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, _ = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.to(device)\n",
    "preds = model(test_features)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.detach().cpu().numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_n_pairs(test_features, x_pred, n=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clean_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now with `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.MNISTDatasetWithLabels(X0, y0)\n",
    "ds_valid = rnnm_data.MNISTDatasetWithLabels(X1, y1)\n",
    "ds_test = rnnm_data.MNISTDatasetWithLabels(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=256,\n",
    "    collate_fn=rnnm_data.collate_mnist_dataset_to_block_with_labels,\n",
    "    shuffle=True,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=500,\n",
    "    collate_fn=rnnm_data.collate_mnist_dataset_to_block_with_labels,\n",
    "    shuffle=False,\n",
    ")\n",
    "dl_test = DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=500,\n",
    "    collate_fn=rnnm_data.collate_mnist_dataset_to_block_with_labels,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.CNNAutoEncoder2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss = rnnm_losses.MSELossMNISTAutoencoder()\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*act.*\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*conv\\d$\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=100, max_depth_search=4, name_patterns=(\".*conv\\d$\",)\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]\n",
    "\n",
    "\n",
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 10, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=2, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=lr,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = learner.predict(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = next(iter(dl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_n_pairs(test_features.image, x_pred, n=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
