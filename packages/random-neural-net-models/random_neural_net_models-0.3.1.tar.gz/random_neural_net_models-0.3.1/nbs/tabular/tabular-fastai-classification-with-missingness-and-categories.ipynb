{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the fastai tabular classification model to handle missing and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as sk_data\n",
    "import sklearn.model_selection as sk_selection\n",
    "import sklearn.metrics as sk_metrics\n",
    "import random_neural_net_models.tabular as rnnm_tab\n",
    "import torch.optim as optim\n",
    "import random_neural_net_models.losses as rnnm_loss\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.utils as rnnm_utils\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnm_utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = rnnm_utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1_000\n",
    "n_features = 3\n",
    "n_classes = 2\n",
    "X, y = sk_data.make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    random_state=42,\n",
    "    centers=n_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intentionally leaking the target class, if embedding is used properly model should pick up on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_cat = y.reshape((-1, 1))\n",
    "X_cat.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:3], y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise = np.random.normal(size=X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_num, X1_num, X0_cat, X1_cat, y0, y1 = sk_selection.train_test_split(\n",
    "    X_noise, X_cat, y, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.NumpyNumCatTrainingDataset(X0_num, X0_cat, y0)\n",
    "ds_valid = rnnm_data.NumpyNumCatTrainingDataset(X1_num, X1_cat, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_numcat_dataset_to_xyblock_keep_orig_y,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_numcat_dataset_to_xyblock_keep_orig_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train)).x_categorical[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModel - categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinalities = np.linspace(1, 100)\n",
    "emb_dims = np.array(\n",
    "    [\n",
    "        rnnm_tab.calc_categorical_feature_embedding_dimension(o)\n",
    "        for o in ordinalities\n",
    "    ]\n",
    ")\n",
    "\n",
    "ax = sns.lineplot(x=ordinalities, y=emb_dims)\n",
    "ax.set(xlabel=\"ordinality\", ylabel=\"embedding dimensionality\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_num = [0,1,2]\n",
    "# cols_cat = [3]\n",
    "n_categories_per_column = rnnm_data.calc_n_categories_per_column(X0_cat)\n",
    "n_categories_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_impute = False\n",
    "impute_bias_source = rnnm_tab.BiasSources.zero\n",
    "n_features_in = n_features + 1  # +1 because of the added leakage feature\n",
    "\n",
    "model = rnnm_tab.TabularModelNumericalAndCategorical(\n",
    "    [n_features_in, 4, 4, n_classes],\n",
    "    n_categories_per_column=n_categories_per_column,\n",
    "    use_batch_norm=False,\n",
    "    do_impute=do_impute,\n",
    "    impute_bias_source=impute_bias_source,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModelClassification - categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = [4, 4]\n",
    "do_impute = False\n",
    "impute_bias_source = rnnm_tab.BiasSources.zero\n",
    "\n",
    "model = rnnm_tab.TabularModelClassification(\n",
    "    n_features=n_features_in,\n",
    "    n_hidden=n_hidden,\n",
    "    n_classes=n_classes,\n",
    "    use_batch_norm=False,\n",
    "    do_impute=do_impute,\n",
    "    impute_bias_source=impute_bias_source,\n",
    "    n_categories_per_column=n_categories_per_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(\n",
    "    yscale=\"log\",\n",
    "    ylim=(\n",
    "        0.1,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModel - categorical + missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missingness_num = (1,)\n",
    "X_noise_miss, _ = rnnm_tab.make_missing_numerical(\n",
    "    X_noise, p_missing=0.1, cols_with_missing=cols_with_missingness_num\n",
    ")\n",
    "X_noise_miss[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missingness_cat = (0,)\n",
    "X_cat_miss, _ = rnnm_tab.make_missing_categorical(\n",
    "    X_cat, p_missing=0.1, cols_with_missing=cols_with_missingness_cat\n",
    ")\n",
    "X_cat_miss[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_num_miss, X1_num_miss, X0_cat_miss, X1_cat_miss, y0_miss, y1_miss = (\n",
    "    sk_selection.train_test_split(X_noise_miss, X_cat_miss, y, test_size=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_miss = rnnm_data.NumpyNumCatTrainingDataset(\n",
    "    X0_num_miss, X0_cat_miss, y0_miss\n",
    ")\n",
    "ds_valid_miss = rnnm_data.NumpyNumCatTrainingDataset(\n",
    "    X1_num_miss, X1_cat_miss, y1_miss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_miss[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "dl_train_miss = DataLoader(\n",
    "    ds_train_miss,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_numcat_dataset_to_xyblock_keep_orig_y,\n",
    ")\n",
    "dl_valid_miss = DataLoader(\n",
    "    ds_valid_miss,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_numcat_dataset_to_xyblock_keep_orig_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train_miss)).x_categorical[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories_per_column = rnnm_data.calc_n_categories_per_column(X0_cat_miss)\n",
    "n_categories_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_impute = True\n",
    "impute_bias_source = rnnm_tab.BiasSources.zero\n",
    "n_features_in = n_features + 1  # +1 because of the added leakage feature\n",
    "\n",
    "model = rnnm_tab.TabularModelNumericalAndCategorical(\n",
    "    [n_features_in, 4, 4, n_classes],\n",
    "    n_categories_per_column=n_categories_per_column,\n",
    "    use_batch_norm=False,\n",
    "    do_impute=do_impute,\n",
    "    impute_bias_source=impute_bias_source,\n",
    "    cols_with_missing_num=cols_with_missingness_num,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train_miss, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\", ylim=(0.2, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train_miss),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train_miss, n_epochs=n_epochs, dataloader_valid=dl_valid_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid_miss).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1_miss, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModelClassification - categorical + missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = [4, 4]\n",
    "do_impute = True\n",
    "impute_bias_source = rnnm_tab.BiasSources.zero\n",
    "\n",
    "model = rnnm_tab.TabularModelClassification(\n",
    "    n_features=n_features_in,\n",
    "    n_hidden=n_hidden,\n",
    "    n_classes=n_classes,\n",
    "    use_batch_norm=False,\n",
    "    do_impute=do_impute,\n",
    "    impute_bias_source=impute_bias_source,\n",
    "    n_categories_per_column=n_categories_per_column,\n",
    "    cols_with_missing=cols_with_missingness_num,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train_miss, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(\n",
    "    yscale=\"log\",\n",
    "    ylim=(\n",
    "        0.1,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train_miss),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train_miss, n_epochs=n_epochs, dataloader_valid=dl_valid_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid_miss).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1_miss, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
