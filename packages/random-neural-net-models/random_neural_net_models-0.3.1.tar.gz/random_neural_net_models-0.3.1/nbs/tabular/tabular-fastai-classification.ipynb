{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the fastai tabular classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as sk_data\n",
    "import sklearn.model_selection as sk_selection\n",
    "import sklearn.metrics as sk_metrics\n",
    "import random_neural_net_models.tabular as rnnm_tab\n",
    "import torch.optim as optim\n",
    "import random_neural_net_models.losses as rnnm_loss\n",
    "import random_neural_net_models.learner as rnnm_learner\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.utils as rnnm_utils\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnm_utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = rnnm_utils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1_000\n",
    "n_features = 3\n",
    "n_classes = 2\n",
    "X, y = sk_data.make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    random_state=42,\n",
    "    centers=n_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:3], y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1, y0, y1 = sk_selection.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = rnnm_data.NumpyTrainingDataset(X0, y0)\n",
    "ds_valid = rnnm_data.NumpyTrainingDataset(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_dataset_to_xyblock_keep_orig_y,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=rnnm_data.collate_numpy_dataset_to_xyblock_keep_orig_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/fastai/blob/master/fastai/layers.py#L175\n",
    "\n",
    "```python\n",
    "class LinBnDrop(nn.Sequential):\n",
    "    \"Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers\"\n",
    "    def __init__(self, n_in, n_out, bn=True, p=0., act=None, lin_first=False):\n",
    "        layers = [BatchNorm(n_out if lin_first else n_in, ndim=1)] if bn else []\n",
    "        if p != 0: layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_in, n_out, bias=not bn)]\n",
    "        if act is not None: lin.append(act)\n",
    "        layers = lin+layers if lin_first else layers+lin\n",
    "        super().__init__(*layers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/fastai/blob/master/fastai/tabular/model.py#L35:\n",
    "\n",
    "```python\n",
    "class TabularModel(Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, \n",
    "        emb_szs:list, # Sequence of (num_embeddings, embedding_dim) for each categorical variable\n",
    "        n_cont:int, # Number of continuous variables\n",
    "        out_sz:int, # Number of outputs for final `LinBnDrop` layer\n",
    "        layers:list, # Sequence of ints used to specify the input and output size of each `LinBnDrop` layer\n",
    "        ps:float|MutableSequence=None, # Sequence of dropout probabilities for `LinBnDrop`\n",
    "        embed_p:float=0., # Dropout probability for `Embedding` layer\n",
    "        y_range=None, # Low and high for `SigmoidRange` activation \n",
    "        use_bn:bool=True, # Use `BatchNorm1d` in `LinBnDrop` layers\n",
    "        bn_final:bool=False, # Use `BatchNorm1d` on final layer\n",
    "        bn_cont:bool=True, # Use `BatchNorm1d` on continuous variables\n",
    "        act_cls=nn.ReLU(inplace=True), # Activation type for `LinBnDrop` layers\n",
    "        lin_first:bool=True # Linear layer is first or last in `LinBnDrop` layers\n",
    "    ):\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        if not is_listy(ps): ps = [ps]*len(layers)\n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(embed_p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont = n_emb,n_cont\n",
    "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
    "        actns = [act_cls for _ in range(len(sizes)-2)] + [None]\n",
    "        _layers = [LinBnDrop(sizes[i], sizes[i+1], bn=use_bn and (i!=len(actns)-1 or bn_final), p=p, act=a, lin_first=lin_first)\n",
    "                       for i,(p,a) in enumerate(zip(ps+[0.],actns))]\n",
    "        if y_range is not None: _layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*_layers)\n",
    "\n",
    "    def forward(self, x_cat, x_cont=None):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            if self.bn_cont is not None: x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        return self.layers(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnnm_tab.TabularModel(\n",
    "    [n_features, 200, 100, n_classes], use_batch_norm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularModelClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = [200, 100]\n",
    "model = rnnm_tab.TabularModelClassification(\n",
    "    n_features=n_features,\n",
    "    n_hidden=n_hidden,\n",
    "    n_classes=n_classes,\n",
    "    use_batch_norm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = rnnm_loss.CrossEntropyXy()\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "\n",
    "save_dir = Path(\"./models\")\n",
    "\n",
    "callbacks = [loss_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = rnnm_learner.Learner(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    callbacks=callbacks,\n",
    "    save_dir=save_dir,\n",
    "    device=device,\n",
    "    show_epoch_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "learner.find_learning_rate(\n",
    "    dl_train, n_epochs=10, lr_find_callback=lr_find_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback.plot(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(dl_train),\n",
    ")\n",
    "scheduler_callback = rnnm_learner.EveryBatchSchedulerCallback(scheduler)\n",
    "learner.update_callback(scheduler_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl_train, n_epochs=n_epochs, dataloader_valid=dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.predict(dl_valid).detach().softmax(dim=1).numpy()[:, 1]\n",
    "probs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.roc_auc_score(y1, probs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
