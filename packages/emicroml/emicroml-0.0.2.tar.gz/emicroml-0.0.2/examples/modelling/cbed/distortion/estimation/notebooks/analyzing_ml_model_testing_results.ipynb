{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb7f461",
   "metadata": {},
   "source": [
    "# Analyzing machine learning model testing results #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d9cd7",
   "metadata": {},
   "source": [
    "## A NOTE BEFORE STARTING ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880421e9",
   "metadata": {},
   "source": [
    "Since the ``emicroml`` git repository tracks this notebook under its original\n",
    "basename ``analyzing_ml_model_testing_results.ipynb``, we recommend that you\n",
    "copy the original notebook and rename it to any other basename that is not one\n",
    "of the original basenames that appear in the ``<root>/examples`` directory\n",
    "before executing any of the notebook cells below, where ``<root>`` is the root\n",
    "of the ``emicroml`` repository. For example, you could rename it\n",
    "``analyzing_ml_model_testing_results_sandbox.ipynb``. This way you can explore\n",
    "the notebook by executing and modifying cells without changing the original\n",
    "notebook, which is being tracked by git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0d90e",
   "metadata": {},
   "source": [
    "## Import necessary modules ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For general array handling.\n",
    "import numpy as np\n",
    "\n",
    "# For loading CBED patterns.\n",
    "import prismatique.load\n",
    "\n",
    "# For cropping HyperSpy signals.\n",
    "import empix\n",
    "\n",
    "# For loading objects from HDF5 files.\n",
    "import h5pywrappers\n",
    "\n",
    "# For creating and plotting figures.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "\n",
    "\n",
    "\n",
    "# For loading ML datasets for testing distortion estimation in CBED.\n",
    "import emicroml.modelling.cbed.distortion.estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d0485-cf65-478b-80c4-d5d294879c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667d633",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2509",
   "metadata": {},
   "source": [
    "In this notebook, we analyze the output that results from performing the\n",
    "\"actions\" described in the following pages:\n",
    "\n",
    "1. [Generating simulated CBED patterns of a sample of $\\ce{MoS2}$ on amorphous C](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/simulations/MoS2_on_amorphous_C/generate_cbed_pattern_sets.html)\n",
    "2. [Generating machine learning datasets for the machine learning model test set #1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/generate_ml_datasets_for_ml_model_test_set_1.html)\n",
    "3. [Combining machine learning datasets for the machine learning model test set #1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/combine_ml_datasets_for_ml_model_test_set_1.html)\n",
    "4. [Running the machine learning model test set #1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/run_ml_model_test_set_1.html)\n",
    "5. [Running the RGM test set #1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/run_rgm_test_set_1.html)\n",
    "\n",
    "In short, in this notebook we analyze the performance results of the \"first\" set\n",
    "of machine learning (ML) model tests for the ML task of estimating distortion in\n",
    "convergent beam electron diffraction (CBED). These performance results are\n",
    "benchmarked against those obtained by the radial gradient maximization (RGM)\n",
    "approach to estimating distortion.\n",
    "\n",
    "In order to execute the cells in this notebook as intended, a set of Python\n",
    "libraries need to be installed in the Python environment within which the cells\n",
    "of the notebook are to be executed. See [this\n",
    "page](https://mrfitzpa.github.io/emicroml/examples/prerequisites_for_execution_without_slurm.html)\n",
    "for instructions on how to do so. Additionally, a subset of the output that\n",
    "results from performing the aforementioned actions is required to execute the\n",
    "cells in this notebook as intended. One can obtain this subset of output by\n",
    "executing said actions, however this requires significant computational\n",
    "resources, including significant walltime. Alternatively, one can copy this\n",
    "subset of output from a Federated Research Data Repository dataset by following\n",
    "the instructions given on [this\n",
    "page](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/copying_subset_of_output_from_frdr_dataset.html).\n",
    "\n",
    "You can find the documentation for the ``emicroml`` library\n",
    "[here](https://mrfitzpa.github.io/emicroml/_autosummary/emicroml.html).\n",
    "It is recommended that you consult the documentation of this\n",
    "library as you explore the notebook. Moreover, users should\n",
    "execute the cells in the order that they appear, i.e. from top to\n",
    "bottom, as some cells reference variables that are set in other\n",
    "cells above them. **Users should make sure to navigate the\n",
    "documentation for the version of ``emicroml`` that they are\n",
    "currently using.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9445a5e-76d1-4957-8399-c8638ab57d0c",
   "metadata": {},
   "source": [
    "## Loading and analyzing the ML testing datasets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199654f0-fbb4-4ce9-9ec2-062cd4c7348c",
   "metadata": {},
   "source": [
    "Upon successful completion of the action described in the page [Combining\n",
    "machine learning datasets for the machine learning model test set\n",
    "#1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/combine_ml_datasets_for_ml_model_test_set_1.html),\n",
    "for every string `<disk_size>` in the sequence `(small, medium, large)`, a ML\n",
    "testing dataset is stored in the HDF5 file at the file path\n",
    "`../data/ml_datasets/ml_datasets_for_ml_model_test_set_1/ml_datasets_with_cbed_patterns_of_MoS2_on_amorphous_C/ml_dataset_with_<disk_size>_sized_disks.h5`,\n",
    "where the ML dataset contains 2880 ML data instances, with each ML dataset\n",
    "instance storing a $512 \\times 512$ \"fake\" CBED pattern obtained by randomly\n",
    "distorting the same undistorted CBED pattern with `<disk_size>`-sized CBED\n",
    "disks. For every string `<disk_size>` in the sequence `(small, medium, large)`,\n",
    "the undistorted CBED pattern with `<disk_size>`-sized CBED disks is the final\n",
    "CBED pattern of a CBED experiment simulated via the multislice technique, where\n",
    "the sample is a 5-layer thin film with a thick layer of amorphous carbon (C). By\n",
    "small-, medium-, and large-sized CBED disks, we mean CBED disks with radii equal\n",
    "roughly to $1/35$, $(1/35+1/10)/2$, and $1/10$ in units of the image width,\n",
    "respectively.\n",
    "\n",
    "Let's start by visualizing the three undistorted CBED patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ce174-3d47-433e-8726-76709c896b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_dir = \"../../../simulations/MoS2_on_amorphous_C/data\"\n",
    "disk_sizes = (\"small\", \"medium\", \"large\")\n",
    "\n",
    "\n",
    "\n",
    "for disk_size in disk_sizes:\n",
    "    filename = (path_to_data_dir\n",
    "                + \"/cbed_pattern_generator_output/patterns_with_{}_sized_disks\"\n",
    "                + \"/stem_sim_intensity_output.h5\").format(disk_size)\n",
    "\n",
    "    kwargs = \\\n",
    "        {\"filename\": filename, \"multi_dim_slice\": (0, 0)}\n",
    "    cbed_intensity_pattern_signal, _ = \\\n",
    "        prismatique.load.cbed_intensity_patterns(**kwargs)\n",
    "\n",
    "    cropping_window_dims = \\\n",
    "        (cbed_intensity_pattern_signal.axes_manager[\"$k_x$\"].size//2,\n",
    "         cbed_intensity_pattern_signal.axes_manager[\"$k_y$\"].size//2)\n",
    "\n",
    "    kwargs = {\"window_dims\": cropping_window_dims}\n",
    "    optional_cropping_params = empix.OptionalCroppingParams(**kwargs)\n",
    "    \n",
    "    kwargs = {\"input_signal\": cbed_intensity_pattern_signal,\n",
    "              \"optional_params\": optional_cropping_params}\n",
    "    cropped_cbed_intensity_pattern_signal = empix.crop(**kwargs)\n",
    "\n",
    "    signal_title = \"CBED pattern with {}-sized disks\".format(disk_size)\n",
    "\n",
    "    kwargs = {\"axes_off\": True, \n",
    "              \"scalebar\": False, \n",
    "              \"colorbar\": False, \n",
    "              \"gamma\": 0.2,\n",
    "              \"cmap\": \"plasma\", \n",
    "              \"title\": signal_title}\n",
    "    cropped_cbed_intensity_pattern_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf3c3d-f466-418a-aa3b-38a28e8c211d",
   "metadata": {},
   "source": [
    "Let's now visualize a single distorted CBED pattern from the ML testing dataset\n",
    "of CBED patterns with medium-sized disks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa4e00-457c-46a7-b0b2-4e202a2a1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_size = \"medium\"\n",
    "\n",
    "path_to_data_dir = \"../data\"\n",
    "\n",
    "path_to_ml_dataset = (path_to_data_dir\n",
    "                      + \"/ml_datasets\"\n",
    "                      + \"/ml_datasets_for_ml_model_test_set_1\"\n",
    "                      + \"/ml_datasets_with_cbed_patterns_of_MoS2_on_amorphous_C\"\n",
    "                      + \"/ml_dataset_with_{}_sized_disks.h5\").format(disk_size)\n",
    "\n",
    "\n",
    "\n",
    "module_alias = emicroml.modelling.cbed.distortion.estimation\n",
    "kwargs = {\"path_to_ml_dataset\": path_to_ml_dataset, \n",
    "          \"entire_ml_dataset_is_to_be_cached\": False, \n",
    "          \"ml_data_values_are_to_be_checked\": False}\n",
    "ml_dataset = module_alias.MLDataset(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "cbed_pattern_idx = 1\n",
    "sampling_grid_dims_in_pixels = cropping_window_dims\n",
    "\n",
    "kwargs = \\\n",
    "    {\"single_dim_slice\": slice(cbed_pattern_idx, cbed_pattern_idx+1), \n",
    "     \"sampling_grid_dims_in_pixels\": sampling_grid_dims_in_pixels}\n",
    "ml_data_instances_as_signals = \\\n",
    "    ml_dataset.get_ml_data_instances_as_signals(**kwargs)\n",
    "\n",
    "ml_data_instances_as_signal = ml_data_instances_as_signals[0]\n",
    "\n",
    "kwargs = {\"axes_off\": True, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 0.2,\n",
    "          \"cmap\": \"plasma\", \n",
    "          \"title\": \"\"}\n",
    "ml_data_instances_as_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401a0aa-2700-4be5-8280-b22873a34009",
   "metadata": {},
   "source": [
    "Note how we've added random illumination support shapes to some of the distorted\n",
    "CBED patterns in each ML testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602148b6-6317-4b5a-962b-37941cac76ad",
   "metadata": {},
   "source": [
    "## Loading and analyzing the ML model testing summary output data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ded79-6ab2-4fb9-b81e-b36620bb6010",
   "metadata": {},
   "source": [
    "Upon successful completion of the action described in the page [Training machine\n",
    "learning\n",
    "models](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/train_ml_model_set.html),\n",
    "10 ML models are trained, and a dictionary representation of each ML model is\n",
    "saved to a file. Here we assume that said ML models have been trained\n",
    "already. Furthermore, upon successful completion of the action described in the\n",
    "page [Running the machine learning model test set\n",
    "#1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/run_ml_model_test_set_1.html),\n",
    "for every string `<disk_size>` in the sequence `(small, medium, large)`, for\n",
    "every nonnegative integer `<k>` less than 10, the `<k>` th trained ML model will\n",
    "have been tested against the ML testing dataset stored in the HDF5 file at the\n",
    "file path\n",
    "`../data/ml_datasets/ml_datasets_for_ml_model_test_set_1/ml_datasets_with_cbed_patterns_of_MoS2_on_amorphous_C/ml_dataset_with_<disk_size>_sized_disks.h5`,\n",
    "with the ML model testing having been performed using the class\n",
    "emicroml.modelling.cbed.distortion.estimation.MLModelTester, and the ML model\n",
    "testing summary output data file having been saved to the HDF5 file at the file\n",
    "path\n",
    "`../data/ml_models/ml_model_<k>/ml_model_test_set_1_results/results_for_cbed_patterns_of_MoS2_on_amorphous_C_with_<disk_size>_sized_disks/ml_model_testing_summary_output_data.h5`.\n",
    "ML model testing summary output data files are described in detail in the\n",
    "documentation for the method\n",
    "[emicroml.modelling.cbed.distortion.estimation.MLModelTester.test_ml_model](https://mrfitzpa.github.io/emicroml/_autosummary/emicroml.modelling.cbed.distortion.estimation.MLModelTester.html#emicroml.modelling.cbed.distortion.estimation.MLModelTester.test_ml_model).\n",
    "\n",
    "Upon successful completion of the action described in the page [Running the RGM\n",
    "test set\n",
    "#1](https://mrfitzpa.github.io/emicroml/examples/modelling/cbed/distortion/estimation/run_rgm_test_set_1.html),\n",
    "for every string `<disk_size>` in the sequence `(small, medium, large)`, the RGM\n",
    "approach to distortion estimation will have been tested against the ML testing\n",
    "dataset stored in the HDF5 file at the file path\n",
    "`../data/ml_datasets/ml_datasets_for_ml_model_test_set_1/ml_datasets_with_cbed_patterns_of_MoS2_on_amorphous_C/ml_dataset_with_<disk_size>_sized_disks.h5`,\n",
    "with the testing summary output data file having been saved to the HDF5 file at\n",
    "the file path\n",
    "`../data/ml_models/ml_model_0/ml_model_test_set_1_results/results_for_cbed_patterns_of_MoS2_on_amorphous_C_with_<disk_size>_sized_disks/rgm_testing_summary_output_data.h5`.\n",
    "\n",
    "For all testing summary output data files, the end-point error (EPE) of the\n",
    "predicted \"adjusted\" standard distortion field is tracked as a performance\n",
    "metric. For each ML testing dataset, let's compare the ML approach to the RGM\n",
    "approach, by plotting the cumulative distribution function (CDF) of the\n",
    "aforementioned performance metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad266f6-7976-4fbc-b1bb-49511bbec445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disk_size_idx, disk_size in enumerate(disk_sizes):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    \n",
    "\n",
    "    path_to_ml_model_testing_summary_output_data = \\\n",
    "        (path_to_data_dir\n",
    "         + \"/ml_models\"\n",
    "         + \"/ml_model_1/ml_model_test_set_1_results\"\n",
    "         + \"/results_for_cbed_patterns_of_MoS2_on_amorphous_C\"\n",
    "         + \"_with_{}_sized_disks\"\n",
    "         + \"/ml_model_testing_summary_output_data.h5\").format(disk_size)\n",
    "    path_to_rgm_testing_summary_output_data = \\\n",
    "        (path_to_data_dir\n",
    "         + \"/rgm_test_set_1_results\"\n",
    "         + \"/results_for_cbed_patterns_of_MoS2_on_amorphous_C\"\n",
    "         + \"_with_{}_sized_disks\"\n",
    "         + \"/rgm_testing_summary_output_data.h5\").format(disk_size)\n",
    "\n",
    "    \n",
    "\n",
    "    filename_to_legend_label_map = \\\n",
    "        {path_to_ml_model_testing_summary_output_data: \"ML approach\",\n",
    "         path_to_rgm_testing_summary_output_data: \"RGM approach\"}\n",
    "    filename_to_color_map = \\\n",
    "        {path_to_ml_model_testing_summary_output_data: \"red\",\n",
    "         path_to_rgm_testing_summary_output_data: \"blue\"}\n",
    "\n",
    "    if disk_size_idx != 0:\n",
    "        filenames = (path_to_ml_model_testing_summary_output_data,\n",
    "                     path_to_rgm_testing_summary_output_data)\n",
    "    else:\n",
    "        filenames = (path_to_rgm_testing_summary_output_data, \n",
    "                     path_to_ml_model_testing_summary_output_data)\n",
    "\n",
    "    \n",
    "\n",
    "    for filename in filenames:\n",
    "        hdf5_dataset_path = (\"/ml_data_instance_metrics/testing\"\n",
    "                             \"/epes_of_adjusted_distortion_fields\")\n",
    "\n",
    "        kwargs = {\"filename\": filename, \"path_in_file\": hdf5_dataset_path}\n",
    "        hdf5_dataset_id = h5pywrappers.obj.ID(**kwargs)\n",
    "\n",
    "        kwargs = {\"dataset_id\": hdf5_dataset_id,\n",
    "                  \"multi_dim_slice\": (slice(None),)}\n",
    "        hdf5_datasubset_id = h5pywrappers.datasubset.ID(**kwargs)\n",
    "\n",
    "        kwargs = {\"datasubset_id\": hdf5_datasubset_id}\n",
    "        x = h5pywrappers.datasubset.load(**kwargs)  \n",
    "\n",
    "        x_max_to_plot = 0.04\n",
    "\n",
    "        kwargs = {\"x\": x,\n",
    "                  \"bins\": np.linspace(0, x_max_to_plot, 100), \n",
    "                  \"histtype\": \"bar\", \n",
    "                  \"ec\": \"black\", \n",
    "                  \"cumulative\": True, \n",
    "                  \"density\": True, \n",
    "                  \"log\": False,\n",
    "                  \"alpha\": 1, \n",
    "                  \"color\": filename_to_color_map[filename],\n",
    "                  \"label\": filename_to_legend_label_map[filename]}\n",
    "        ax.hist(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    legend_label_font_size = 15\n",
    "    ax.legend(loc=\"lower right\", \n",
    "              fontsize=legend_label_font_size)\n",
    "\n",
    "    axis_label_font_size = legend_label_font_size\n",
    "    ax.set_xlabel(\"EPE of adjusted distortion field (image width)\", \n",
    "                  fontsize=axis_label_font_size)\n",
    "    ax.set_ylabel(\"portion of images\", \n",
    "                  fontsize=axis_label_font_size)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1))\n",
    "\n",
    "    for spatial_dim in (\"x\", \"y\"):\n",
    "        major_tick_width = 1.5\n",
    "        major_tick_length = 8\n",
    "        minor_tick_width = major_tick_width\n",
    "        minor_tick_length = major_tick_length//2\n",
    "        tick_label_size = 15\n",
    "        linewidth = major_tick_width\n",
    "    \n",
    "        kwargs = {\"axis\": spatial_dim,\n",
    "                  \"which\": \"major\",\n",
    "                  \"direction\": \"in\",\n",
    "                  \"left\": True,\n",
    "                  \"right\": True, \n",
    "                  \"width\": major_tick_width, \n",
    "                  \"length\": major_tick_length, \n",
    "                  \"labelsize\": tick_label_size}\n",
    "        ax.tick_params(**kwargs)\n",
    "\n",
    "        kwargs[\"which\"] = \"minor\"\n",
    "        kwargs[\"width\"] = minor_tick_width\n",
    "        kwargs[\"length\"] = minor_tick_length\n",
    "        ax.tick_params(**kwargs)\n",
    "\n",
    "        for side in ['top','bottom','left','right']:\n",
    "            ax.spines[side].set_linewidth(linewidth)\n",
    "\n",
    "    title = (\"Benchmarking using CBED patterns \\n\"\n",
    "             \"with {}-sized disks\").format(disk_size)\n",
    "    title_size=legend_label_font_size\n",
    "    ax.set_title(title, fontsize=title_size)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe65b5a-1729-463a-b101-39c99705a2f2",
   "metadata": {},
   "source": [
    "As we can see from the figures, the RGM approach outperforms the ML approach for\n",
    "the case of small-sized CBED disks, whereas the ML approach is comparable\n",
    "performance-wise to the RGM approach for the case of medium-sized disks, and\n",
    "outperforms the RGM approach for the case of large-sized CBED disks. The fact\n",
    "that the ML approach outperforms the RGM approach for the case of large-sized\n",
    "CBED disks is likely due to the fact that the CBED disks are overlapping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
