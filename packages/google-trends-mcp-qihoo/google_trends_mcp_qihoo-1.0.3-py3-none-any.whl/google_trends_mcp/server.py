#!/usr/bin/env python3
"""
Google Trends MCP Server
ç”¨äºåˆ†æGoogleæœç´¢è¶‹åŠ¿çš„MCPæœåŠ¡å™¨
"""

import asyncio
from typing import List
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent
from pytrends.request import TrendReq

# åˆå§‹åŒ–MCPæœåŠ¡å™¨
server = Server("google-trends-tools", version="1.0.0")

# å…¨å±€pytrendså®ä¾‹
pytrends = None

def get_pytrends():
    """è·å–pytrendså®ä¾‹ï¼Œå»¶è¿Ÿåˆå§‹åŒ–é¿å…å¯åŠ¨æ—¶çš„ç½‘ç»œé—®é¢˜"""
    global pytrends
    if pytrends is None:
        pytrends = TrendReq(hl='zh-CN', tz=360)
    return pytrends

# å®šä¹‰å·¥å…·
google_trends_tool = Tool(
    name="google_trends_analysis",
    description="è·å–Google Trendsæ•°æ®å¹¶æä¾›åˆ†ææŠ¥å‘Š",
    inputSchema={
        "type": "object",
        "properties": {
            "keywords": {
                "type": "array",
                "items": {"type": "string"},
                "description": "å…³é”®è¯åˆ—è¡¨ï¼Œä¾‹å¦‚ ['æ™ºèƒ½å’–å•¡æœº', 'nespresso']"
            },
            "timeframe": {
                "type": "string",
                "description": "æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸º 'today 3-m' (æœ€è¿‘3ä¸ªæœˆ)",
                "default": "today 3-m"
            }
        },
        "required": ["keywords"]
    }
)

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> List[TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    
    if name != "google_trends_analysis":
        raise ValueError(f"Unknown tool: {name}")
    
    keywords = arguments.get("keywords", [])
    timeframe = arguments.get("timeframe", "today 3-m")
    
    if not keywords:
        return [TextContent(type="text", text="âŒ é”™è¯¯ï¼šè¯·æä¾›è‡³å°‘ä¸€ä¸ªå…³é”®è¯")]
    
    if len(keywords) > 5:
        return [TextContent(type="text", text="âŒ é”™è¯¯ï¼šæœ€å¤šæ”¯æŒ5ä¸ªå…³é”®è¯åŒæ—¶åˆ†æ")]
    
    try:
        trends = get_pytrends()
        
        # æ„å»ºè½½è·å¹¶å‘é€è¯·æ±‚
        trends.build_payload(keywords, timeframe=timeframe)
        
        # è·å–å…´è¶£éšæ—¶é—´å˜åŒ–æ•°æ®
        interest_over_time_df = trends.interest_over_time()
        
        if interest_over_time_df.empty:
            result = f"ğŸ“Š æœªæ‰¾åˆ°å…³é”®è¯ {keywords} åœ¨æ—¶é—´æ®µ {timeframe} çš„è¶‹åŠ¿æ•°æ®ã€‚\nè¯·å°è¯•ï¼š\n- ä½¿ç”¨æ›´é€šç”¨çš„å…³é”®è¯\n- è°ƒæ•´æ—¶é—´èŒƒå›´\n- æ£€æŸ¥å…³é”®è¯æ‹¼å†™"
            return [TextContent(type="text", text=result)]
        
        # è·å–ç›¸å…³æŸ¥è¯¢æ•°æ®
        try:
            related_queries_dict = trends.related_queries()
        except Exception as e:
            related_queries_dict = {}
            print(f"è·å–ç›¸å…³æŸ¥è¯¢æ•°æ®å¤±è´¥: {e}")
        
        # å¼€å§‹æ„å»ºåˆ†ææŠ¥å‘Š
        analysis = f"# ğŸ“Š Google Trends åˆ†ææŠ¥å‘Š\n\n"
        analysis += f"**å…³é”®è¯**: {', '.join(keywords)}\n"
        analysis += f"**æ—¶é—´èŒƒå›´**: {timeframe}\n"
        analysis += f"**ç”Ÿæˆæ—¶é—´**: {interest_over_time_df.index[-1].strftime('%Y-%m-%d')}\n\n"
        
        # 1. å¹³å‡å…´è¶£åº¦åˆ†æ
        analysis += "## ğŸ“ˆ å¹³å‡å…³æ³¨åº¦å¯¹æ¯”\n\n"
        mean_interest = interest_over_time_df.mean(numeric_only=True).sort_values(ascending=False)
        
        for i, (kw, score) in enumerate(mean_interest.items(), 1):
            emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "ğŸ“Š"
            analysis += f"{emoji} **{kw}**: {score:.1f}åˆ†\n"
        
        analysis += "\n"
        
        # 2. è¶‹åŠ¿å˜åŒ–åˆ†æ
        analysis += "## ğŸ“Š è¶‹åŠ¿å˜åŒ–åˆ†æ\n\n"
        
        # è®¡ç®—æœ€è¿‘è¶‹åŠ¿ï¼ˆæœ€å4å‘¨ vs å‰4å‘¨çš„å¹³å‡å€¼ï¼‰
        if len(interest_over_time_df) >= 8:
            recent_period = interest_over_time_df.tail(4).mean(numeric_only=True)
            earlier_period = interest_over_time_df.head(len(interest_over_time_df)-4).tail(4).mean(numeric_only=True)
            
            for kw in keywords:
                if kw in recent_period and kw in earlier_period:
                    change = ((recent_period[kw] - earlier_period[kw]) / max(earlier_period[kw], 1)) * 100
                    if change > 20:
                        trend_emoji = "ğŸ“ˆğŸ”¥"
                        trend_text = "å¼ºåŠ²ä¸Šå‡"
                    elif change > 5:
                        trend_emoji = "ğŸ“ˆ"
                        trend_text = "ç¨³æ­¥ä¸Šå‡"
                    elif change < -20:
                        trend_emoji = "ğŸ“‰â„ï¸"
                        trend_text = "æ˜æ˜¾ä¸‹é™"
                    elif change < -5:
                        trend_emoji = "ğŸ“‰"
                        trend_text = "è½»å¾®ä¸‹é™"
                    else:
                        trend_emoji = "â¡ï¸"
                        trend_text = "ç›¸å¯¹ç¨³å®š"
                    
                    analysis += f"- **{kw}**: {trend_emoji} {trend_text} ({change:+.1f}%)\n"
        
        analysis += "\n"
        
        # 3. ä¸Šå‡ç›¸å…³æŸ¥è¯¢åˆ†æ
        analysis += "## ğŸš€ çƒ­é—¨ä¸Šå‡æœç´¢è¯ (å¸‚åœºæœºä¼š)\n\n"
        found_rising = False
        
        for kw in keywords:
            if (kw in related_queries_dict and 
                related_queries_dict[kw] and 
                'rising' in related_queries_dict[kw] and 
                related_queries_dict[kw]['rising'] is not None and 
                not related_queries_dict[kw]['rising'].empty):
                
                found_rising = True
                analysis += f"### ğŸ” å…³äº '{kw}' çš„ä¸Šå‡æœç´¢è¯:\n"
                
                rising_df = related_queries_dict[kw]['rising'].head(5)
                for _, row in rising_df.iterrows():
                    value = row['value']
                    if isinstance(value, str) and value == 'Breakout':
                        growth = "ğŸš€ çˆ†å‘å¼å¢é•¿"
                    elif isinstance(value, (int, float)):
                        growth = f"ğŸ“ˆ +{value}%"
                    else:
                        growth = "ğŸ“Š æ˜¾è‘—å¢é•¿"
                    
                    analysis += f"- **{row['query']}** {growth}\n"
                analysis += "\n"
        
        if not found_rising:
            analysis += "æš‚æ— æ˜¾è‘—çš„ä¸Šå‡æœç´¢è¯æ•°æ®ã€‚\n\n"
        
        # 4. ç­–ç•¥å»ºè®®
        analysis += "## ğŸ’¡ åŸºäºæ•°æ®çš„ç­–ç•¥å»ºè®®\n\n"
        
        top_keyword = mean_interest.index[0]
        analysis += f"### ğŸ¯ æ ¸å¿ƒå…³é”®è¯ç­–ç•¥\n"
        analysis += f"- **ä¸»æ¨å…³é”®è¯**: '{top_keyword}' (å¹³å‡å…³æ³¨åº¦æœ€é«˜: {mean_interest[top_keyword]:.1f}åˆ†)\n"
        analysis += f"- å»ºè®®å°†æ­¤å…³é”®è¯ä½œä¸ºæ ¸å¿ƒæŠ•æ”¾å’ŒSEOä¼˜åŒ–é‡ç‚¹\n\n"
        
        if found_rising:
            analysis += f"### ğŸŒŸ æ–°å…´æœºä¼šç‚¹\n"
            analysis += f"- å…³æ³¨ä¸Šè¿°'ä¸Šå‡æœç´¢è¯'ï¼Œå®ƒä»¬ä»£è¡¨æ–°çš„å¸‚åœºéœ€æ±‚\n"
            analysis += f"- å¯ç”¨äºå†…å®¹åˆ›ä½œã€é•¿å°¾å…³é”®è¯ä¼˜åŒ–å’Œæ–°äº§å“å¼€å‘æ–¹å‘\n\n"
        
        analysis += f"### ğŸ“… æ—¶æœºå»ºè®®\n"
        analysis += f"- æ ¹æ®è¶‹åŠ¿å˜åŒ–ï¼Œåœ¨å…³æ³¨åº¦ä¸Šå‡æœŸåŠ å¤§è¥é”€æŠ•å…¥\n"
        analysis += f"- æŒç»­ç›‘æ§è¶‹åŠ¿å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´ç­–ç•¥\n"
        
        return [TextContent(type="text", text=analysis)]
        
    except Exception as e:
        error_msg = f"âŒ è·å–Google Trendsæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n\n"
        error_msg += "å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\n"
        error_msg += "- æ£€æŸ¥ç½‘ç»œè¿æ¥\n"
        error_msg += "- ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯APIé™æµï¼‰\n"
        error_msg += "- å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„å…³é”®è¯\n"
        error_msg += "- è°ƒæ•´æ—¶é—´èŒƒå›´å‚æ•°"
        return [TextContent(type="text", text=error_msg)]

@server.list_tools()
async def handle_list_tools() -> List[Tool]:
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·"""
    return [google_trends_tool]

async def async_main():
    """å¯åŠ¨MCPæœåŠ¡å™¨"""
    async with stdio_server() as (read_stream, write_stream):
        await server.run(read_stream, write_stream, server.create_initialization_options())

def main():
    """å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    asyncio.run(async_main())

if __name__ == "__main__":
    main()
