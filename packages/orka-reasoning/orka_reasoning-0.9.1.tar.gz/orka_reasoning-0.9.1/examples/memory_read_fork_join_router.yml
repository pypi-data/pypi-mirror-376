orchestrator:
  id: orka-ui
  strategy: parallel
  queue: orka:generated
  agents:
    - memory-read_0
    - openai-answer_2
    - fork_3
    - join_9
    - openai-binary_10
    - router_11
    - memory-write_final
agents:
  - id: memory-read_0
    type: memory
    queue: orka:memory-read_0
    config:
      operation: read
      memory_category_filter: stored
      enable_vector_search: true
      vector_weight: 0.7
      text_weight: 0.3
      enable_hybrid_search: true
      similarity_threshold: 0.75
      ef_runtime: 10
    namespace: fact_validator
    prompt: Retrieve any stored memories about how the subject '{{ get_input() }}' was classified or understood in the past. Return "NONE" if nothing matches.
  - id: openai-answer_2
    type: openai-answer
    queue: orka:openai-answer_2
    prompt: Given previous context {{ get_agent_response('memory-read_0') }}, provide an initial detailed answer to {{ get_input() }}.
  - id: fork_3
    type: fork
    targets:
      - - openai-binary_4
        - openai-classification_5
        - openai-answer_6
      - - openai-answer_7
        - failover_11
    depends_on:
      - openai-answer_2
  - id: openai-binary_4
    type: openai-binary
    queue: orka:openai-binary_4
    prompt: Does the question {{ get_input() }} require factual validation?
    depends_on:
      - fork_3
  - id: openai-answer_7
    type: openai-answer
    queue: orka:openai-answer_7
    prompt: Provide a concise summary for the question {{ get_input() }}.
    depends_on:
      - fork_3
  - id: openai-classification_5
    type: openai-classification
    queue: orka:openai-classification_5
    prompt: Classify the domain of the question {{ get_input() }}
    options:
      - science
      - history
      - technology
      - geography
      - culture
      - general
    depends_on:
      - openai-binary_4
  - id: failover_11
    type: failover
    input: openai-answer_7
    children:
      - id: duckduckgo_12
        type: duckduckgo
        queue: orka:duckduckgo_12
        prompt: "{{ get_input() }}"
      - id: duckduckgo_13
        type: duckduckgo
        queue: orka:duckduckgo_13
        prompt: "{{ get_input() }}"
    depends_on:
      - openai-answer_7
      - duckduckgo_12
      - duckduckgo_13
  - id: openai-answer_6
    type: openai-answer
    queue: orka:openai-answer_6
    prompt: "Provide an alternative perspective or deeper insight into the question {{ get_input() }} considering domain: {{ get_agent_response('openai-classification_5') }}."
    depends_on:
      - openai-classification_5
  - id: join_9
    type: join
    group: fork_3
  - id: openai-binary_10
    type: openai-binary
    queue: orka:openai-binary_10
    prompt: "Is the provided information coherent and complete based on outputs: {{ get_agent_response('join_9') }}?"
    depends_on:
      - join_9
  - id: router_11
    type: router
    params:
      decision_key: openai-binary_10
      routing_map:
        "true":
          - openai-answer_14
          - memory-write_final
        "false":
          - openai-answer_15
          - memory-write_final
    depends_on:
      - openai-binary_10
  - id: openai-answer_14
    type: openai-answer
    queue: orka:openai-answer_14
    prompt: Given confirmed coherent inputs {{ get_agent_response('join_9') }}, provide a polished final response to {{ get_input() }}.
    depends_on:
      - router_11
  - id: openai-answer_15
    type: openai-answer
    queue: orka:openai-answer_15
    prompt: "      Given identified gaps in coherence or completeness in  {{ get_agent_response('join_9') }}, clarify or complete the information to fully answer {{ get_input() }}."
    depends_on:
      - router_11
  - id: memory-write_final
    type: memory
    queue: orka:memory-write_final
    config:
      operation: write
      vector: true
      vector_field_name: "content_vector"
      force_recreate_index: false
    namespace: fact_validator
    prompt: "{{ safe_get_response('openai-answer_14', get_agent_response('openai-answer_15')) }}"
    metadata:
      source: '{{ "openai-answer_14" if get_agent_response("openai-answer_14") else "openai-answer_15" }}'
      result: "{{ safe_get_response('openai-answer_14', get_agent_response('openai-answer_15')) }}"
      category: stored
    key_template: "{{ get_input() }}"
