{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69aeaf81-607b-4d55-9e77-be267ac08479",
   "metadata": {},
   "source": [
    "# LLoCa Quickstart\n",
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/heidelberg-hepml/lloca/blob/main/examples/demo_transformer.ipynb)\n",
    "\n",
    "In this tutorial, we give a quick introduction for how to use Lorentz Local Canonicalization (LLoCa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19f50e-ba16-4a3b-88ee-b6c31c565e83",
   "metadata": {},
   "source": [
    "LLoCa is a framework to make any network Lorentz-equivariant. It uses the concept of canonicalization, i.e. local frames where features are invariant under symmetry transformations, making it possible to process them with any backbone architecture without violating equivariance. The frames are constructed from a set of vectors constructed with a simple Lorentz-equivariant network, which are turned into Lorentz transformations through a orthonormalization step. To maximise expressivity, each particle gets its own *local* frame, but this requires a modification of message-passing to allow the communication of tensorial messages between particles in different frames.\n",
    "\n",
    "We will now demonstrate how to build a simple LLoCa-Transformer following three steps:\n",
    "\n",
    "1. Construct local frames based on 3 equivariantly predicted vectors\n",
    "2. Transform particle features into local frames\n",
    "3. Process local particle features with any backbone architecture\n",
    "\n",
    "![LLoCa workflow](https://raw.githubusercontent.com/heidelberg-hepml/lloca/main/img/lloca.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58232c6b-85e1-4e48-857b-24995368ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the lloca package\n",
    "%pip install lloca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94a506-afb2-47ad-9c44-dbdf7f1081f1",
   "metadata": {},
   "source": [
    "### 0) Generate particle data\n",
    "\n",
    "We start by generating toy particle data, for instance for an amplitude regression task. We describe particles by a four-momentum and one scalar feature, for instance the particle type. Using random numbers, we generate a batch of 128 events with 10 particles each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd9b4b6-eff1-4609-bdda-44157908e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4]) torch.Size([128, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "# generate particle data\n",
    "import torch\n",
    "num_scalars = 1\n",
    "B, N = 128, 10\n",
    "mass = 1\n",
    "p3 = torch.randn(B, N, 3)\n",
    "fourmomenta = torch.cat([(mass**2 + (p3**2).sum(dim=-1, keepdims=True)).sqrt(), p3], dim=-1)\n",
    "scalars = torch.randn(B, N, num_scalars)\n",
    "print(fourmomenta.shape, scalars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374c3ed-6f4b-47c6-9525-e906d5957797",
   "metadata": {},
   "source": [
    "### 1) Construct local frames based on 3 equivariantly predicted vectors\n",
    "\n",
    "Based on these particle features, we want to construct a local frame $L$ for each particle. The local frames are Lorentz transformations, i.e. they satisfy $L^TgL=g$ with $L\\in \\mathbb{R}^{4\\times 4}$. We further design them to satisfy the transformation behavior $L\\overset{\\Lambda}{\\to} L\\Lambda^{-1}$ under Lorentz transformations $\\Lambda$, this ensures that particle features in the local frame are invariant.\n",
    "\n",
    "We construct the local frames in two steps. First, we use a simple Lorentz-equivariant network, `equivectors`, to construct 3 vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ea0375-250f-44e6-84b4-e8a55d9c7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jspinner/.local/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/jspinner/.local/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/jspinner/.local/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/jspinner/.local/lib/python3.10/site-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/jspinner/.local/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/jspinner/.local/lib/python3.10/site-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(\n",
      "/home/jspinner/.local/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/jspinner/.local/lib/python3.10/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from lloca.equivectors.equimlp import EquiMLP\n",
    "\n",
    "def equivectors_constructor(n_vectors):\n",
    "    return EquiMLP(\n",
    "        n_vectors=n_vectors,\n",
    "        num_blocks=2,\n",
    "        num_scalars=num_scalars,\n",
    "        hidden_channels=8,\n",
    "        num_layers_mlp=2,\n",
    "    )\n",
    "\n",
    "# quickly test it\n",
    "equivectors_test = equivectors_constructor(3)\n",
    "vectors = equivectors_test(fourmomenta, scalars)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7352c-f2e5-4e97-be7b-d079c3a2045c",
   "metadata": {},
   "source": [
    "This `equivectors` network is used in the larger `framesnet` class, which also includes the subsequent orthonormalization to construct the local `frames`. We therefore construct the `equivectors_constructor` to the `LearnedPDFrames` `framesnet`, which orthonormalizes the three vectors to construct a Lorentz transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b358bfa-9cff-491b-8924-62b30145c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "from lloca.framesnet.equi_frames import LearnedPDFrames\n",
    "\n",
    "framesnet = LearnedPDFrames(equivectors=equivectors_constructor)\n",
    "frames = framesnet(fourmomenta, scalars)\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7552446-e055-43cb-b6f0-33056bfc16d7",
   "metadata": {},
   "source": [
    "Lets check that the `frames` object satisfies the Lorentz condition $L^T gL=g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496db8b1-7384-44a2-9503-0c796019c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  0.,  0.],\n",
      "        [ 0., -1., -0., -0.],\n",
      "        [ 0., -0., -1., -0.],\n",
      "        [ 0., -0., -0., -1.]])\n",
      "tensor([[ 1.0000e+00, -5.3085e-08,  1.3039e-08,  3.6322e-08],\n",
      "        [-5.3085e-08, -1.0000e+00, -2.9802e-08, -2.9802e-08],\n",
      "        [ 1.3039e-08, -2.9802e-08, -1.0000e+00,  0.0000e+00],\n",
      "        [ 3.6322e-08, -2.9802e-08,  0.0000e+00, -1.0000e+00]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from lloca.utils.lorentz import lorentz_metric\n",
    "\n",
    "metric = lorentz_metric(frames.shape[:-2])\n",
    "print(metric[0,0])\n",
    "\n",
    "lhs = torch.einsum(\"...ij,...jk,...kl->...il\", frames.matrices, metric, frames.matrices.transpose(-1, -2))\n",
    "print(lhs[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f567ddb-1a65-4916-b5bc-e0d3f00de0dd",
   "metadata": {},
   "source": [
    "The package implements many alternative `framesnet` choices. First, a subset of the vectors can be fixed to construct frames equivariant under subgroups of the Lorentz group such as `LearnedSO3Frames` and `LearnedSO2Frames`. Second, random global frames can be sampled to implement data augmentation as in `RandomFrames`, and the baseline `IdentityFrames`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978aff-8156-4acd-8281-8c37ab637e6f",
   "metadata": {},
   "source": [
    "### 2) Transform particle features into local frames\n",
    "\n",
    "Once the frames are constructed, we have to transform the particle features into their local frames. We use the local frames transformation for the four-momenta, whereas the scalar features are already invariant by definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48a34a1-b754-41d2-96ee-b885a3eb7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4])\n",
      "torch.Size([128, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "from lloca.reps.tensorreps_transform import TensorReps, TensorRepsTransform\n",
    "\n",
    "fourmomenta_rep = TensorReps(\"1x1n\")\n",
    "trafo_fourmomenta = TensorRepsTransform(fourmomenta_rep)\n",
    "fourmomenta_local = trafo_fourmomenta(fourmomenta, frames)\n",
    "print(fourmomenta_local.shape)\n",
    "\n",
    "features_local = torch.cat([fourmomenta_local, scalars], dim=-1)\n",
    "print(features_local.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aafee0-0448-4138-92ec-ae2eb87d658c",
   "metadata": {},
   "source": [
    "The `lloca` package implements arbitrary Lorentz tensors through the `TensorReps` class, and their transformation behavior with `TensorRepsTransform`. We denote `0n` for scalar, `1n` for vector, `2n` for rank 2 tensor, and so on, where the `n` stands for *normal* in contrast to *parity-odd* (not fully supported). General representations can be obtained by linear combinations of these fundamentals, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41de4b35-ad29-47fb-ae3a-983dcd6a024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0n: 1-dimensional\n",
      "1x1n: 4-dimensional\n",
      "1x2n: 16-dimensional\n",
      "4x0n+8x1n+3x2n+2x3n: 212-dimensional\n"
     ]
    }
   ],
   "source": [
    "for reps in [\"1x0n\", \"1x1n\", \"1x2n\", \"4x0n+8x1n+3x2n+2x3n\"]:\n",
    "    print(f\"{reps}: {TensorReps(reps).dim}-dimensional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3750da1-7aa8-4fae-865a-e2fd6dced128",
   "metadata": {},
   "source": [
    "As a cross-check, we apply a global Lorentz transformation `random` onto the fourmomenta to obtain `fourmomenta_prime`. We then re-evaluate the frames as `frames_prime`, and obtain `fourmomenta_prime_local` after transforming into the local frames. We indeed find that the four-momenta in the local frame are invariant under (global) Lorentz transformations of the original four-momenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e270ef-b48b-4ed1-99a5-cf77c61e19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3665,  0.3767,  0.4872, -0.6987], grad_fn=<SelectBackward0>)\n",
      "tensor([ 1.3665,  0.3767,  0.4868, -0.6989], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from lloca.utils.rand_transforms import rand_lorentz\n",
    "from lloca.framesnet.frames import Frames\n",
    "\n",
    "random = Frames(rand_lorentz([B,1])).repeat(1, N, 1, 1)\n",
    "fourmomenta_prime = trafo_fourmomenta(fourmomenta, random)\n",
    "frames_prime = framesnet(fourmomenta_prime, scalars)\n",
    "fourmomenta_prime_local = trafo_fourmomenta(fourmomenta_prime, frames_prime)\n",
    "print(fourmomenta_local[0,0])\n",
    "print(fourmomenta_prime_local[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1db51-1a39-49ca-ac6c-c599b61f34be",
   "metadata": {},
   "source": [
    "### 3) Process local particle features with any backbone architecture\n",
    "\n",
    "Given the particle features in the local frame, we can process them with any backbone architecture without violating Lorentz-equivariance. To obtain an equivariant prediction, we have to finally transform the output features from the local into the global frames, however this step is trivial if the output features are scalar.\n",
    "\n",
    "There is one caveat regarding the backbone architecture: To allow a meaningful message-passing, we have to properly transform particle features when they are communicated between particles. This manifests in a modification of the attention mechanism for transformers, and in the message-passing for graph networks. This aspect is already implemented in the backbones available in `lloca/backbone/`, and has to be added for new backbone architectures within LLoCa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8d5ff9-ea8a-4eab-a2bc-48883ff4db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "from lloca.backbone.transformer import Transformer\n",
    "\n",
    "backbone = Transformer(\n",
    "    in_channels=4+num_scalars,\n",
    "    attn_reps=\"4x0n+1x1n\",\n",
    "    out_channels=1,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    ")\n",
    "\n",
    "out = backbone(features_local, frames)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c0e27-5267-4300-ba1f-e936efd2a349",
   "metadata": {},
   "source": [
    "Finally, we check that the network output is indeed invariant under Lorentz transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13116bfd-7657-46e2-ae80-fa80439b541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3903], grad_fn=<SelectBackward0>)\n",
      "tensor([0.3902], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0,0])\n",
    "\n",
    "features_prime_local = torch.cat([fourmomenta_prime_local, scalars], dim=-1)\n",
    "out_prime = backbone(features_prime_local, frames_prime)\n",
    "print(out_prime[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11b15a-8cd2-425b-87de-d13f0b077889",
   "metadata": {},
   "source": [
    "Thats it, now you're ready to build your own `LLoCa` networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfcf599-b98c-4098-8a9a-93686968bb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
