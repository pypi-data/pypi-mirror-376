#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
{{project_name}} é¡¹ç›®è¿è¡Œè„šæœ¬
============================
åŸºäº Crawlo æ¡†æ¶çš„æ™ºèƒ½çˆ¬è™«å¯åŠ¨å™¨ã€‚
æ”¯æŒå•æœº/åˆ†å¸ƒå¼æ¨¡å¼ï¼Œçµæ´»é…ç½®ï¼Œå¼€ç®±å³ç”¨ã€‚

ğŸ¯ å¿«é€Ÿä½¿ç”¨:
    python run.py spider_name                     # å•æœºæ¨¡å¼è¿è¡Œ
    python run.py spider_name --distributed       # åˆ†å¸ƒå¼æ¨¡å¼è¿è¡Œ
    python run.py spider_name --env production    # ä½¿ç”¨é¢„è®¾é…ç½®
    python run.py all                             # è¿è¡Œæ‰€æœ‰çˆ¬è™«

ğŸ”§ é«˜çº§é€‰é¡¹:
    python run.py spider_name --dry-run           # å¹²è¿è¡Œï¼ˆä¸æ‰§è¡Œå®é™…çˆ¬å–ï¼‰
    python run.py spider_name --concurrency 16    # è‡ªå®šä¹‰å¹¶å‘æ•°
    python run.py spider_name --mode gentle       # æ¸©å’Œæ¨¡å¼ï¼ˆä½è´Ÿè½½ï¼‰
    python run.py spider1 spider2 --distributed   # å¤šçˆ¬è™«åˆ†å¸ƒå¼è¿è¡Œ

ğŸ“¦ é…ç½®æ¨¡å¼:
    --standalone     å•æœºæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰- å†…å­˜é˜Ÿåˆ—ï¼Œæ— éœ€å¤–éƒ¨ä¾èµ–
    --distributed    åˆ†å¸ƒå¼æ¨¡å¼ - Redisé˜Ÿåˆ—ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹
    --auto          è‡ªåŠ¨æ¨¡å¼ - æ™ºèƒ½æ£€æµ‹Rediså¯ç”¨æ€§

ğŸ›ï¸ é¢„è®¾é…ç½®:
    --env development    å¼€å‘ç¯å¢ƒï¼ˆè°ƒè¯•å‹å¥½ï¼‰
    --env production     ç”Ÿäº§ç¯å¢ƒï¼ˆé«˜æ€§èƒ½ï¼‰
    --env large-scale    å¤§è§„æ¨¡çˆ¬å–ï¼ˆä¼˜åŒ–å†…å­˜ï¼‰
    --env gentle         æ¸©å’Œæ¨¡å¼ï¼ˆä½è´Ÿè½½ï¼‰
"""

import os
import sys
import asyncio
import argparse
from pathlib import Path
from crawlo.crawler import CrawlerProcess
from crawlo.config import CrawloConfig
from crawlo.mode_manager import standalone_mode, distributed_mode, auto_mode


def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='{{project_name}} çˆ¬è™«å¯åŠ¨å™¨ - åŸºäº Crawlo æ¡†æ¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run.py my_spider                    # é»˜è®¤å•æœºæ¨¡å¼
  python run.py my_spider --distributed      # åˆ†å¸ƒå¼æ¨¡å¼
  python run.py my_spider --env production   # ç”Ÿäº§ç¯å¢ƒé…ç½®
  python run.py spider1 spider2              # è¿è¡Œå¤šä¸ªçˆ¬è™«
  python run.py all                          # è¿è¡Œæ‰€æœ‰çˆ¬è™«
  python run.py my_spider --dry-run          # æµ‹è¯•æ¨¡å¼
        """
    )
    
    # çˆ¬è™«åç§°ï¼ˆä½ç½®å‚æ•°ï¼‰
    parser.add_argument(
        'spiders', 
        nargs='*',
        help='è¦è¿è¡Œçš„çˆ¬è™«åç§°ï¼ˆå¯æŒ‡å®šå¤šä¸ªï¼Œ"all"è¡¨ç¤ºè¿è¡Œæ‰€æœ‰çˆ¬è™«ï¼‰'
    )
    
    # è¿è¡Œæ¨¡å¼é€‰æ‹©
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        '--standalone', 
        action='store_true',
        help='å•æœºæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰- ä½¿ç”¨å†…å­˜é˜Ÿåˆ—ï¼Œæ— éœ€å¤–éƒ¨ä¾èµ–'
    )
    mode_group.add_argument(
        '--distributed', 
        action='store_true',
        help='åˆ†å¸ƒå¼æ¨¡å¼ - ä½¿ç”¨ Redis é˜Ÿåˆ—ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹çˆ¬å–'
    )
    mode_group.add_argument(
        '--auto', 
        action='store_true',
        help='è‡ªåŠ¨æ¨¡å¼ - æ™ºèƒ½æ£€æµ‹ Redis å¯ç”¨æ€§é€‰æ‹©é˜Ÿåˆ—ç±»å‹'
    )
    
    # é¢„è®¾ç¯å¢ƒé…ç½®
    parser.add_argument(
        '--env', 
        choices=['development', 'production', 'large-scale', 'gentle'],
        help='é¢„è®¾ç¯å¢ƒé…ç½®ï¼ˆä¼˜å…ˆçº§é«˜äºæ¨¡å¼é€‰æ‹©ï¼‰'
    )
    
    # æ€§èƒ½è°ƒä¼˜é€‰é¡¹
    parser.add_argument(
        '--concurrency', 
        type=int,
        help='å¹¶å‘è¯·æ±‚æ•°ï¼ˆè¦†ç›–é»˜è®¤è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--delay', 
        type=float,
        help='è¯·æ±‚å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰'
    )
    
    # åŠŸèƒ½é€‰é¡¹
    parser.add_argument(
        '--dry-run', 
        action='store_true',
        help='å¹²è¿è¡Œæ¨¡å¼ - è§£æé¡µé¢ä½†ä¸æ‰§è¡Œå®é™…çˆ¬å–æ“ä½œ'
    )
    
    parser.add_argument(
        '--debug', 
        action='store_true',
        help='å¯ç”¨è°ƒè¯•æ¨¡å¼ - è¯¦ç»†æ—¥å¿—è¾“å‡º'
    )
    
    parser.add_argument(
        '--config-file', 
        type=str,
        help='è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    # ç¯å¢ƒå˜é‡æ”¯æŒ
    parser.add_argument(
        '--from-env', 
        action='store_true',
        help='ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®ï¼ˆCRAWLO_*ï¼‰'
    )
    
    return parser


def build_config(args):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ„å»ºé…ç½®"""
    config = None
    
    # 1. ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
    if args.from_env:
        config = CrawloConfig.from_env()
        print("ğŸ“‹ ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
    
    # 2. ä½¿ç”¨é¢„è®¾ç¯å¢ƒé…ç½®
    elif args.env:
        presets = {
            'development': CrawloConfig.presets().development(),
            'production': CrawloConfig.presets().production(),
            'large-scale': CrawloConfig.presets().large_scale(),
            'gentle': CrawloConfig.presets().gentle()
        }
        config = presets[args.env]
        print(f"ğŸ›ï¸  ä½¿ç”¨é¢„è®¾é…ç½®: {args.env}")
    
    # 3. ä½¿ç”¨æ¨¡å¼é…ç½®
    elif args.distributed:
        config = CrawloConfig.distributed()
        print("ğŸŒ å¯ç”¨åˆ†å¸ƒå¼æ¨¡å¼")
    elif args.auto:
        config = CrawloConfig.auto()
        print("ğŸ¤– å¯ç”¨è‡ªåŠ¨æ£€æµ‹æ¨¡å¼")
    else:
        # é»˜è®¤å•æœºæ¨¡å¼
        config = CrawloConfig.standalone()
        print("ğŸ’» ä½¿ç”¨å•æœºæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰")
    
    # 4. åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.concurrency:
        config.set('CONCURRENCY', args.concurrency)
        print(f"âš¡ è®¾ç½®å¹¶å‘æ•°: {args.concurrency}")
    
    if args.delay:
        config.set('DOWNLOAD_DELAY', args.delay)
        print(f"â±ï¸  è®¾ç½®è¯·æ±‚å»¶è¿Ÿ: {args.delay}ç§’")
    
    if args.debug:
        config.set('LOG_LEVEL', 'DEBUG')
        print("ğŸ› å¯ç”¨è°ƒè¯•æ¨¡å¼")
    
    if args.dry_run:
        # å¹²è¿è¡Œæ¨¡å¼çš„é…ç½®ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
        config.set('DOWNLOAD_DELAY', 0.1)  # åŠ å¿«é€Ÿåº¦
        config.set('CONCURRENCY', 1)       # é™ä½å¹¶å‘
        print("ğŸ§ª å¯ç”¨å¹²è¿è¡Œæ¨¡å¼")
    
    return config


async def main():
    """ä¸»å‡½æ•°ï¼šè§£æå‚æ•°ï¼Œæ„å»ºé…ç½®ï¼Œå¯åŠ¨çˆ¬è™«"""
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_parser()
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†çˆ¬è™«
    if not args.spiders:
        print("âŒ è¯·æŒ‡å®šè¦è¿è¡Œçš„çˆ¬è™«åç§°")
        print("\nå¯ç”¨çš„çˆ¬è™«:")
        print("   # TODO: åœ¨è¿™é‡Œåˆ—å‡ºä½ çš„çˆ¬è™«")
        print("   # from {{project_name}}.spiders import MySpider")
        print("\nä½¿ç”¨æ–¹æ³•: python run.py <spider_name>")
        parser.print_help()
        return
    
    # æ„å»ºé…ç½®
    config = build_config(args)
    
    # åˆ›å»ºçˆ¬è™«è¿›ç¨‹
    print(f"\nğŸš€ æ­£åœ¨å¯åŠ¨çˆ¬è™«: {', '.join(args.spiders)}")
    
    if args.dry_run:
        print("   ğŸ§ª [å¹²è¿è¡Œæ¨¡å¼] å°†è§£æé¡µé¢ä½†ä¸æ‰§è¡Œå®é™…çˆ¬å–")
    
    try:
        # åº”ç”¨é…ç½®å¹¶å¯åŠ¨
        process = CrawlerProcess(settings=config.to_dict())
        
        # æ£€æŸ¥æ˜¯å¦è¦è¿è¡Œæ‰€æœ‰çˆ¬è™«
        if 'all' in [s.lower() for s in args.spiders]:
            # è·å–æ‰€æœ‰å·²æ³¨å†Œçš„çˆ¬è™«åç§°
            spider_names = process.get_spider_names()
            if not spider_names:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•çˆ¬è™«")
                print("ğŸ’¡ è¯·ç¡®ä¿:")
                print("  â€¢ çˆ¬è™«å®šä¹‰åœ¨ 'spiders/' ç›®å½•ä¸­")
                print("  â€¢ çˆ¬è™«ç±»æœ‰ 'name' å±æ€§")
                return 1
            
            print(f"ğŸ“‹ æ‰¾åˆ° {len(spider_names)} ä¸ªçˆ¬è™«: {', '.join(spider_names)}")
            # è¿è¡Œæ‰€æœ‰çˆ¬è™«
            await process.crawl(spider_names)
        else:
            # è¿è¡ŒæŒ‡å®šçˆ¬è™«
            await process.crawl(args.spiders)
        
        print("\nâœ… æ‰€æœ‰çˆ¬è™«æ‰§è¡Œå®Œæˆ")
        
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥çˆ¬è™«: {e}")
        print("   è¯·æ£€æŸ¥çˆ¬è™«æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¹¶æ›´æ–° run.py ä¸­çš„å¯¼å…¥è¯­å¥")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        raise


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­çˆ¬è™«æ‰§è¡Œ")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        sys.exit(1)