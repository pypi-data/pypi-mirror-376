Metadata-Version: 2.4
Name: veotools
Version: 0.1.9
Summary: A Python toolkit for AI-powered video generation and seamless stitching using Google's Veo models.
Project-URL: Homepage, https://github.com/frontboat/veotools
Project-URL: Repository, https://github.com/frontboat/veotools
Project-URL: Issues, https://github.com/frontboat/veotools/issues
Author: frontboat
License: MIT
License-File: LICENSE
Keywords: generation,google-genai,mcp,stitching,veo,video
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Software Development :: Libraries
Requires-Python: >=3.10
Requires-Dist: google-genai<2.0.0,>=1.30.0
Requires-Dist: numpy>=1.26.0
Requires-Dist: opencv-python>=4.8.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: requests>=2.31.0
Provides-Extra: dev
Requires-Dist: build>=1.0.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'dev'
Requires-Dist: pytest-cov>=4.1.0; extra == 'dev'
Requires-Dist: pytest-mock>=3.11.0; extra == 'dev'
Requires-Dist: pytest-xdist>=3.3.0; extra == 'dev'
Requires-Dist: pytest>=7.4.0; extra == 'dev'
Requires-Dist: twine>=4.0.0; extra == 'dev'
Provides-Extra: docs
Requires-Dist: mkdocs-autorefs>=0.5.0; extra == 'docs'
Requires-Dist: mkdocs-material>=9.5.0; extra == 'docs'
Requires-Dist: mkdocs>=1.5.0; extra == 'docs'
Requires-Dist: mkdocstrings[python]>=0.24.0; extra == 'docs'
Provides-Extra: mcp
Requires-Dist: mcp[cli]>=1.0.0; extra == 'mcp'
Description-Content-Type: text/markdown

# Veotools

Concise Python SDK and MCP server for generating and extending videos with Google Veo.

## Features
- Video generation from text, image seed, or continuation from an existing video
- Seamless extension workflow (extract last-second frame → generate → stitch with trim)
- MCP tools with progress streaming (start/get/cancel, continue_video) and recent videos resource
- Model discovery (local registry + remote list, cached)
- Accurate metadata via ffprobe/OpenCV; outputs under project `output/` (override with `VEO_OUTPUT_DIR`)
- Safety settings pass-through for generation (best-effort)
- Context caching helpers and `cached_content` support

## Install

```bash
pip install veotools

# Or install from source
pip install -e .

# With MCP server support
pip install "veotools[mcp]"

# For development (includes testing tools)
pip install -e ".[dev,mcp]"

# Set your API key
export GEMINI_API_KEY="your-api-key"
# Or create a .env file with:
# GEMINI_API_KEY=your-api-key
```

## SDK quick start

### Simple Video Generation

```python
import veotools as veo

# Initialize
veo.init()

# Generate video from text
result = veo.generate_from_text(
    "A serene mountain landscape at sunset",
    model="veo-3.0-fast-generate-preview"
)

print(f"Generated: {result.path}")
```

### Continue and stitch

```python
# Continue from an existing video (like one from your phone)
result = veo.generate_from_video(
    "my_dog.mp4",
    "the dog discovers a treasure chest",
    extract_at=-1.0  # Use last frame
)

# Stitch them together seamlessly
final = veo.stitch_videos(
    ["my_dog.mp4", result.path],
    overlap=1.0  # Trim 1 second overlap
)
```

## CLI

Install exposes the `veo` command. Use `-h/--help` on any subcommand.

```bash
# Basics
veo preflight
veo list-models --remote

# Generate from text (optional safety + cached content)
veo generate --prompt "cat riding a hat" --model veo-3.0-fast-generate-preview \
  --safety-json "[{\"category\":\"HARM_CATEGORY_HARASSMENT\",\"threshold\":\"BLOCK_ONLY_HIGH\"}]" \
  --cached-content "caches/your-cache-name"

# Continue a video and stitch seamlessly
veo continue --video dog.mp4 --prompt "the dog finds a treasure chest" --overlap 1.0 \
  --safety-json "[{\"category\":\"HARM_CATEGORY_HARASSMENT\",\"threshold\":\"BLOCK_ONLY_HIGH\"}]"

# Help
veo --help
veo generate --help
```

### Create a Story with Bridge

```python
# Chain operations together
bridge = veo.Bridge("my_story")

final_video = (bridge
    .add_media("sunrise.jpg")
    .generate("sunrise coming to life")
    .add_media("my_video.mp4")
    .generate("continuing the adventure")
    .stitch(overlap=1.0)
    .save("my_story.mp4")
)
```

## Core functions

### Generation

- `generate_from_text(prompt, model, **kwargs)` - Generate video from text
- `generate_from_image(image_path, prompt, model, **kwargs)` - Generate video from image
- `generate_from_video(video_path, prompt, extract_at, model, **kwargs)` - Continue video

Optional config supported (best-effort pass-through):
- `aspect_ratio` (model-dependent)
- `negative_prompt`
- `person_generation` (validated per Veo model and mode)
- `safety_settings` (list of {category, threshold} or `types.SafetySetting`)
- `cached_content` (cache name string)

### Processing

- `extract_frame(video_path, time_offset)` - Extract single frame
- `extract_frames(video_path, times)` - Extract multiple frames
- `get_video_info(video_path)` - Get video metadata

### Stitching

- `stitch_videos(video_paths, overlap)` - Stitch videos with overlap trimming
- `stitch_with_transitions(videos, transitions)` - Stitch with transition videos

### Workflow

- `Bridge()` - Create workflow chains
- `VideoResult` - Web-ready result objects
- `ProgressTracker` - Progress callback handling

## MCP tools

These functions are designed for integration with MCP servers and return deterministic JSON-friendly dicts.

### System

```python
import veotools as veo

veo.preflight()
# -> { ok: bool, gemini_api_key: bool, ffmpeg: {installed, version}, write_permissions: bool, base_path: str }

veo.version()
# -> { veotools: str | None, dependencies: {...}, ffmpeg: str | None }
```

### Non-blocking generation jobs

```python
import veotools as veo

# Start a job immediately
start = veo.generate_start({
  "prompt": "A serene mountain landscape at sunset",
  "model": "veo-3.0-fast-generate-preview"
})
job_id = start["job_id"]

# Poll status
status = veo.generate_get(job_id)
# -> { job_id, status, progress, message, kind, remote_operation_id?, result?, error_code?, error_message? }

# Request cancellation (cooperative)
veo.generate_cancel(job_id)
```

### Caching helpers

Programmatic usage via MCP-friendly APIs:

```python
import veotools as veo

# Create a cache from files
cache = veo.cache_create_from_files(
  model="gemini-1.5-flash-001",
  files=["media/a11.txt"],
  system_instruction="You are an expert analyzing transcripts."
)

# Use cached content in generation
start = veo.generate_start({
  "prompt": "Summarize the transcript",
  "model": "veo-3.0-fast-generate-preview",
  "options": {"cached_content": cache.get("name")}
})
```

Manage cached content:

```python
import veotools as veo

# List caches (metadata only)
listing = veo.cache_list()
for c in listing.get("caches", []):
    print(c.get("name"), c.get("display_name"), c.get("expire_time"))

# Get single cache metadata
meta = veo.cache_get(name="caches/abc123")

# Update TTL or expiry time
veo.cache_update(name="caches/abc123", ttl_seconds=600)  # set TTL to 10 minutes
# or
veo.cache_update(name="caches/abc123", expire_time_iso="2025-01-27T16:02:36.473528+00:00")

# Delete cache
veo.cache_delete(name="caches/abc123")
```

### Cursor MCP configuration

Add an entry in `~/.cursor/mcp.json` pointing to the installed `veo-mcp` (or your venv path):

```json
{
  "mcpServers": {
    "veotools": {
      "command": "/Users/you/.venv/bin/veo-mcp",
      "args": [],
      "env": {
        "GEMINI_API_KEY": "your-api-key",
        "VEO_OUTPUT_DIR": "/Users/you/projects/output" 
      },
      "disabled": false
    }
  }
}
```

Alternatively, use Python directly:

```json
{
  "mcpServers": {
    "veotools": {
      "command": "/Users/you/.venv/bin/python",
      "args": ["-m", "veotools.mcp_server"],
      "env": { "GEMINI_API_KEY": "your-api-key" },
      "disabled": false
    }
  }
}
```

## Model discovery
```python
models = veotools.list_models(include_remote=True)
print([m["id"] for m in models["models"] if m["id"].startswith("veo-")])
```

## Progress Tracking

```python
def my_progress(message: str, percent: int):
    print(f"{message}: {percent}%")

result = veo.generate_from_text(
    "sunset over ocean",
    on_progress=my_progress
)
```

## Web-ready results

All results are JSON-serializable for API integration:

```python
result = veo.generate_from_text("sunset")

# Convert to dictionary
data = result.to_dict()

# Ready for JSON API
import json
json_response = json.dumps(data)
```

## Examples

See the `examples/` folder for complete examples:

- `examples/text_to_video.py`
- `examples/video_to_video.py`
- `examples/chained_workflow.py`
- `examples/all_functions.py`

## Project Structure

```
src/veotools/
├── __init__.py          # Package initialization and exports
├── core.py              # Core client and storage management
├── models.py            # Data models and result objects
├── cli.py               # Command-line interface
├── api/
│   ├── bridge.py        # Workflow orchestration API
│   └── mcp_api.py       # MCP-friendly wrapper functions
├── generate/
│   └── video.py         # Video generation functions
├── process/
│   └── extractor.py     # Frame extraction and metadata
├── stitch/
│   └── seamless.py      # Video stitching capabilities
└── server/
    └── mcp_server.py    # MCP server implementation

tests/                   # Test suite (mirrors src structure)
├── conftest.py          # Shared fixtures and configuration
├── test_core.py
├── test_models.py
├── test_api/
├── test_generate/
├── test_process/
└── test_stitch/
```

## Key Concepts

### VideoResult
Web-ready result object with metadata, progress, and JSON serialization.

### Bridge Pattern
Chain operations together for complex workflows:
```python
bridge.add_media().generate().stitch().save()
```

### Progress Callbacks
Track long-running operations:
```python
on_progress=lambda msg, pct: print(f"{msg}: {pct}%")
```

### Storage Manager
Organized file management (local now, cloud-ready for future).

## Notes

- Generation usually takes 1–3 minutes
- Veo access may require allowlist
- Person generation constraints per Veo docs:
  - Veo 3: text→video allows `allow_all`; image/video-seeded allows `allow_adult`
  - Veo 2: text→video allows `allow_all`, `allow_adult`, `dont_allow`; image/video-seeded allows `allow_adult`, `dont_allow`

## License

MIT

## Development

### Setting Up Development Environment

```bash
# Clone the repository
git clone https://github.com/frontboat/veotools.git
cd veotools

# Install in development mode with all dependencies
pip install -e ".[dev,mcp]"

# Set up pre-commit hooks (optional)
pre-commit install
```

### Running Tests

```bash
# Run all tests
pytest

# Run only unit tests (fast, no external dependencies)
pytest -m unit

# Run integration tests
pytest -m integration

# Run with coverage report
pytest --cov=veotools --cov-report=html

# Run tests in parallel
pytest -n auto

# Using Make commands
make test           # Run all tests
make test-unit      # Run only unit tests
make test-coverage  # Run with coverage report
```

### Testing Guidelines

- Tests are organized to mirror the source code structure
- All tests use pytest and follow AAA pattern (Arrange-Act-Assert)
- External dependencies (API calls, ffmpeg) are mocked in unit tests
- Fixtures are defined in `tests/conftest.py`
- Mark tests appropriately: `@pytest.mark.unit`, `@pytest.mark.integration`, `@pytest.mark.slow`

### Building and Publishing

```bash
# Build the package
python -m build

# Check the package
twine check dist/*

# Upload to PyPI (requires credentials)
twine upload dist/*
```

## Contributing

Pull requests welcome! Please ensure:
- All tests pass (`make test`)
- Code follows existing style conventions
- New features include appropriate tests
- Documentation is updated as needed

## Support

For issues and questions, please use GitHub Issues.