if __name__ == "__main__":
    #!/usr/bin/env python
    # coding: utf-8

    # # Notebook: PyOlimp ‚Äî –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏
    #
    # –í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å —Å–∏—Å—Ç–µ–º–æ–π **PyOlimp**,
    # –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–æ–π –¥–ª—è –∑–∞–¥–∞—á–∏ **–ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π –∑—Ä–µ–Ω–∏—è** (—Ä–µ—Ñ—Ä–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö).
    #
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å–Ω—ã–π pipeline**, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π:
    # - –∑–∞–≥—Ä—É–∑–∫—É –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, SCA-2023);
    # - –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.
    #
    # üß† –í–∫–ª—é—á—ë–Ω –ø—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏:
    # - `PrecompensationUSRNet` ‚Äî –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–µ—Ç–∏ USRNet —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤–æ–π–Ω–æ–≥–æ –≤–≤–æ–¥–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + PSF), –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏.
    #
    # –í—Å–µ –º–æ–¥—É–ª–∏ –∏ –ø–æ—Ç–æ–∫–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ —Ä–∞–º–∫–∞—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `pyolimp`.

    # ### üì¶ –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫
    #
    # –í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –∏–º–ø–æ—Ä—Ç –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥—É–ª–µ–π –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏—Ö –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞, –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –∏ —É—Ç–∏–ª–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    #
    # - `sys` ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—É—Ç—å, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –º–æ–¥—É–ª—è–º;
    # - `olimp.dataset.sca_2023`:
    #   - `sca_2023` ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –∏–ª–∏ –æ–±—ä–µ–∫—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ SCA-2023;
    #   - `read_img_path` ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º;
    # - `olimp.evaluation.loss.piq.MultiScaleSSIMLoss` ‚Äî —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫–∏ MS-SSIM –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ PIQ, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö;
    # - `olimp.precompensation.nn.models.usrnet.PrecompensationUSRNet` ‚Äî –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ USRNet, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –∑–∞–¥–∞—á –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏;
    # - `olimp.processing.fft_conv` ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–≤—ë—Ä—Ç–∫–∏ –≤ —á–∞—Å—Ç–æ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ (FFT);
    #
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ PyTorch –∏ —É—Ç–∏–ª–∏—Ç—ã:
    # - `torch`, `torch.nn`, `torch.optim` ‚Äî –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, –æ–±—É—á–µ–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π;
    # - `torch.utils.data.Dataset`, `DataLoader` ‚Äî –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏ –∏ –º–∏–Ω–∏-–±–∞—Ç—á–∞–º–∏;
    # - `torchvision.transforms`, `utils` ‚Äî —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è;
    # - `torch.nn.functional` ‚Äî —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã PyTorch (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –ø–æ—Ç–µ—Ä–∏ –∏ —Ç.–¥.);
    #
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
    # - `numpy` ‚Äî –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ —Ä–∞–±–æ—Ç—ã —Å –º–∞—Å—Å–∏–≤–∞–º–∏;
    # - `matplotlib.pyplot` ‚Äî –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤;
    # - `itertools.product` ‚Äî –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–∫–∞—Ä—Ç–æ–≤—ã—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π (–ø–µ—Ä–µ–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤);
    # - `tqdm` ‚Äî –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤ –ø—Ä–∏ –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è).

    # In[3]:

    from multiprocessing import freeze_support
    import sys

    sys.path.append("../../../")

    # In[4]:

    # dataset
    from olimp.dataset.sca_2023 import sca_2023, read_img_path

    # loss
    from olimp.evaluation.loss.piq import MultiScaleSSIMLoss

    # models
    from olimp.precompensation.nn.models.usrnet import PrecompensationUSRNet

    # utils
    from olimp.processing import fft_conv

    # In[5]:

    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader
    from torchvision import transforms, utils
    import torch.nn.functional as F

    # In[6]:

    import numpy as np
    import matplotlib.pyplot as plt
    from itertools import product
    from tqdm import tqdm

    # In[7]:

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device

    # # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    #
    # ## üßæ –ö–ª–∞—Å—Å `PreCompensationDataset`
    #
    # –ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç `PreCompensationDataset` –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä (PSF, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ) –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ **SCA-2023**.
    #
    # –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    # - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ PSF –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤ —Å –ø–æ–º–æ—â—å—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ `image_categories` –∏ `psf_categories`;
    # - –î–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `sca_2023`;
    # - –§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è **–¥–µ–∫–∞—Ä—Ç–æ–≤–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ**: –∫–∞–∂–¥–∞—è PSF –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º;
    # - –í–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è (–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 255), –∞ PSF –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç—Å—è –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é `torch.fft.fftshift`.
    #
    # –í—ã—Ö–æ–¥ `__getitem__`:
    # - `psf` ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è —Ç–æ—á–∫–∏;
    # - `image` ‚Äî –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–ª–∞–≤–∞—é—â–µ–π –∑–∞–ø—è—Ç–æ–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1].
    #
    # –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏, –ø–æ–∑–≤–æ–ª—è—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∏—Å–∫–∞–∂–µ–Ω–∏–π.

    # In[8]:

    class PreCompensationDataset(Dataset):

        def __init__(self, image_categories: dict, psf_categories: dict):
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            image_dict = sca_2023(categories=image_categories)
            psf_dict = sca_2023(categories=psf_categories)

            self.images = []
            for key in image_dict:
                self.images.extend(image_dict[key])

            self.psfs = []
            for key in psf_dict:
                self.psfs.extend(psf_dict[key])

            # –î–µ–∫–∞—Ä—Ç–æ–≤–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ: –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ –≤—Å–µ–º–∏ PSF
            self.pairs = list(product(self.images, self.psfs))

        def __len__(self):
            return len(self.pairs)

        def __getitem__(self, idx):
            img_path, psf_path = self.pairs[idx]

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = read_img_path(img_path) / 255.0

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è PSF
            psf = read_img_path(psf_path).float()
            psf /= psf.sum()
            psf = torch.fft.fftshift(psf)

            return psf, image

    # In[9]:

    dataset = PreCompensationDataset(
        image_categories={
            "Images/Real_images",
        },
        psf_categories={"PSFs/Broad"},
    )

    # ### üß™ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    #
    # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –¥–µ–ª–∏—Ç—Å—è –Ω–∞ —Ç—Ä–∏ —á–∞—Å—Ç–∏:
    #
    # - **–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞** (`train_size`) ‚Äî 40% –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤;
    # - **–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞** (`val_size`) ‚Äî 40% –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤;
    # - **–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞** (`test_size`) ‚Äî –æ—Å—Ç–∞–≤—à–∏–µ—Å—è 20% (–≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∫–∞–∫ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –ø–æ–ª–Ω–æ–π –¥–ª–∏–Ω–æ–π –∏ —Å—É–º–º–æ–π –ø–µ—Ä–≤—ã—Ö –¥–≤—É—Ö —á–∞—Å—Ç–µ–π).

    # In[10]:

    train_size = int(0.4 * len(dataset))
    val_size = int(0.4 * len(dataset))
    test_size = len(dataset) - (train_size + val_size)

    print(train_size, val_size, test_size)

    # ### üîÄ –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞

    # In[11]:

    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )

    # ### üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (`DataLoader`)
    #
    # –°–æ–∑–¥–∞—é—Ç—Å—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `torch.utils.data.DataLoader`:
    #
    # - `train_dataloader` ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É:
    #   - `shuffle=True` ‚Äî –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–æ–π;
    #   - `batch_size=1` ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 1 (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å);
    #   - `pin_memory=True` ‚Äî —É—Å–∫–æ—Ä—è–µ—Ç –ø–µ—Ä–µ–¥–∞—á—É –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU;
    #   - `num_workers=4` ‚Äî —á–∏—Å–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏;
    #   - `prefetch_factor=2` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö –±–∞—Ç—á–µ–π –Ω–∞ –ø–æ—Ç–æ–∫.
    #
    # - `val_dataloader` ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É:
    #   - `shuffle=False` ‚Äî –ø–æ—Ä—è–¥–æ–∫ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è;
    #   - –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã `train_dataloader`.

    # In[12]:

    batchsize = 1

    # In[13]:

    train_dataloader = DataLoader(
        train_dataset, shuffle=True, batch_size=batchsize
    )

    # In[14]:

    val_dataloader = DataLoader(
        val_dataset, shuffle=False, batch_size=batchsize
    )

    # In[15]:

    val_dataloader = train_dataloader

    # ### üñºÔ∏è –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (`plot_images`)
    #
    # –§—É–Ω–∫—Ü–∏—è `plot_images` –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —É–¥–æ–±–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –≤–∏–¥–µ —Å–µ—Ç–∫–∏.
    #
    # –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    # - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ `torch.Tensor`, —Ç–∞–∫ –∏ `numpy.ndarray`;
    # - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ —Ñ–æ—Ä–º–∞—Ç—É `float32` –∏ –¥–∏–∞–ø–∞–∑–æ–Ω—É [0, 1];
    # - –£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (`squeeze`) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç –∏–∑ `CHW` –≤ `HWC` –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏;
    # - –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é `matplotlib.pyplot.imshow`:
    #   - –≤ –æ—Ç—Ç–µ–Ω–∫–∞—Ö —Å–µ—Ä–æ–≥–æ, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2D;
    #   - –≤ —Ü–≤–µ—Ç–µ, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 3D;
    # - –ü—Ä–∏ –ø–µ—Ä–µ–¥–∞—á–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ `titles` –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –º–∏–Ω–∏–º—É–º–∞ –∏ –º–∞–∫—Å–∏–º—É–º–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è;
    # - –£–¥–∞–ª—è–µ—Ç –æ—Å–∏ (`axis('off')`) –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏;
    # - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç `tight_layout()` –∏ –≤—ã–∑—ã–≤–∞–µ—Ç `plt.show()`.

    # In[16]:

    def plot_images(images, titles=None, rows=1, figsize=(12, 3)):
        cols = len(images)
        fig, axs = plt.subplots(rows, cols, figsize=figsize)
        axs = np.atleast_1d(axs).ravel()

        for i, img in enumerate(images):
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ numpy –∏ float32
            if isinstance(img, torch.Tensor):
                arr = img.detach().cpu().to(torch.float32).numpy()
            elif isinstance(img, np.ndarray):
                arr = img.astype(np.float32)
            else:
                arr = np.array(img, dtype=np.float32)

            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–Ω–∞–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
            arr = arr.squeeze()
            if arr.ndim == 3 and arr.shape[0] in (1, 3):  # CHW -> HWC
                arr = arr.transpose(1, 2, 0)

            axs[i].imshow(
                arr, cmap="gray" if arr.ndim == 2 else None, vmin=0, vmax=1
            )
            axs[i].axis("off")
            if titles:
                axs[i].set_title(
                    f"{titles[i]}\nmin={arr.min():.3f}, max={arr.max():.3f}"
                )

        plt.tight_layout()
        plt.show()

    # ### üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
    #
    # –í —ç—Ç–æ–º –±–ª–æ–∫–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞.
    #
    # - –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å `PrecompensationUSRNet` —Å –∑–∞—Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏:
    #   ```python
    #   model = PrecompensationUSRNet().from_path(path="hf://RVI/usrnet_color_ms_ssim.pth").to(device)

    # In[17]:

    def new_preprocess(self, image, psf, scale_factor=1, noise_level=0):
        sigma = torch.tensor(noise_level).float().view([1, 1, 1, 1])
        sigma = sigma.repeat([image.shape[0], 1, 1, 1])
        # –£–±—Ä–∞–ª–∏ fftshift
        return image, psf, scale_factor, sigma

    # In[18]:

    model = (
        PrecompensationUSRNet()
        .from_path(path="hf://RVI/usrnet_color_ms_ssim.pth")
        .to(device)
    )

    # In[19]:

    from types import MethodType

    model.preprocess = MethodType(new_preprocess, model)

    # ### small test

    # In[20]:

    # –ü–µ—Ä–≤—ã–π –±–∞—Ç—á
    for psfs, imgs in train_dataloader:
        psfs = psfs.to(device)
        imgs = imgs.to(device)
        blurs = fft_conv(imgs, psfs)

        with torch.inference_mode():
            model_inputs = model.preprocess(imgs, torch.fft.fftshift(psfs))
            model_inputs = tuple(
                inp.to(device) if isinstance(inp, torch.Tensor) else inp
                for inp in model_inputs
            )
            model_outputs = model(model_inputs)
            precompensated = model_outputs[0]
            retinal = fft_conv(precompensated, psfs)

        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –±–∞—Ç—á–∞
        for i in range(len(imgs)):
            plot_images(
                images=[imgs[i], blurs[i], precompensated[i], retinal[i]],
                titles=["Original", "Blurred", "Precompensated", "Retinal"],
                rows=1,
                figsize=(16, 4),
            )

        break  # —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á

    # ### üìâ –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (`loss_func`)
    #
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è `loss_func`, —Ä–µ–∞–ª–∏–∑—É—é—â–∞—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–π –ø–æ—Ç–µ—Ä–∏ (MS-SSIM) –º–µ–∂–¥—É –¥–≤—É–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏:
    #

    # In[21]:

    def loss_func(img1, img2):
        device = img1.device
        ms_ssim = MultiScaleSSIMLoss().to(device)
        ms_ssim.scale_weights = ms_ssim.scale_weights.to(img1.device)
        loss = ms_ssim(img1, img2)
        return loss

    # ### üìà –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    #
    # –î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä `Adam`:

    # In[22]:

    initial_lr = 1e-5
    optimizer_model = torch.optim.Adam(model.parameters(), lr=initial_lr)

    # ### üèãÔ∏è‚Äç‚ôÇÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏
    #
    # –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫:
    #
    # - –ò–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏:
    #   - `os` ‚Äî –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–æ–≤, –º–æ–¥–µ–ª–µ–π –∏ —Ç.–¥.);
    #   - `json` ‚Äî –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
    #
    # - –ò–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (AMP)** –∏–∑ `torch.cuda.amp`:
    #   - `GradScaler` ‚Äî –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã, –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—è –ø—Ä–æ–±–ª–µ–º—É underflow –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –≤ `float16`;
    #   - `autocast` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ–∂–¥—É `float32` –∏ `float16` —Ç–∞–º, –≥–¥–µ —ç—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ.
    #
    # - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è `scaler` –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤

    # In[23]:

    import os
    import json
    from torch.cuda.amp import GradScaler, autocast

    scaler = GradScaler()

    # In[24]:

    def ensure_dir(path):
        os.makedirs(path, exist_ok=True)

    def save_checkpoint(model, epoch, batch_idx, out_dir="checkpoints"):
        folder = os.path.join(
            out_dir, f"epoch_{epoch:03}_batch_{batch_idx:05}"
        )
        ensure_dir(folder)
        checkpoint_path = os.path.join(folder, "model.pth")
        torch.save(model.state_dict(), checkpoint_path)
        print(f"Checkpoint saved to {checkpoint_path}")

    def load_last_checkpoint(
        model, optimizer=None, out_dir="checkpoints"
    ):  # returns (start_epoch, last_batch)
        if not os.path.exists(out_dir):
            return 1, 0
        # find folders epoch_{e}_batch_{b}
        folders = [d for d in os.listdir(out_dir) if d.startswith("epoch_")]
        if not folders:
            return 1, 0
        # parse and sort
        ckpts = []
        for f in folders:
            parts = f.split("_")
            try:
                e = int(parts[1])
                b = int(parts[3])
                ckpts.append((e, b, f))
            except:
                continue
        if not ckpts:
            return 1, 0
        e, b, folder = max(ckpts, key=lambda x: (x[0], x[1]))
        path = os.path.join(out_dir, folder, "model.pth")
        model.load_state_dict(torch.load(path))
        if optimizer:
            # optimizer state not saved; user may need custom
            pass
        return e, b

    def train(
        model,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion,
        optimizer,
        epochs: int,
        checkpoint_interval: int = 2000,
        device: str = "cuda",
        plot_every: int = None,
        fast_stop: bool = False,
    ):
        IS_POSIX = os.name != "nt"
        ensure_dir("checkpoints")
        ensure_dir("logs")
        model.to(device)
        # load logs if resuming
        start_epoch = 1
        metrics = {"epoch": [], "train_loss": [], "val_loss": []}
        best_train_loss = float("inf")
        best_val_loss = float("inf")
        # resume from metrics.json
        if os.path.exists("logs/metrics.json"):
            with open("logs/metrics.json", "r") as f:
                data = json.load(f)
            metrics = data.get("metrics", metrics)
            best = data.get("best", {})
            best_train_loss = best.get("train_loss", best_train_loss)
            best_val_loss = best.get("val_loss", best_val_loss)
            if metrics["epoch"]:
                last_epoch = metrics["epoch"][-1]
                start_epoch = last_epoch + 1
                # load last checkpoint
                load_last_checkpoint(model, optimizer)
        # training loop
        for epoch in tqdm(range(start_epoch, epochs + 1), desc="Epochs"):
            model.train()
            train_losses = []
            for batch_idx, (psfs, imgs) in enumerate(
                tqdm(train_loader, desc="Batches", leave=False), 1
            ):
                psfs, imgs = psfs.to(device), imgs.to(device)
                blurs = fft_conv(imgs, psfs)
                inputs = model.preprocess(imgs, torch.fft.fftshift(psfs))
                inputs = tuple(
                    x.to(device) if isinstance(x, torch.Tensor) else x
                    for x in inputs
                )
                if IS_POSIX:
                    with autocast():
                        outputs = model(inputs)
                else:
                    outputs = model(inputs)

                precompensated = outputs[0].to(torch.float32)
                retinal = fft_conv(precompensated, psfs)
                retinal = torch.nan_to_num(
                    retinal, nan=0.0, posinf=1.0, neginf=0.0
                )
                retinal = torch.clip(retinal, 0, 1)
                optimizer.zero_grad()
                loss = criterion(retinal, imgs)

                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()

                train_losses.append(loss.item())
                if batch_idx % checkpoint_interval == 0:
                    save_checkpoint(model, epoch, batch_idx)
                if plot_every and batch_idx % plot_every == 0:
                    print(
                        f"Epoch {epoch}, Batch {batch_idx} loss: {loss.item():.4f}"
                    )
                    for i in range(len(imgs)):
                        plot_images(
                            images=[
                                imgs[i],
                                blurs[i],
                                precompensated[i],
                                retinal[i],
                            ],
                            titles=[
                                "Original",
                                "Blurred",
                                "Precompensated",
                                "Retinal",
                            ],
                            rows=1,
                            figsize=(16, 4),
                        )
                if fast_stop:
                    print("Training stop for demo purpose")
                    return

            mean_train_loss = sum(train_losses) / len(train_losses)
            model.eval()
            val_losses = []
            with torch.no_grad():
                for psfs, imgs in val_loader:
                    psfs, imgs = psfs.to(device), imgs.to(device)
                    blurs = fft_conv(imgs, psfs)
                    inputs = model.preprocess(imgs, torch.fft.fftshift(psfs))
                    inputs = tuple(
                        x.to(device) if isinstance(x, torch.Tensor) else x
                        for x in inputs
                    )
                    with autocast():
                        outputs = model(inputs)
                    precompensated = outputs[0].to(torch.float32)
                    retinal = fft_conv(precompensated, psfs)
                    retinal = torch.nan_to_num(
                        retinal, nan=0.0, posinf=1.0, neginf=0.0
                    )
                    retinal = torch.clip(retinal, 0, 1)
                    val_losses.append(criterion(retinal, imgs).item())
            mean_val_loss = sum(val_losses) / len(val_losses)
            best_train_loss = min(best_train_loss, mean_train_loss)
            best_val_loss = min(best_val_loss, mean_val_loss)
            metrics["epoch"].append(epoch)
            metrics["train_loss"].append(mean_train_loss)
            metrics["val_loss"].append(mean_val_loss)
            ensure_dir("logs")
            with open("logs/metrics.json", "w") as f:
                json.dump(
                    {
                        "metrics": metrics,
                        "best": {
                            "train_loss": best_train_loss,
                            "val_loss": best_val_loss,
                        },
                    },
                    f,
                    indent=4,
                )
            print(
                f"Epoch {epoch}: train_loss={mean_train_loss:.4f} (best {best_train_loss:.4f}),"
                f" val_loss={mean_val_loss:.4f} (best {best_val_loss:.4f})"
            )
        return metrics, {
            "best_train_loss": best_train_loss,
            "best_val_loss": best_val_loss,
        }

    # In[25]:

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    train(
        model=model,
        train_loader=train_dataloader,
        val_loader=val_dataloader,
        criterion=loss_func,
        optimizer=optimizer_model,
        epochs=1500,
        checkpoint_interval=2500,
        plot_every=1,
        fast_stop=True,
    )
