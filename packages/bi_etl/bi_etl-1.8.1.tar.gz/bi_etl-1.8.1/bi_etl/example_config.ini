#######################################################
##               EXAMPLE CONFIG FILE
## Copy to your ETL folder and customize as required
#######################################################

[Config]
parent=example_config_shared.ini


[bi_etl]
environment_name=my_example
parallel_processes=1
partitions_per_thread=1
lookup_disk_swap_at_percent_ram_used=85
#lookup_disk_swap_at_process_ram_usage_mb=2000

[load_sequence]
job_retries=1


[logging]
log_folder=C:\python_logs
console_entry_format=%(levelname)-8s %(name)s: %(message)s
## root_level sets the logging level for any class not explicltly set in the [loggers] section
root_level=INFO
## console_log_level can be used to filter ALL messages on the console
console_log_level=DEBUG
## file_log_level can be used to filter ALL messages in the file
file_log_level=DEBUG
log_file_max_size=10MB
log_files_to_keep=9
log_file_entry_format=%(asctime)s - %(levelname)-8s - %(name)s: %(message)s
#date_format=%Y-%m-%d %H:%M:%S
#######  LOGGING FORMAT PLACEHOLDERS
#   %(name)s            Name of the logger (logging channel)
#   %(levelno)s         Numeric logging level for the message (DEBUG, INFO,
#                       WARNING, ERROR, CRITICAL)
#   %(levelname)s       Text logging level for the message ("DEBUG", "INFO",
#                       "WARNING", "ERROR", "CRITICAL")
#   %(pathname)s        Full pathname of the source file where the logging
#                       call was issued (if available)
#   %(filename)s        Filename portion of pathname
#   %(module)s          Module (name portion of filename)
#   %(lineno)d          Source line number where the logging call was issued
#                       (if available)
#   %(funcName)s        Function name
#   %(created)f         Time when the LogRecord was created (time.time()
#                       return value)
#   %(asctime)s         Textual time when the LogRecord was created
#   %(msecs)d           Millisecond portion of the creation time
#   %(relativeCreated)d Time in milliseconds when the LogRecord was created,
#                       relative to the time the logging module was loaded
#                       (typically at application startup time)
#   %(thread)d          Thread ID (if available)
#   %(threadName)s      Thread name (if available)
#   %(process)d         Process ID (if available)
#   %(message)s         The result of record.getMessage(), computed just as
#                       the record is emitted

[loggers]
root=DEBUG
## __main__ will be used for ETL jobs or other files when run directly
__main__=DEBUG 
bi_etl=DEBUG
my_package.sub_package.my_module=DEBUG
Scheduler=DEBUG
etl_jobs=DEBUG

################################################################################################
## Configuration for bi_etl.scheduler.scheduler_interface and bi_etl.scheduler.scheduler
[Scheduler]
trace=True
database=WAREHOUSE
schema=myuserid
## Which host should the scheduler submit to or process from
qualified_host_name=mymachinename

process_check_interval=2
maximum_concurrent_tasks=2
base_module=etl_jobs
base_ui_url=http://localhost:6543/etl/get_workflow_status?root_task_id=

################################################################################################

[Cache]
path=C:\temp

[Limits]
## Limits for lookup RAM (and in future Disk) usage

[SMTP]
from=sender@example.com
gateway=smtp.example.com
distro_list=<developer1@example.com>,<developer2@example.com>

[JIRA]
server=https://example.atlassian.net
userid=bot
password=*******************

## Configuration for bi_etl.informatica.pmcmd.PMCMD
[INFORMATICA_COMMANDS]
INFA_HOME=E:\Informatica\9.5.1\clients\PowerCenterClient\CommandLineUtilities\PC
INFA_DOMAINS_FILE=E:\Informatica\9.5.1\clients\PowerCenterClient\domains.infa
## RUN_VIA_CMD is only referenced on Windows
RUN_VIA_CMD=Yes
USER_ID=my_informatica_userid
## Password encrypted with pmpasswd
PASSWORD=**********
REPOSITORY=repo
SERVICE=BI_IS
DOMAIN=domain_example_com

######################################################################################################################
# Begin of Databse connection configurations used by bi_etl.scheduler.task.ETLTask.get_database

# logical database definition (The DSN is expected to be different in each environment)
[WAREHOUSE]
dsn=bidev
default_user_id=etl_user
dialect=oracle
fast_numeric=on
encoding=cp1252
arraysize=5000

[STAGE]
dsn=${WAREHOUSE:dsn}
default_user_id=${WAREHOUSE:default_user_id}
schema=STAGING
arraysize=${WAREHOUSE:arraysize}

[etl_user]
userid=etl_user
## Note: passwords can also stored using keyring
##       using Service = DB_definition_name
##             Username = userid
##       On Windows those stored passwords can be managed using Windows Credential Manager.
##       On any platform they can be managed using the keyring command line.
password=*******************

## Note: userid is not required, it defaults to the section name
[other_user]
password=*******************

[sql_server_example]
## URL becomes dialect://user:pass@dsn/dbname
dialect=mssql+pyodbc
dsn=example_odbc_dsn
default_user_id=BI_USER

[BI_USER]
password=*******************

# End of Databse connection configurations
######################################################################################################################

######################################################################################################################
## Begin of individual ETL job configuration parameters

[etl_jobs.data_mart.f_events]
max_rows=500

## End of individual ETL job configuration parameters
######################################################################################################################