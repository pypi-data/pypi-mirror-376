# db_client.py

import os

import pandas as pd
import psycopg2
import yaml
from pandas import PeriodDtype
from psycopg2 import sql, connect
from psycopg2.extras import execute_values

# import logging
from hmcis_packs.logger.logger_config import setup_logger

# ========== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ==========
# –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤ ‚Äî —Å–æ–∑–¥–∞—ë–º, –µ—Å–ª–∏ –Ω–µ—Ç
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

LOG_FILE = os.path.join(LOG_DIR, 'database_client.log')

# # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥—É–ª—è
# logging.basicConfig(
#     level=logging.INFO,
#     format='%(asctime)s %(levelname)s: %(message)s',
#     handlers=[
#         logging.StreamHandler(sys.stdout),  # –≤ –∫–æ–Ω—Å–æ–ª—å (stdout)
#         logging.FileHandler(LOG_FILE, encoding='utf-8')  # –≤ —Ñ–∞–π–ª
#     ]
# )

logger = setup_logger(__name__)


# ===============================================


class DatabaseClient:
    def __init__(self, config_path=None):
        if config_path is None:
            user_home = os.path.expanduser("~")
            config_path = os.path.join(user_home, "db_config.yaml")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.db_config = yaml.safe_load(f)

    def _map_dtype(self, dtype):
        """
        –ú–∞–ø–ø–∏–Ω–≥ pandas dtype ‚Üí PostgreSQL —Ç–∏–ø.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç PeriodDtype, float, int, bool, datetime, object –∏ fallback BYTEA.
        """
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–∏–æ–¥–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å isinstance —Å PeriodDtype
        if isinstance(dtype, PeriodDtype):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–∏–æ–¥ –∫–∞–∫ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ TIMESTAMP
            return 'TIMESTAMP'
        if pd.api.types.is_float_dtype(dtype):
            return 'NUMERIC'
        if pd.api.types.is_integer_dtype(dtype):
            return 'INTEGER'
        if pd.api.types.is_bool_dtype(dtype):
            return 'BOOLEAN'
        if pd.api.types.is_datetime64_any_dtype(dtype):
            return 'TIMESTAMP'
        if dtype == 'object':
            return 'VARCHAR'
        return 'BYTEA'

    def save_df_to_db(self,
                      df: pd.DataFrame,
                      table_name: str,
                      schema: str = 'IFRS Reports',
                      binary_columns: list[str] = None):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ PostgreSQL, —Å–æ–∑–¥–∞—ë—Ç —Å—Ö–µ–º—É/—Ç–∞–±–ª–∏—Ü—É –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏,
        –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø–∞–∫–µ—Ç–Ω—É—é –≤—Å—Ç–∞–≤–∫—É —á–µ—Ä–µ–∑ execute_values.
        –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ 2 –∫–æ–º–º–∏—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ —Å—Ö–µ–º–∞, –ø–æ—Ç–æ–º —Ç–∞–±–ª–∏—Ü–∞ + –¥–∞–Ω–Ω—ã–µ.
        """
        if binary_columns is None:
            binary_columns = []

        # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å –ø—É—Å—Ç—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
        df = df.loc[:, df.columns.str.strip() != '']
        df = df.iloc[:, df.columns.notna()]
        conn = psycopg2.connect(**self.db_config)
        cursor = conn.cursor()
        try:
            # 1) –°–æ–∑–¥–∞—ë–º —Å—Ö–µ–º—É –∏ –∫–æ–º–º–∏—Ç–∏–º —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–∫–∞—Ç–∏–ª—Å—è –≤–º–µ—Å—Ç–µ —Å –æ—à–∏–±–∫–∞–º–∏ –Ω–∏–∂–µ
            cursor.execute(
                sql.SQL("CREATE SCHEMA IF NOT EXISTS {}")
                .format(sql.Identifier(schema))
            )
            conn.commit()

            # 2) –ì–æ—Ç–æ–≤–∏–º DDL –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
            cols_ddl = []
            for col, dtype in zip(df.columns, df.dtypes):
                if col in binary_columns:
                    pg_type = 'BYTEA'
                else:
                    pg_type = self._map_dtype(dtype)
                cols_ddl.append(f"{sql.Identifier(col).as_string(conn)} {pg_type}")

            create_sql = sql.SQL(
                "CREATE TABLE IF NOT EXISTS {schema}.{table} ({fields})"
            ).format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
                fields=sql.SQL(", ").join(sql.SQL(c) for c in cols_ddl),
            )
            cursor.execute(create_sql)

            # 3) –û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π
            truncate_sql = sql.SQL("TRUNCATE {schema}.{table}").format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
            )
            cursor.execute(truncate_sql)

            # 4) –ì–æ—Ç–æ–≤–∏–º –ø–∞–∫–µ—Ç–Ω—É—é –≤—Å—Ç–∞–≤–∫—É
            insert_sql = sql.SQL(
                "INSERT INTO {schema}.{table} ({fields}) VALUES %s"
            ).format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
                fields=sql.SQL(', ').join(map(sql.Identifier, df.columns))
            )
            records = []
            for row in df.itertuples(index=False, name=None):
                rec = []
                for val, col in zip(row, df.columns):
                    if col in binary_columns:
                        rec.append(psycopg2.Binary(val))
                    else:
                        rec.append(val)
                records.append(tuple(rec))

            execute_values(cursor, insert_sql.as_string(conn), records, page_size=10000)

            # 5) –§–∏–∫—Å–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ –≤—Å—Ç–∞–≤–∫—É –¥–∞–Ω–Ω—ã—Ö
            conn.commit()
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ '{schema}.{table_name}'")

        except Exception as e:
            conn.rollback()
            logger.error("üíÄ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: %s", e)
            raise
        finally:
            cursor.close()
            conn.close()

    def fetch_data(self, query: str, params: tuple = None, schema: str = None):
        """
        –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –ë–î –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å.

        :param query: SQL-–∑–∞–ø—Ä–æ—Å (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ sql.SQL)
        :param params: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ –∑–∞–ø—Ä–æ—Å
        :param schema: —Å—Ö–µ–º–∞ –≤ –±–¥, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π —á–∏—Ç–∞–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        :return: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        conn = None
        try:
            conn = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config.get('port', 5432),
                dbname=self.db_config['dbname'],
                user=self.db_config['user'],
                password=self.db_config['password'],
            )
            with conn.cursor() as cur:
                cur.execute(query, params)
                return cur.fetchall()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ë–î: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def execute_custom(self, raw_sql: str, schema: str, params: tuple = None):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π SQL, –ø–æ–¥—Å—Ç–∞–≤–ª—è—è –∏–º—è —Å—Ö–µ–º—ã.

        :param raw_sql: SQL —Å–æ –≤—Å—Ç–∞–≤–∫–æ–π {schema}, –Ω–∞–ø—Ä–∏–º–µ—Ä
                        "SELECT * FROM {schema}.my_table WHERE x = %s"
        :param schema: –∏–º—è —Å—Ö–µ–º—ã –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏
        :param params: –∫–æ—Ä—Ç–µ–∂ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è %s-–ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        :return: —Ä–µ–∑—É–ª—å—Ç–∞—Ç fetchall()
        """
        # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å, –±–µ–∑–æ–ø–∞—Å–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä—É—è –∏–º—è —Å—Ö–µ–º—ã
        query = sql.SQL(raw_sql).format(
            schema=sql.Identifier(schema)
        )

        conn = psycopg2.connect(**self.db_config)
        try:
            with conn.cursor() as cur:
                cur.execute(query, params or ())
                rows = cur.fetchall()
                # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
                columns = [desc[0] for desc in cur.description]
                return rows, columns
        finally:
            conn.close()

    def stream_data_with_timer(self,
                               raw_sql: str,
                               schema: str,
                               params: tuple = None,
                               chunk_size: int = 10_000):
        """
        –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä: –ø–æ –ø–æ—Ä—Ü–∏—è–º –æ—Ç–¥–∞—ë—Ç (rows, columns).
        columns –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –ø–æ—Ä—Ü–∏–∏, –¥–∞–ª–µ–µ None.
        """
        query = sql.SQL(raw_sql).format(schema=sql.Identifier(schema))
        conn = psycopg2.connect(**self.db_config)

        try:
            with conn.cursor(name="streaming_cursor") as cur:
                cur.itersize = chunk_size
                cur.execute(query, params or ())

                first_batch = True
                while True:
                    rows = cur.fetchmany(chunk_size)
                    if not rows:
                        break

                    if first_batch:
                        columns = [desc[0] for desc in cur.description]
                        yield rows, columns
                        first_batch = False
                    else:
                        yield rows, None
        finally:
            conn.close()

    def get_total_count(self, raw_sql: str, schema: str, params: tuple = None) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–µ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã–¥–∞—Å—Ç raw_sql (–±–µ–∑ LIMIT).
        """
        count_sql = f"SELECT COUNT(*) FROM ({raw_sql}) AS subquery"
        query = sql.SQL(count_sql).format(schema=sql.Identifier(schema))
        with psycopg2.connect(**self.db_config) as conn, conn.cursor() as cur:
            cur.execute(query, params or ())
            return cur.fetchone()[0]

    def extract_data_with_timer(self,
                                raw_sql: str,
                                schema: str,
                                params: tuple = None,
                                chunk_size: int = 10_000):
        total = self.get_total_count(raw_sql, schema, params)
        query = sql.SQL(raw_sql).format(schema=sql.Identifier(schema))

        conn = connect(**self.db_config)
        try:
            with conn.cursor(name="stream_cursor") as cur:
                cur.itersize = chunk_size
                cur.execute(query, params or ())

                first = True
                while True:
                    rows = cur.fetchmany(chunk_size)
                    if not rows:
                        break

                    if first:
                        columns = [desc[0] for desc in cur.description]
                        yield rows, columns, total
                        first = False
                    else:
                        yield rows, None, total
        finally:
            conn.close()


if __name__ == '__main__':
    dbclient = DatabaseClient()
    # language=SQL
    query = '''
WITH base AS
     (
             SELECT
                     a.*                                                                      ,
                     substring("Asset description" FROM '((LBE|XW|Z94|KM)[[:alnum:]_]*)') AS code,
                     regexp_replace("Asset description", '\s*(LBE|XW|Z94|KM)[[:alnum:]_]*$',
                     -- –≤—ã—Ä–µ–∂–µ–º VIN + –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ
                     '' )                                                              AS element_left_part
             FROM
                     "Cars"."ANLA" AS a
             WHERE
                     "Deact.Date" = '' )
SELECT
        b."Asset description",
        b.code               ,
--        b.class               ,
        b.element_left_part  ,
        mp.model_norm,
        b."Class"
FROM
        base AS b
LEFT JOIN
        LATERAL
        (
                SELECT
                        model_norm
                FROM
                        "Cars".model_pattern
                WHERE
                        b.element_left_part ~* model_pattern.pattern
                ORDER BY
                        model_norm
                LIMIT 1 ) AS mp
ON
        true
--where b."Class" = 'HA01B08'
   '''

    rows, columns = dbclient.execute_custom(raw_sql=query, schema='Cars')
    df = pd.DataFrame(rows, columns=columns)

    pass
